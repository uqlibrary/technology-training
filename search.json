[
  {
    "objectID": "r/setup.html",
    "href": "r/setup.html",
    "title": "R with RStudio",
    "section": "",
    "text": "Tip\n\n\n\nRegistrations available for our next intensive!\nBook for 27th-29th Jan 2026",
    "crumbs": [
      "R with RStudio"
    ]
  },
  {
    "objectID": "r/setup.html#overview",
    "href": "r/setup.html#overview",
    "title": "R with RStudio",
    "section": "Overview",
    "text": "Overview\nWelcome to our three-day R training intensive! This runs twice a year and the next intensive will be in late January.\nBy the end of the three days, you’ll have learnt the Python skills to manipulate, visualise and present data. We’ll spend roughly half the time learning content, and half the time working on a project in groups.\nAs we set up, there’s a few things to do, if you haven’t already\n\nInstall the software\nIntroduce yourself to your table\nJoin our Teams channel\nRegister your attendance",
    "crumbs": [
      "R with RStudio"
    ]
  },
  {
    "objectID": "r/setup.html#r-rstudio",
    "href": "r/setup.html#r-rstudio",
    "title": "R with RStudio",
    "section": "R + RStudio",
    "text": "R + RStudio\nThe R programming language is a language used for calculations, statistics, visualisations and many more data science tasks.\nRStudio is an open source Integrated Development Environment (IDE) for R, which means it provides many features on top of R to make it easier to write and run code.\nR’s main strong points are:\n\nOpen Source: you can install it anywhere and adapt it to your needs;\nReproducibility: makes an analysis repeatable by detailing the process in a script;\nCustomisable: being a programming language, you can create your own custom tools;\nLarge datasets: it can handle very large datasets (certainly well beyond the row limitations of Excel, and even further using HPCs and other tricks);\nDiverse ecosystem: packages allow you to extend R for thousands of different analyses.\n\nThe learning curve will be steeper than point-and-click tools, but as far as programming languages go, R is more user-friendly than others.\n\nInstallation\nFor this course, you need to have both R and RStudio installed (installation instructions).",
    "crumbs": [
      "R with RStudio"
    ]
  },
  {
    "objectID": "r/setup.html#r-projects",
    "href": "r/setup.html#r-projects",
    "title": "R with RStudio",
    "section": "R Projects",
    "text": "R Projects\nLet’s first create a new project:\n\nClick the “File” menu button (top left corner), then “New Project”\nClick “New Directory”\nClick “New Project”\nIn “Directory name”, type the name of your project, for example “YYYY-MM-DD_rstudio-intro”\nBrowse and select a folder where to locate your project (~ is your home directory). For example, a folder called “r-projects”.\nClick the “Create Project” button\n\n\nR Projects make your work with R more straight forward, as they allow you to segregate your different projects in separate folders. You can create a .Rproj file in a new directory or an existing directory that already has R code and data. Everything then happens by default in this directory. The .Rproj file stores information about your project options, and allows you to go straight back to your work.",
    "crumbs": [
      "R with RStudio"
    ]
  },
  {
    "objectID": "r/setup.html#workshops",
    "href": "r/setup.html#workshops",
    "title": "R with RStudio",
    "section": "Workshops",
    "text": "Workshops\nOver these three days we’ll cover six sessions of content:\n\n\n\nSession\nDescription\n\n\n\n\nThe Fundamentals\nThe basics of R. Variables, functions and packages.\n\n\nData processing\nImporting, manipulating and analysing data with dplyr\n\n\nVisualisation\nCreating visualisations of our data with ggplot2\n\n\nSharing and Publishing\nUsing GitHub for sharing and version control, as well as quarto for publishing dashboards and websites.\n\n\nStatistics\nDescriptive and inferential statistics, with some regressions and hypothesis testing.\n\n\nProgramming Essentials\nR tools everyone should know. Conditionals, loops and functions.\n\n\n\nThese content sessions are pretty packed, and we won’t have too much time to deviate. That’s why we’ll also have five project sessions - see Project Overview for details. You’re welcome to ask lengthier questions and play around there!",
    "crumbs": [
      "R with RStudio"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html",
    "href": "r/Essentials/3 - Visualisation.html",
    "title": "Visualisation",
    "section": "",
    "text": "During this session, you will:",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#installing-ggplot2",
    "href": "r/Essentials/3 - Visualisation.html#installing-ggplot2",
    "title": "Visualisation",
    "section": "Installing ggplot2",
    "text": "Installing ggplot2\nWe first need to make sure we have the ggplot2 package available on our computer. We can use the “Install” button in the “Packages” pane, or we can execute this command in the console: install.packages(\"ggplot2\")\nYou only need to install a package once, but you need to load it every time you start a new R session.\nWe will write ggplot2 code more comfortably in a script. Feel free to continue using the script from previous sessions, or create a new one about visualisations.\nWe can straight away load the package into the library by adding this command to our script and executing it:\n\nlibrary(ggplot2)",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#finding-help",
    "href": "r/Essentials/3 - Visualisation.html#finding-help",
    "title": "Visualisation",
    "section": "Finding help",
    "text": "Finding help\nWe are going to work with different datasets that come with the ggplot2 package. For any dataset or function doubts that you might have, don’t forget the three ways to bring up a help page:\n\nthe command: ?functionname\nthe keyboard shortcut: press F1 after writing a function name\nthe search box in the Help pane\n\n\nIntroducing ggplot2\nThe R package ggplot2 was developed by Hadley Wickham with the objective of creating a grammar of graphics for categorical data (in 2007). It is based on the book The Grammar of Graphics Developed by Leland Wilkinson (first edition published in 1999).\nIt is now part of the group of data science packages called Tidyverse.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#the-components-of-the-grammar-of-graphics",
    "href": "r/Essentials/3 - Visualisation.html#the-components-of-the-grammar-of-graphics",
    "title": "Visualisation",
    "section": "The components of the Grammar of Graphics",
    "text": "The components of the Grammar of Graphics\nThe Grammar of Graphics is based on the idea that you can build every graph from the same few components.\nThe components are:\n\nData\nMapping\nStatistics\nScales\nGeometries\nFacets\nCoordinates\nTheme\n\nIn this introductory session, we will mainly focus on the data, the mapping, the statistics, the geometries and the theme.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#ggplot2s-three-essential-components",
    "href": "r/Essentials/3 - Visualisation.html#ggplot2s-three-essential-components",
    "title": "Visualisation",
    "section": "ggplot2’s three essential components",
    "text": "ggplot2’s three essential components\nIn ggplot2, the 3 main components that we usually have to provide are:\n\nWhere the data comes from,\nthe aesthetic mappings, and\na geometry.\n\nFor our first example, let’s use the msleep dataset (from the ggplot2 package), which contains data about mammals’ sleeping patterns.\n\nYou can find out about the dataset with ?msleep.\n\nLet’s start with specifying where the data comes from in the ggplot() function:\n\nggplot(data = msleep)\n\n\n\n\n\n\n\n\nThis is not very interesting. We need to tell ggplot2 what we want to visualise, by mapping aesthetic elements (like our axes) to variables from the data. We want to visualise how common different conservations statuses are, so let’s associate the right variable to the x axis:\n\nggplot(data = msleep,\n       mapping = aes(x = conservation))\n\n\n\n\n\n\n\n\nggplot2 has done what we asked it to do: the conservation variable is on the x axis. But nothing is shown on the plot area, because we haven’t defined how to represent the data, with a geometry_* function:\n\nggplot(data = msleep,\n       mapping = aes(x = conservation)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNow we have a useful plot: we can see that a lot of animals in this dataset don’t have a conservation status, and that “least concern” is the next most common value.\nWe can see our three essential elements in the code:\n\nthe data comes from the msleep object;\nthe variable conservation is mapped to the aesthetic x (i.e. the x axis);\nthe geometry is \"bar\", for “bar chart”.\n\nHere, we don’t need to specify what variable is associated to the y axis, as the “bar” geometry automatically does a count of the different values in the conservation variable. That is what statistics are applied automatically to the data.\n\nIn ggplot2, each geometry has default statistics, so we often don’t need to specify which stats we want to use. We could use a stat_*() function instead of a geom_*() function, but most people start with the geometry (and let ggplot2 pick the default statistics that are applied).",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#line-plots",
    "href": "r/Essentials/3 - Visualisation.html#line-plots",
    "title": "Visualisation",
    "section": "Line plots",
    "text": "Line plots\nLet’s have a look at another dataset: the economics dataset from the US. Learn more about it with ?economics, and have a peak at its structure with:\n\nstr(economics)\n\nspc_tbl_ [574 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ date    : Date[1:574], format: \"1967-07-01\" \"1967-08-01\" ...\n $ pce     : num [1:574] 507 510 516 512 517 ...\n $ pop     : num [1:574] 198712 198911 199113 199311 199498 ...\n $ psavert : num [1:574] 12.6 12.6 11.9 12.9 12.8 11.8 11.7 12.3 11.7 12.3 ...\n $ uempmed : num [1:574] 4.5 4.7 4.6 4.9 4.7 4.8 5.1 4.5 4.1 4.6 ...\n $ unemploy: num [1:574] 2944 2945 2958 3143 3066 ...\n\n\nDo you think that unemployment is stable over the years? Let’s have a look with a line plot, often used to visualise time series:\n\nggplot(data = economics,\n       mapping = aes(x = date,\n                     y = unemploy)) + \n    geom_line()\n\n\n\n\n\n\n\n\nLet’s go through our essential elements once more:\n\nThe ggplot() function initialises a ggplot object. In it, we declare the input data frame and specify the set of plot aesthetics used throughout all layers of our plot;\nThe aes() function groups our mappings of aesthetics to variables;\nThe geom_&lt;...&gt;() function specifies what geometric element we want to use.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#scatterplots",
    "href": "r/Essentials/3 - Visualisation.html#scatterplots",
    "title": "Visualisation",
    "section": "Scatterplots",
    "text": "Scatterplots\nScatterplots are often used to look at the relationship between two variables. Let’s try it with a new dataset: mpg (which stands for “miles per gallon”), a dataset about fuel efficiency of different models of cars.\n\n?mpg\nstr(mpg)\n\nDo you think that big engines use fuel more efficiently than small engines?\nWe can focus on two variables:\n\ndispl: a car’s engine size, in litres.\nhwy: a car’s fuel efficiency on the highway, in miles per gallon.\n\nFor the geometry, we now have use “points”:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) +\n    geom_point()\n\n\n\n\n\n\n\n\nNotice how the points seem to be aligned on a grid? That’s because the data was rounded. If we want to better visualise the density of points, we can use the “count” geometry, which makes the dots bigger when data points have the same x and y values:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) +\n    geom_count()\n\n\n\n\n\n\n\n\nAlternatively, we can avoid overlapping of points by using the “jitter” geometry, which gives the points a little shake:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) +\n    geom_jitter()\n\n\n\n\n\n\n\n\nEven though the position of the dots does not match exactly the original x and y values, it does help visualise densities better.\nThe plot shows a negative relationship between engine size (displ) and fuel efficiency (hwy). In other words, cars with big engines use more fuel. Does this confirm or refute your hypothesis about fuel efficiency and engine size?\nHowever, we can see some outliers. We need to find out more about our data.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#adding-aesthetics",
    "href": "r/Essentials/3 - Visualisation.html#adding-aesthetics",
    "title": "Visualisation",
    "section": "Adding aesthetics",
    "text": "Adding aesthetics\nWe can highlight the “class” factor by adding a new aesthetic:\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy,\n                     colour = class)) +\n    geom_jitter()\n\n\n\n\n\n\n\n\nIt seems that two-seaters are more fuel efficient than other cars with a similar engine size, which can be explained by the lower weight of the car. The general trend starts to make more sense!\nWe now know how to create a simple scatterplot, and how to visualise extra variables. But how can we better represent a correlation?",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#trend-lines",
    "href": "r/Essentials/3 - Visualisation.html#trend-lines",
    "title": "Visualisation",
    "section": "Trend lines",
    "text": "Trend lines\nA trend line can be created with the geom_smooth() function:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) +\n    geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nWe stopped using the argument names because we know in which order they appear: first the data, then the mapping of aesthetics. Let’s save ourselves some typing from now on!\n\nThe console shows you what function / formula was used to draw the trend line. This is important information, as there are countless ways to do that. To better understand what happens in the background, open the function’s help page and notice that the default value for the method argument is “NULL”. Read up on how it automatically picks a suitable method depending on the sample size, in the “Arguments” section.\nWant a linear trend line instead? Add the argument method = \"lm\" to your function:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) +\n    geom_smooth(method = \"lm\")",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#layering",
    "href": "r/Essentials/3 - Visualisation.html#layering",
    "title": "Visualisation",
    "section": "Layering",
    "text": "Layering\nA trend line is usually displayed on top of the scatterplot. How can we combine several layers? We can string them with the + operator:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) + \n    geom_point() +\n    geom_smooth()\n\n\n\n\n\n\n\n\n\nThe order of the functions matters: the points will be drawn before the trend line, which is probably what you’re after.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#the-colour-aesthetic",
    "href": "r/Essentials/3 - Visualisation.html#the-colour-aesthetic",
    "title": "Visualisation",
    "section": "The colour aesthetic",
    "text": "The colour aesthetic\nWe can once again add some information to our visualisation by mapping the class variable to the colour aesthetic:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) + \n    geom_point(aes(colour = class)) + \n    geom_smooth()\n\n\n\n\n\n\n\n\nChallenge 1 – where should aesthetics be defined?\nTake the last plot we created:\n\nggplot(mpg,\n       aes(x = displ,\n           y = hwy)) + \n    geom_point(aes(colour = class)) + \n    geom_smooth()\n\nWhat would happen if you moved the colour = class aesthetic from the geometry function to the ggplot() call?\nDifferent geometries can also have their own mappings that overwrite the defaults. If you place mappings in a geom_* function, ggplot2 will treat them as local mappings for the layer. It will use these mappings to extend or overwrite the global mappings for that layer only. This makes it possible to display different aesthetics in different layers.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#saving-a-plot",
    "href": "r/Essentials/3 - Visualisation.html#saving-a-plot",
    "title": "Visualisation",
    "section": "Saving a plot",
    "text": "Saving a plot\nLike your visualisation? You can export it with the “Export” menu in the “Plots” pane.\n\nBuilding a document or a slideshow? You can copy it straight to your clipboard, and paste it into it.\nA PDF is a good, quick option to export an easily shareable file with vector graphics. Try for example the “A5” size, the “Landscape” orientation, and save it into your “plots” directory.\nMore options are available in the “Save as image…” option. PNG is a good compressed format for graphics, but if you want to further customise your visualisation in a different program, use SVG or EPS, which are vector formats. (Try to open an SVG file in Inkscape for example.)\n\nTo save the last plot with a command, you can use the ggsave() function:\n\nggsave(filename = \"plots/fuel_efficiency.png\")\n\nThis is great to automate the export process for each plot in your script, but ggsave() also has extra options, like setting the DPI, which is useful for getting the right resolution for a specific use. For example, to export a plot for your presentation:\n\nggsave(filename = \"plots/fuel_efficiency.png\", dpi = \"screen\")\n\n\nSaving a .svg file with requires installing the svglite package. This packages seems so work best installing in a fresh R session (Session &gt; Restart R) from source install.packages(\"svglite\", type = \"source\"). Then load the library library(svglite) rerun your code including loading previous libraries (ggplot2 etc.) and now saving a plot with a .svg extension should work!\n\nChallenge 2 – add a variable and a smooth line\nLet’s use a similar approach to what we did with the mpg dataset.\nTake our previous unemployment visualisation, but represented with points this time:\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy)) + \n    geom_point()\n\nHow could we:\n\nAdd a smooth line for the number of unemployed people. Are there any interesting arguments that could make the smoother more useful?\nColour the points according to the median duration of unemployment (see ?economics)\n\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy)) + \n    geom_point(aes(colour = uempmed)) +\n    geom_smooth()\n\n\n\n\n\n\n\n\n\nSee how the legend changes depending on the type of data mapped to the colour aesthetic? (i.e. categorical vs continuous)\n\nThis default “trend line” is not particularly useful. We could make it follow the data more closely by using the span argument. The closer to 0, the closer to the data the smoother will be:\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy)) + \n    geom_point(aes(colour = uempmed)) +\n    geom_smooth(span = 0.1)\n\n\n\n\n\n\n\n\nYou can now see why this is called a “smoother”: we can fit a smooth curve to data that varies a lot.\nTo further refine our visualisation, we could visualise the unemployment rate rather than the number of unemployed people, by calculating it straight into our code:\n\nggplot(economics,\n       aes(x = date,\n           y = unemploy / pop)) + \n    geom_point(aes(colour = uempmed)) +\n    geom_smooth(span = 0.1)\n\n\n\n\n\n\n\n\nThe early 1980s recession now seems to have had a more significant impact on unemployment than the Global Financial Crisis of 2007-2008.",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#bar-charts-and-ordered-factors",
    "href": "r/Essentials/3 - Visualisation.html#bar-charts-and-ordered-factors",
    "title": "Visualisation",
    "section": "Bar charts and ordered factors",
    "text": "Bar charts and ordered factors\nLet’s use the diamonds dataset now. The diamonds dataset comes with ggplot2 and contains information about ~54,000 diamonds, including the price, carat, colour, clarity, and cut quality of each diamond.\nLet’s have a look at the data:\n\ndiamonds\nsummary(diamonds)\n?diamonds\n\nBack to bar charts. Consider a basic bar chart, as drawn with geom_bar(). The following chart displays the total number of diamonds in the diamonds dataset, grouped by cut:\n\nggplot(diamonds,\n       aes(x = cut)) + \n    geom_bar()\n\n\n\n\n\n\n\n\nThe chart shows that more diamonds are available with high quality cuts than with low quality cuts.\ncut is an ordered factor, which you can confirm by printing it to the console:\n\nhead(diamonds$cut)\n\n[1] Ideal     Premium   Good      Premium   Good      Very Good\nLevels: Fair &lt; Good &lt; Very Good &lt; Premium &lt; Ideal\n\n\nSee how ggplot2 respects that order in the bar chart?\n\nCustomising a plot\nLet’s see how we can customise our bar chart’s look.\n\nChange a geometry’s default colour\nFirst, we can pick our favourite colour in geom_bar():\n\nggplot(diamonds,\n       aes(x = cut)) + \n    geom_bar(fill = \"tomato\")\n\n\n\n\n\n\n\n\nIf you are curious about what colour names exist in R, you can use the colours() function. Alernatively, you can use any hex value like “#760daa”.\n\n\n\nChange labels\nWe can also modify labels with the labs() function to make our plot more self-explanatory:\n\nggplot(diamonds,\n       aes(x = cut)) + \n    geom_bar(fill = \"tomato\") +\n    labs(title = \"Where are the bad ones?\",\n         x = \"Quality of the cut\",\n         y = \"Number of diamonds\")\n\n\n\n\n\n\n\n\nLet’s have a look at what labs() can do:\n\n?labs\n\nIt can edit the title, the subtitle, the x and y axes labels, and the caption.\n\nRemember that captions and titles are better sorted out in the publication itself, especially for accessibility reasons (e.g. to help with screen readers).\n\n\n\nHorizontal bar charts\nFor a horizontal bar chart, we can map the cut variable to the y aesthetic instead of x. But remember to also change your labels around!\n\nggplot(diamonds,\n       aes(y = cut)) + # switch here...\n  geom_bar(fill = \"tomato\") +\n  labs(title = \"Where are the bad ones?\",\n       y = \"Quality of the cut\", # ...but also here!\n       x = \"Number of diamonds\") # ...and here!\n\n\n\n\n\n\n\n\nThis is particularly helpful when long category names overlap under the x axis.\n\n\nBuilt-in themes\nThe theme() function allows us to really get into the details of our plot’s look, but some theme_*() functions make it easy to apply a built-in theme, like theme_bw():\n\nggplot(diamonds,\n       aes(y = cut)) + \n  geom_bar(fill = \"tomato\") +\n  labs(title = \"Where are the bad ones?\",\n       y = \"Quality of the cut\",\n       x = \"Number of diamonds\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nTry theme_minimal() as well, and if you want more options, install the ggthemes package!",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#interactive-visualisations",
    "href": "r/Essentials/3 - Visualisation.html#interactive-visualisations",
    "title": "Visualisation",
    "section": "Interactive visualisations",
    "text": "Interactive visualisations\nPlotly is a package that allows creating interactive visualisation. A nifty aspect of it is that it can directly convert most static ggplot2 visualisations to interactive HTML visualisations.\nAfter installing the package, you can convert our mpg visualisation by saving it as an object, and passing it to the ggplotly() function:\n\nstatic_plot &lt;- ggplot(mpg,\n                      aes(x = displ,\n                          y = hwy)) + \n  geom_jitter(aes(colour = class)) + \n  geom_smooth()\nlibrary(plotly)\nggplotly(static_plot)\n\n\n\n\n\nWe can now use our mouse to hover over points and see the associated data, turn series off and on, and draw rectangles to zoom in.\nThis kind of visualisation is a good way to expose extra data through the tooltips. For example, associating the “manufacturer” and “model” variables to “label” aesthetics in the ggplot2 command won’t show that information on the static visualisation (unless labelling geometry is used), but it will be included in the plotly tooltip:\n\nstatic_plot &lt;- ggplot(mpg,\n                      aes(x = displ,\n                          y = hwy)) + \n  geom_jitter(aes(colour = class,\n                  label = manufacturer,\n                  label2 = model)) + \n  geom_smooth()\nlibrary(plotly)\nggplotly(static_plot)",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/3 - Visualisation.html#further-resources",
    "href": "r/Essentials/3 - Visualisation.html#further-resources",
    "title": "Visualisation",
    "section": "Further resources",
    "text": "Further resources\n\nggplot2 cheatsheet\nOfficial ggplot2 documentation\nOfficial ggplot2 website\nChapter on data visualisation in the book R for Data Science\nFrom Data to Viz, a website to explore different visualisations and the code that generates them\nSelva Prabhakaran’s r-statistics.co section on ggplot2\nCoding Club’s data visualisation tutorial\nSTHDA’s ggplot2 essentials\nLear more about plotly and exploratory data analysis with the book Interactive web-based data visualization with R, plotly, and shiny",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html",
    "href": "r/Essentials/2 - Data processing.html",
    "title": "Preparing data for analysis",
    "section": "",
    "text": "In this hands-on session, we will use the dplyr package to transform your data.\nSpecifically, you will learn how to explore, filter, reorganise and process a dataframe with the following verbs:\n\nselect(): pick variables\nfilter(): pick observations\narrange(): reorder observations\nmutate(): create new variables\nsummarise(): collapse to a single summary\ngroup_by(): change the scope of function",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#what-are-we-going-to-learn",
    "href": "r/Essentials/2 - Data processing.html#what-are-we-going-to-learn",
    "title": "Preparing data for analysis",
    "section": "",
    "text": "In this hands-on session, we will use the dplyr package to transform your data.\nSpecifically, you will learn how to explore, filter, reorganise and process a dataframe with the following verbs:\n\nselect(): pick variables\nfilter(): pick observations\narrange(): reorder observations\nmutate(): create new variables\nsummarise(): collapse to a single summary\ngroup_by(): change the scope of function",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#keep-in-mind",
    "href": "r/Essentials/2 - Data processing.html#keep-in-mind",
    "title": "Preparing data for analysis",
    "section": "Keep in mind",
    "text": "Keep in mind\n\nEverything we write today will be saved in your project. Please remember to save it somewhere you can access it later if you wish to revisit what we do today.\nR is case sensitive: it will tell the difference between uppercase and lowercase.\nRespect the naming rules for objects (no spaces, does not start with a number…)\n\n\nHelp\nFor any dataset or function doubts that you might have, don’t forget the three ways of getting help in RStudio:\n\nthe shortcut command: ?functionname\nthe help function: help(functionname)\nthe keyboard shortcut: press F1 after writing a function name",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#setting-up",
    "href": "r/Essentials/2 - Data processing.html#setting-up",
    "title": "Preparing data for analysis",
    "section": "Setting up",
    "text": "Setting up\n\nInstall the dplyr package\nIf you don’t have it already, you can install dplyr with the command: install.packages(\"dplyr\")\n\nAlternatively, you can install the whole “tidyverse”, a meta-package useful for data science: install.packages(\"tidyverse\")\n\n\n\nCreate a script\nWe will use a script to write code more comfortably.\n\nMenu: Top left corner, click the green “plus” symbol, or press the shortcut (for Windows/Linux) Ctrl+Shift+N or (for Mac) Cmd+Shift+N. This will open an “Untitled1” file.\nGo to “File &gt; Save” or press (for Windows/Linux) Ctrl+S or (for Mac) Cmd+S. This will ask where you want to save your file and the name of the new file.\nCall your file “process.R”\n\n\n\nIntroducing our data\nLet’s import and explore the gapminder data again.\n\nuse the read.csv() command to bring it into R:\n\ngapminder &lt;- read.csv(\"../../data/gapminder.csv\")\n\nRemember you can use Ctrl+shift to execute a command from the script.\n\n\nYou can explore the gapminder dataset using dim(), head() and str()\n\nHow can we get the dataframe’s variable names? There are two ways: names(gapminder) returns the names regardless of the object type, such as list, vector, data.frame etc., whereas colnames(gapminder) returns the variable names for matrix-like objects, such as matrices, dataframes…\nTo return one specific column in the dataframe, you can use the dollar syntax: gapminder$year. For example, try these:\nclass(gapminder$country) # what kind of data?\n[1] \"character\"\nrange(gapminder$year) # what is the time range?\n[1] 1952 2007",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#basic-dplyr-verbs",
    "href": "r/Essentials/2 - Data processing.html#basic-dplyr-verbs",
    "title": "Preparing data for analysis",
    "section": "Basic dplyr verbs",
    "text": "Basic dplyr verbs\nThe R package dplyr was developed by Hadley Wickham for data manipulation.\nThe book R for Data Science introduces the package as follows:\n\nYou are going to learn the five key dplyr functions that allow you to solve the vast majority of your data manipulation challenges:\n\nPick variables by their names with select()\nPick observations by their values with filter()\nReorder the rows with arrange()\nCreate new variables with functions of existing variables with mutate()\nCollapse many values down to a single summary with summarise()\n\nThese can all be used in conjunction with group_by() which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. These six functions provide the main verbs for a language of data manipulation.\n\nTo use the verbs to their full extent, we will use pipes and logical operators, which we will introduce as we go.\nLet’s load the dplyr package to access its functions:\nlibrary(dplyr)\n\nYou only need to install a package once (with install.packages()), but you need to reload it every time you start a new R session (with library()).\n\n\n1. Pick variables with select()\nselect() allows us to pick variables (i.e. columns) from the dataset. For example, to only keep the data about year, country and GDP per capita:\ngap_small &lt;- select(gapminder, year, country, gdpPercap)\nThe first argument refers to the dataframe that is being transformed, and the following arguments are the columns you want to keep. Notice that it keeps the order you specified?\nYou can also rename columns in the same command:\ngap_small &lt;- select(gapminder, year, country, gdpPerPerson = gdpPercap)\nIf you have many variables but only want to remove a small number, it might be better to deselect instead of selecting. You can do that by using the - character in front of a variable name:\nnames(select(gapminder, -continent))\n[1] \"country\"   \"year\"      \"pop\"       \"lifeExp\"   \"gdpPercap\"\nThere are also a lot of helper functions to select columns according to a logic. For example, to only keep the columns that have “a” in their names:\nnames(select(gapminder, contains(\"a\")))\n[1] \"year\"      \"gdpPercap\"\n\n\n2. Pick observations with filter()\nThe filter() function allows use to pick observations depending on one or several conditions. But to be able to define these conditions, we need to learn about logical operators.\nLogical operators allow us to compare things. Here are some of the most important ones:\n\n==: equal\n!=: different or not equal\n&gt;: greater than\n&lt;: smaller than\n&gt;=: greater or equal\n&lt;=: smaller or equal\n\n\nRemember: = is used to pass on a value to an argument, whereas == is used to check for equality. Using = instead of == for a logical statment is one of the most common errors and R will give you a reminder in the console when this happens.\n\nFor example, to filter the observations for Australia, we can use the following condition:\naustralia &lt;- filter(gapminder, country == \"Australia\")\naustralia\n# A tibble: 12 × 6\n   country    year      pop continent lifeExp gdpPercap\n   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 Australia  1952  8691212 Oceania      69.1    10040.\n 2 Australia  1957  9712569 Oceania      70.3    10950.\n 3 Australia  1962 10794968 Oceania      70.9    12217.\n 4 Australia  1967 11872264 Oceania      71.1    14526.\n 5 Australia  1972 13177000 Oceania      71.9    16789.\n 6 Australia  1977 14074100 Oceania      73.5    18334.\n 7 Australia  1982 15184200 Oceania      74.7    19477.\n 8 Australia  1987 16257249 Oceania      76.3    21889.\n 9 Australia  1992 17481977 Oceania      77.6    23425.\n10 Australia  1997 18565243 Oceania      78.8    26998.\n11 Australia  2002 19546792 Oceania      80.4    30688.\n12 Australia  2007 20434176 Oceania      81.2    34435.\nThe function compares the value “Australia” to all the values in the country variable, and only keeps the rows that have TRUE as an answer.\nNow, let’s filter the rows that have a life expectancy lifeExp greater than 81 years:\nlife81 &lt;- filter(gapminder, lifeExp &gt; 81)\ndim(life81)\n[1] 7 6\n\n\n3. Reorder observations with arrange()\narrange() will reorder our rows according to a variable, by default in ascending order:\narrange(life81, lifeExp)\n# A tibble: 7 × 6\n  country          year       pop continent lifeExp gdpPercap\n  &lt;chr&gt;           &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 Australia        2007  20434176 Oceania      81.2    34435.\n2 Hong Kong China  2002   6762476 Asia         81.5    30209.\n3 Switzerland      2007   7554661 Europe       81.7    37506.\n4 Iceland          2007    301931 Europe       81.8    36181.\n5 Japan            2002 127065841 Asia         82      28605.\n6 Hong Kong China  2007   6980412 Asia         82.2    39725.\n7 Japan            2007 127467972 Asia         82.6    31656.\nIf we want to have a look at the entries with highest life expectancy first, we can use the desc() function (for “descending”):\narrange(life81, desc(lifeExp))\n# A tibble: 7 × 6\n  country          year       pop continent lifeExp gdpPercap\n  &lt;chr&gt;           &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 Japan            2007 127467972 Asia         82.6    31656.\n2 Hong Kong China  2007   6980412 Asia         82.2    39725.\n3 Japan            2002 127065841 Asia         82      28605.\n4 Iceland          2007    301931 Europe       81.8    36181.\n5 Switzerland      2007   7554661 Europe       81.7    37506.\n6 Hong Kong China  2002   6762476 Asia         81.5    30209.\n7 Australia        2007  20434176 Oceania      81.2    34435.\n\nThe pipe operator\nWhat if we wanted to get that result in one single command, without an intermediate life81 object?\nWe could nest the commands into each other, the first step as the first argument of the second step:\narrange(filter(gapminder, lifeExp &gt; 81), desc(lifeExp))\n… but this becomes very hard to read, very quickly. (Imagine with 3 steps or more!)\nWe can make our code more readable and avoid creating useless intermediate objects by piping commands into each other. The pipe operator %&gt;% strings commands together, using the left side’s output as the first argument of the right side function.\nFor example, this command:\ngapminder %&gt;%\n  filter(lifeExp &gt; 81) %&gt;% \n  arrange(desc(lifeExp))\n… is equivalent to:\narrange(filter(gapminder, lifeExp &gt; 81), desc(lifeExp))\nThe pipe operator can be read as “then” and makes the code a lot more readable than when nesting functions into each other, and avoids the creation of several intermediate objects. It is also easier to troubleshoot as it makes it easy to execute the pipeline step by step.\nFrom now on, we’ll use the pipe syntax as a default.\n\nNote that this material uses the magrittr pipe. The magrittr package is the one that introduced the pipe operator to the R world, and dplyr automatically imports this useful operator when it is loaded. However, the pipe being such a widespread and popular concept in programming and data science, it ended up making it into Base R (the “native” pipe) in 2021 with the release of R 4.1, using a different operator: |&gt;. You can switch your pipe shortcut to the native pipe in Tools &gt; Global options &gt; Code &gt; Use native pipe operator.\n\n\n\n\n4. Create new variables with mutate()\nHave a look at what the verb mutate() can do with ?mutate.\nLet’s see what the two following variables can be used for:\ngapminder %&gt;%\n    select(gdpPercap, pop)\n# A tibble: 1,704 × 2\n   gdpPercap      pop\n       &lt;dbl&gt;    &lt;dbl&gt;\n 1      779.  8425333\n 2      821.  9240934\n 3      853. 10267083\n 4      836. 11537966\n 5      740. 13079460\n 6      786. 14880372\n 7      978. 12881816\n 8      852. 13867957\n 9      649. 16317921\n10      635. 22227415\n# ℹ 1,694 more rows\nHow do you think we could combine them to add something new to our dataset?\nWe can use mutate() to create a gdp variable that tells us the total gdp.\nName your new dataset gap_gdp. When finished, dim(gap_gdp) should result in 1704 7.\nHint: use the * operator within mutate() to multiply the pop by gdpPercap.\ngap_gdp &lt;- gapminder %&gt;%\n    mutate(gdp = gdpPercap * pop)\ndim(gap_gdp)\n[1] 1704    7\nhead(gap_gdp)\n# A tibble: 6 × 7\n  country      year      pop continent lifeExp gdpPercap          gdp\n  &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Afghanistan  1952  8425333 Asia         28.8      779.  6567086330.\n2 Afghanistan  1957  9240934 Asia         30.3      821.  7585448670.\n3 Afghanistan  1962 10267083 Asia         32.0      853.  8758855797.\n4 Afghanistan  1967 11537966 Asia         34.0      836.  9648014150.\n5 Afghanistan  1972 13079460 Asia         36.1      740.  9678553274.\n6 Afghanistan  1977 14880372 Asia         38.4      786. 11697659231.\nYou can reuse a variable computed by ‘mutate()’ straight away. For example, we also want a more readable version of our new variable, in billion dollars:\ngap_gdp &lt;- gapminder %&gt;%\n    mutate(gdp = gdpPercap * pop,\n           gdpBil = gdp / 1e9)\n\n\n5. Collapse to a single value with summarise()\nsummarise() collapses many values down to a single summary. For example, to find the mean life expectancy for the whole dataset:\ngapminder %&gt;%\n  summarise(meanLE = mean(lifeExp))\n# A tibble: 1 × 1\n  meanLE\n   &lt;dbl&gt;\n1   59.5\nHowever, a single-value summary is not particularly interesting. summarise() becomes more powerful when used with group_by().\n\n\n6. Change the scope with group_by()\ngroup_by() changes the scope of the following function(s) from operating on the entire dataset to operating on it group-by-group.\nSee the effect of the grouping step:\ngapminder %&gt;%\n    group_by(continent)\n# A tibble: 1,704 × 6\n   country      year      pop continent lifeExp gdpPercap\n   &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan  1952  8425333 Asia         28.8      779.\n 2 Afghanistan  1957  9240934 Asia         30.3      821.\n 3 Afghanistan  1962 10267083 Asia         32.0      853.\n 4 Afghanistan  1967 11537966 Asia         34.0      836.\n 5 Afghanistan  1972 13079460 Asia         36.1      740.\n 6 Afghanistan  1977 14880372 Asia         38.4      786.\n 7 Afghanistan  1982 12881816 Asia         39.9      978.\n 8 Afghanistan  1987 13867957 Asia         40.8      852.\n 9 Afghanistan  1992 16317921 Asia         41.7      649.\n10 Afghanistan  1997 22227415 Asia         41.8      635.\n# ℹ 1,694 more rows\nThe data in the cells is the same, the size of the object is the same. However, the dataframe was converted to a tibble, because a dataframe is not capable of storing grouping information.\nUsing the group_by() function before summarising makes things more interesting. Let’s re-run the previous command, with the intermediate grouping step:\ngapminder %&gt;%\n  group_by(continent) %&gt;% \n  summarise(meanLE = mean(lifeExp))\n# A tibble: 5 × 2\n  continent meanLE\n  &lt;chr&gt;      &lt;dbl&gt;\n1 Africa      48.9\n2 Americas    64.7\n3 Asia        60.1\n4 Europe      71.9\n5 Oceania     74.3\nWe now have the summary computed for each continent.\nSimilarly, to find out the total population per continent in 2007, we can do the following:\ngapminder %&gt;% \n    filter(year == 2007) %&gt;%\n    group_by(continent) %&gt;%\n    summarise(pop = sum(pop))\n# A tibble: 5 × 2\n  continent        pop\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Africa     929539692\n2 Americas   898871184\n3 Asia      3811953827\n4 Europe     586098529\n5 Oceania     24549947",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#exporting-your-data",
    "href": "r/Essentials/2 - Data processing.html#exporting-your-data",
    "title": "Preparing data for analysis",
    "section": "Exporting your data",
    "text": "Exporting your data\nIf you want to save your data as a .csv file, you can use the write.csv() function:\npop07 &lt;- gapminder %&gt;% \n  filter(year == 2007) %&gt;%\n  group_by(continent) %&gt;%\n  summarise(pop = sum(pop))\n\nwrite.csv(pop07, \"pop07.csv\")\nYou can also use it with the pipe:\ngapminder %&gt;% \n  filter(year == 2007) %&gt;%\n  group_by(continent) %&gt;%\n  summarise(pop = sum(pop)) %&gt;%\n  write.csv(\"pop07.csv\")",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#more-examples",
    "href": "r/Essentials/2 - Data processing.html#more-examples",
    "title": "Preparing data for analysis",
    "section": "More examples",
    "text": "More examples\nAnother example of a summary, with a the starwars data set that dplyr provides:\nGrouping by species, summarise the number of characters per species and find the mean mass. Only for species groups with more than 1 character.\nstarwars %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = n(), # this counts the number of rows in each group\n    mass = mean(mass, na.rm = TRUE)\n  ) %&gt;%\n  filter(n &gt; 1) # the mean of a single value is not worth reporting\n# A tibble: 9 × 3\n  species      n  mass\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n1 Droid        6  69.8\n2 Gungan       3  74  \n3 Human       35  81.3\n4 Kaminoan     2  88  \n5 Mirialan     2  53.1\n6 Twi'lek      2  55  \n7 Wookiee      2 124  \n8 Zabrak       2  80  \n9 &lt;NA&gt;         4  81  \nAn example of data manipulation and data visualisation in the same command with gapminder:\nSummarise the gapminder population data into total population per continent per year and plot coloured by continent.\n# increase in population per continent\nlibrary(ggplot2)\ngapminder %&gt;% \n  group_by(continent, year) %&gt;% \n  summarise(pop = sum(pop)) %&gt;% \n  ggplot(aes(x = year,\n             y = pop,\n             colour = continent)) +\n  geom_line()\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\nAnd another example, using using our gapminder dataset:\nLet’s say we want to calulate the variation (range) in life expectancy per country and plot the top and bottom 10 countries?\ngapminder %&gt;% \n  group_by(country) %&gt;% \n  summarise(maxLifeExp = max(lifeExp),\n            minLifeExp = min(lifeExp)) %&gt;% \n  mutate(dif = maxLifeExp - minLifeExp) %&gt;%  # new col with difference betwen max/min lifeExp\n  arrange(desc(dif)) %&gt;%  # arrange by dif, descending order for the next step\n  slice(1:10, (nrow(.)-10):nrow(.)) %&gt;%  # slice top 10 rows and bottom 10 rows\n  ggplot(aes(x = reorder(country, dif), y = dif)) +\n  geom_col() +\n  coord_flip() + # flip the x and y axis for a horizontal bar chart\n  labs(x = \"Country\",\n       y = \"Difference in Life Expectancy\") + # prettier labels for axes (which have been flipped) \n  annotate(\"segment\", x = 11.5, xend = 21.5, y = 39, yend = 39, colour = \"purple\", size=1, alpha=0.6) +\n  annotate(\"segment\", x = 0.5, xend = 11, y = 39, yend = 39, colour = \"green\", size=1, alpha=0.6) +\n    annotate(\"text\", x = c(5, 16), y = c(40, 40), \n           label = c(\"Smallest 10\", \"Largest 10\") ,\n           color=\"black\", size= 5 , angle=90) # add labels to colored lines\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Essentials/2 - Data processing.html#close-project",
    "href": "r/Essentials/2 - Data processing.html#close-project",
    "title": "Preparing data for analysis",
    "section": "Close project",
    "text": "Close project\nIf you want to close RStudio, make sure you save your script first.\nYou can then close the window, and if your script contains all the steps necessary for your data processing, it is safer to not save your workspace at the prompt. It should only take a second te execute all the commands stored in your script when you re-open your project.",
    "crumbs": [
      "Essentials",
      "Preparing data for analysis"
    ]
  },
  {
    "objectID": "r/Advanced topics/5 - Statistics.html",
    "href": "r/Advanced topics/5 - Statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "This session is aimed as an overview of how to perform some statistical modelling with R. It is an R workshop, not a statistics workshop - if you’d like to better understand the statistical models, or need help deciding what’s best for you, please consult a statistics resource or contact a statistician.\nIn this session, we’ll cover\nWe’ll be working from our “Players2024” dataset. After downloading it and putting it in your data folder, to bring it in and clean it up,\nlibrary(dplyr)\nplayers &lt;- read.csv(\"../../data/Players2024.csv\")\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "r/Advanced topics/5 - Statistics.html#descriptive-statistics",
    "href": "r/Advanced topics/5 - Statistics.html#descriptive-statistics",
    "title": "Statistics",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nWe’ll start with sample size. To calculate the number of non-empty observations in a column, say the numeric variable players$height_cm, we use the length() function\n\nlength(players$height_cm)\n\n[1] 5932\n\n\nWe can compute measures of central tendancy similarly. The average value is given by\n\nmean(players$height_cm)\n\n[1] 183.0413\n\n\nand the median by\n\nmedian(players$height_cm)\n\n[1] 183\n\n\n\nMeasures of variance\nWe can also compute measures of variance. The minimum and maximum are as expected\n\nmin(players$height_cm)\n\n[1] 160\n\nmax(players$height_cm)\n\n[1] 206\n\n\nThe function range() yields both\n\nrange(players$height_cm)\n\n[1] 160 206\n\n\nSo the actual range, i.e. the difference, is\n\ndiff(range(players$height_cm))\n\n[1] 46\n\n\nQuartiles are given by quantile() and the inter-quartile range (IQR) by IQR():\n\nquantile(players$height_cm)\n\n  0%  25%  50%  75% 100% \n 160  178  183  188  206 \n\nIQR(players$height_cm)\n\n[1] 10\n\n\nA column’s standard deviation and variance are given by\n\nsd(players$height_cm)\n\n[1] 6.838736\n\nvar(players$height_cm)\n\n[1] 46.76832\n\n\nAll together, you can see a nice statistical summary with\n\nsummary(players$height_cm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    160     178     183     183     188     206 \n\n\n\n\nMeasures of correlation\nIf you’ve got two numeric variables, you might want to examine covariance and correlation. These indicate how strongly the variables are linearly related. We’ll need to use the players$age variable as well.\nThe covariance between “height_cm” and “age” is\n\ncov(players$height_cm, players$age)\n\n[1] 0.5126608\n\n\nSimilarly, we can find the Pearson correlation coefficient between two columns.\n\ncor(players$height_cm, players$age)\n\n[1] 0.01682598\n\n\nYou can also specify “kendall” or “spearman” for their respective correlation coefficients\n\ncor(players$height_cm, players$age, method = \"kendall\")\n\n[1] 0.005417946\n\ncor(players$height_cm, players$age, method = \"spearman\")\n\n[1] 0.007604345\n\n\n\n\nReminder about groupbys\nBefore we move to inferential statistics, it’s worth reiterating the power of groupbys discussed in the second workshop.\nTo group by a specific variable, like “positions”, we use\n\nplayers %&gt;% \n    group_by(positions)\n\n# A tibble: 5,932 × 7\n# Groups:   positions [4]\n   name                birth_date height_cm positions  nationality   age club   \n   &lt;chr&gt;               &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;  \n 1 James Milner        1986-01-04       175 Midfield   England        38 Bright…\n 2 Anastasios Tsokanis 1991-05-02       176 Midfield   Greece         33 Volou …\n 3 Jonas Hofmann       1992-07-14       176 Midfield   Germany        32 Bayer …\n 4 Pepe Reina          1982-08-31       188 Goalkeeper Spain          42 Calcio…\n 5 Lionel Carole       1991-04-12       180 Defender   France         33 Kayser…\n 6 Ludovic Butelle     1983-04-03       188 Goalkeeper France         41 Stade …\n 7 Daley Blind         1990-03-09       180 Defender   Netherlands    34 Girona…\n 8 Craig Gordon        1982-12-31       193 Goalkeeper Scotland       41 Heart …\n 9 Dimitrios Sotiriou  1987-09-13       185 Goalkeeper Greece         37 Omilos…\n10 Alessio Cragno      1994-06-28       184 Goalkeeper Italy          30 Associ…\n# ℹ 5,922 more rows\n\n\nBy applying our statistics to the group_by object, we’ll apply them to every variable for each position.\n\nplayers %&gt;% \n    group_by(positions) %&gt;% \n    summarise(mean_height = mean(height_cm))\n\n# A tibble: 4 × 2\n  positions  mean_height\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Attack            181.\n2 Defender          184.\n3 Goalkeeper        191.\n4 Midfield          180.",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "r/Advanced topics/5 - Statistics.html#inferential-statistics",
    "href": "r/Advanced topics/5 - Statistics.html#inferential-statistics",
    "title": "Statistics",
    "section": "Inferential Statistics",
    "text": "Inferential Statistics\nWhile descriptive statistics describes the data definitively, inferential statistics aim to produce models for extrapolating conlusions.\n\nSimple linear regressions\nLeast-squares regression for two sets of measurements can be performed with the function lm. Recall that linear regressions have the mathematical form\n\\[ Y = β_1 X + β_0 \\]\nwhere \\(β_1\\) is the slope (or gradient) of the line and \\(β_0\\) the y-intercept. We use the regression tool to estimate the parameters \\(β_0\\,,β_1\\).\nA linear model (like above) is one example of the more general relationship \\(Y\\sim X\\), where \\(Y\\) is distributed as \\(X\\) (or, \\(Y\\) depends on \\(X\\)). For this reason, we can construct a linear model in R with three pieces of information\n\nThe type of model (e.g. linear) as a function (e.g. lm(...))\nThe general relationship between variables as a string (e.g. \"height_cm ~ age\")\nThe dataset we’re using (e.g. players)\n\n\nlm(formula = \"height_cm ~ age\", data = players)\n\n\nCall:\nlm(formula = \"height_cm ~ age\", data = players)\n\nCoefficients:\n(Intercept)          age  \n  182.38260      0.02583  \n\n\n\n\n\n\n\n\nTipR formula syntax\n\n\n\nPerforming statistical modelling with R inevitably requires using R’s powerful formula syntax, as we just did with `“height_cm ~ age”. For anything beyond simple linear regressions, you’ll need to include more terms and operators in these. Here’s a quick summary of a few, but you should check out this handy blog post for a better summary and the official documentation for comprehensive details.\n~\nUse ~ to separate the \\(Y\\) variable from the \\(X\\) variable(s), e.g. y ~ x.\n+\nAdd multiple \\(X\\) variables, e.g. y ~ x + z (for variable z)\n:\nConsider the interaction between two variables, e.g. y ~ x:z.\n-\nRemove variables, e.g. y ~ x - 1 (removes the intercept).\n\n\nIf we store this as a variable, we can then produce a summary of the results (note that we can remove the formula = and data = if the order is correct),\n\nmodel &lt;- lm(\"height_cm ~ age\", players)\nsummary(model)\n\n\nCall:\nlm(formula = \"height_cm ~ age\", data = players)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.028  -5.028   0.075   4.978  23.075 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 182.38260    0.51599 353.460   &lt;2e-16 ***\nage           0.02583    0.01993   1.296    0.195    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.838 on 5930 degrees of freedom\nMultiple R-squared:  0.0002831, Adjusted R-squared:  0.0001145 \nF-statistic: 1.679 on 1 and 5930 DF,  p-value: 0.1951\n\n\nIf you want to get specific parameters out, we can index with $:\n\nsummary(model)$r.squared\n\n[1] 0.0002831136\n\n\nThat’s a pretty shocking fit.\n\nPlotting it\nNaturally, you’d want to plot this. We’ll need to use techniques from the visualisation session. Let’s import ggplot2\n\nlibrary(ggplot2)\n\nStart by making a scatterplot of the data,\n\nggplot(players, aes(x = height_cm, y = age)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThen, you’ll need to plot the regression as a line. For reference,\n\\[ y = \\text{slope}\\times x + \\text{intercept}\\]\nSo\n\nb0 &lt;- model$coefficients[1]\nb1 &lt;- model$coefficients[2]\n\nggplot(players, aes(x = age, y = height_cm)) + \n    geom_point() + \n    geom_abline(intercept = b0, slope = b1)\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)-tests\nWe can also perform \\(t\\)-tests. Typically, these are performed to examine the statistical signficance of a difference between two samples’ means. Let’s examine whether that earlier groupby result for is accurate for heights, specifically, are goalkeepers taller than non-goalkeepers?\nLet’s start by creating a new column with the values\n\n\n\nFALSE\nNon-goalkeeper\n\n\nTRUE\nGoalkeeper\n\n\n\n\nplayers &lt;- players %&gt;% \n  mutate(gk = positions == \"Goalkeeper\")\n\nThe \\(t\\)-test’s goal is to check whether \\(\\text{height\\_cm}\\) depends on \\(\\text{gk}\\), so the formula is \\(\\text{height\\_cm}\\sim\\text{gk}\\). This is given to the t.test function:\n\nt.test(height_cm ~ gk, data = players)\n\n\n    Welch Two Sample t-test\n\ndata:  height_cm by gk\nt = -48.817, df = 1274.4, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group FALSE and group TRUE is not equal to 0\n95 percent confidence interval:\n -9.036644 -8.338391\nsample estimates:\nmean in group FALSE  mean in group TRUE \n           181.9810            190.6685 \n\n\nYielding a p-value of \\(p&lt;2.2\\times10^{-16}\\), indicating that the null-hypothesis (heights are the same) is extremely unlikely.\nTo visualise this result, it might be helpful to produce a histogram of the heights\n\nggplot(players, \n       aes(x = height_cm, fill = gk)) + \n  geom_histogram(bins = 24)\n\n\n\n\n\n\n\n\n\n\nANOVAs\nWhat about the means of the other three? We could use an ANOVA to examine them. We use the aov() function for this.\nLet’s start by making a new dataset without goalkeepers\n\nno_gk &lt;- players %&gt;% filter(gk == FALSE)\n\nNext, we save the analysis of variance results\n\nres_aov &lt;- aov(height_cm ~ positions, data = no_gk)\n\nAnd examine them with summary()\n\nsummary(res_aov)\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)    \npositions      2  15470    7735   199.7 &lt;2e-16 ***\nResiduals   5205 201552      39                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEven without goalkeepers included, it looks like their positions are not all independent of height.\n\n\n\\(\\chi^2\\) tests\n\\(χ^2\\) tests are useful for examining the relationship of categorical variables by comparing the frequencies of each. Often, you’d use this if you can make a contingency table.\nWe only have one useful categorical variable here, “positions” (the others have too many unique values), so we’ll need to create another. Let’s see if there’s a relationship between players’ positions and names with the letter “a”.\nMake a binary column for players with the letter “a” in their names. To do this, we need to apply a string method to all the columns in the dataframe as follows\n\nplayers &lt;- players %&gt;%\n  mutate(a_in_name = grepl(\"a\", name))\n\n\nThe grepl function perform pattern matching: it checks if the pattern \"a\" is inside the values in name.\n\nLet’s cross tabulate positions with this new column\n\ntable(players$positions, players$a_in_name)\n\n            \n             FALSE TRUE\n  Attack       291 1280\n  Defender     355 1606\n  Goalkeeper   149  575\n  Midfield     312 1364\n\n\nThe \\(χ^2\\) test’s job is to examine whether players’ positions depend on the presence of “a” in their name. To evaluate it we need to send the contingency table in:\n\nchisq.test(table(players$positions, players$a_in_name))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(players$positions, players$a_in_name)\nX-squared = 2.1808, df = 3, p-value = 0.5357\n\n\nAs expected, there is no signifcant relationship. A simple bar plot can help us here\n\nggplot(players,\n       aes(x = positions, fill = a_in_name)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nIf we use the position = \"fill\" parameter to geom_bar, we’ll see each as a proportion\n\nggplot(players,\n       aes(x = positions, fill = a_in_name)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nIt looks as though the proportions are much the same.\n\n\nGeneralised linear models\nWe’ll finish by looking at Generalised Linear Models. The distributions they include are\n\nBinomial\nPoisson\nGaussian (Normal)\nGamma\nInverse Gaussian\nA few quasi options\n\nWe’ll use the binomial option to create logistic regressions.\nLogistic regressions examine the distribution of binary data. For us, we can compare the heights of goalkeepers vs non-goalkeepers again.\nNow, we can model this column with height. We’ll do the same as our \\(t\\)-test case, but this time we need to specify that family = binomial to ensure we’ll get a logistic:\n\nres_logistic &lt;- glm(gk ~ height_cm, family = binomial, data = players)\n\nWe can take a look at the results with\n\nsummary(res_logistic)\n\n\nCall:\nglm(formula = gk ~ height_cm, family = binomial, data = players)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -53.23360    1.92714  -27.62   &lt;2e-16 ***\nheight_cm     0.27448    0.01019   26.94   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4401.4  on 5931  degrees of freedom\nResidual deviance: 3167.0  on 5930  degrees of freedom\nAIC: 3171\n\nNumber of Fisher Scoring iterations: 6\n\n\nAnd we can then visualise it with ggplot2. We need to make another variable, because we need to replace TRUE \\(\\rightarrow\\) 1 and FALSE \\(\\rightarrow\\) 0 for the plot.\n\nplayers &lt;- players %&gt;% mutate(gk_numeric = as.numeric(gk))\n\nNow we can plot the logistic regression. The fitted values (on the \\(y\\)-axis) are stored in res_logistic$fitted.values, but there are no provided \\(x\\)-values - these come from the players dataset. Use geom_point() for the data and geom_line() for the fit:\n\nggplot(players, aes(x = height_cm, y = gk_numeric)) + \n  geom_point() + \n  geom_line(aes(y = res_logistic$fitted.values))",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html",
    "href": "qgis/Essentials/2 - Vector Analysis.html",
    "title": "Vector Analysis",
    "section": "",
    "text": "In this workshop, we will learn about:\n\nImporting data from a CSV\nJoining Tabular data\nOverlaps/Intersections\nDigitisation\nPoint counts within a polygon"
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#what-are-we-going-to-learn",
    "href": "qgis/Essentials/2 - Vector Analysis.html#what-are-we-going-to-learn",
    "title": "Vector Analysis",
    "section": "",
    "text": "In this workshop, we will learn about:\n\nImporting data from a CSV\nJoining Tabular data\nOverlaps/Intersections\nDigitisation\nPoint counts within a polygon"
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#what-is-vector-data",
    "href": "qgis/Essentials/2 - Vector Analysis.html#what-is-vector-data",
    "title": "Vector Analysis",
    "section": "What is Vector Data?",
    "text": "What is Vector Data?\nVector data is made up of points, lines, and/or polygons. They are made up of precise points with individual coordinates. Vector data is best contrasted with Raster data which has a grid of values evenly spaced apart, connected to one coordinate. Rasters are efficient at displaying large amounts of data, where vector data is very precise.\nThe Map School has some useful explainers of what Vector data is."
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#what-are-we-doing-today",
    "href": "qgis/Essentials/2 - Vector Analysis.html#what-are-we-doing-today",
    "title": "Vector Analysis",
    "section": "What are we doing today?",
    "text": "What are we doing today?\nTo look at vector data, we’re going to use the example of koala populations and protected areas, and use some analyses to see how they interact. The QLD Government has set koala protection as a priority for the State, but how do their priorities match up with the data? We can use QGIS and spatial analysis to ask questions of the data."
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#gather-some-data",
    "href": "qgis/Essentials/2 - Vector Analysis.html#gather-some-data",
    "title": "Vector Analysis",
    "section": "Gather some data",
    "text": "Gather some data\nWe’re going to explore a number of different online spatial data repositories. Please download the full dataset here, and extract it into the qgis_vector folder you created earlier.\n\nIn the zip file of today’s data we have already trimmed it down to just QLD to save on file size\n\n\nData Summary\nYou should have:\n\nPoint data for analysis\n\nKoala Sightings\n\nBoundary Files to spatially categorise our data\n\nKoala Priority Areas\nProtected Areas\nSA2 Areas (with human population)"
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#load-in-our-data",
    "href": "qgis/Essentials/2 - Vector Analysis.html#load-in-our-data",
    "title": "Vector Analysis",
    "section": "Load in our data",
    "text": "Load in our data\nFor most of our data, we will simply be able to double click on it in the Project Home folder within the Browser window. When you load in this data, QGIS will give you a warning that your Project Projection is different to the data you’re importing. Simply click cancel on this window. We will be fixing this issue later. Make sure your Project Projection remains as EPSG:7856.\nLoad in:\n\nSA2_ERP_2021_QLD.gpkg (suburb data)\nCAPAD2020_terrestrial_QLD.gpkg (Protected Areas)\nkoala_priority_area.gpkg\n\nBut what about the Koala Encounters location data? We need to handle this differently, as it is currently not in a spatial format, but in a csv file.\n\nImporting CSV data\n\nGo to Layer &gt; Add Layer &gt; Add Delimited Text Layer...\nClick the three dots ... next to the File name field, navigate to the project folder, and select koala_reduced\nClick the Geometry Definition drop down\n\nThis should automatically identify decimalLongitude and the X field, and decimalLatitude as the Y field.\nYou may need to set the Geometry CRS. For this data from the ALA it is EPSG:4326 - WGS84\n\nClick Add\n\n\nIt’s usually the case that data like this is in EPSG:4326 - WGS84, as that is the standard used by most GPS units and Google Maps. However, it’s still worth checking those details on the website you’ve downloaded it from. If your data doesn’t come with a predefined projection, and the spatial portal doesn’t specify, but it uses a Google Maps style interface, it’s probably using EPSG:4326 - WGS84"
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#tabular-data",
    "href": "qgis/Essentials/2 - Vector Analysis.html#tabular-data",
    "title": "Vector Analysis",
    "section": "Tabular data",
    "text": "Tabular data\nQGIS can deal with plain tabular data. For example, try importing the file HDI.ods: it doesn’t contain any coordinates, but we can still store it as a layer and use it in our project. You can see the data it contains by opening its attribute table.\nHow can we add the Human Development Index (HDI) data to our existing “admin” shapefile?\n\nJoining tabular data\nTo add the HDI data to our region shapefile, we can go the the “admin” layer’s properties, use the  Joins tab and click the Add new join button  to create a new join. We can then choose the HDI data as the Join layer, and define what common field between the two tables we will merge on: the ISO_3166_2 code in our case.\nYou can now see the joined data highlighted in green in the Fields tab, click “OK”, and check the actual values in the “admin” layer’s attribute table."
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#subset-our-sa2-data-down-to-seq---select-features-using-an-expression",
    "href": "qgis/Essentials/2 - Vector Analysis.html#subset-our-sa2-data-down-to-seq---select-features-using-an-expression",
    "title": "Vector Analysis",
    "section": "Subset our SA2 data down to SEQ - Select features using an expression",
    "text": "Subset our SA2 data down to SEQ - Select features using an expression\nThe following code will allow you to select the SA2 features that are in SEQ.\n\nRight click on the reprojected SA2 layer, and select Open Attribute Table\nFrom the Attribute Table that opens, click the Select features using an expression button: \nIn the Select by Expression window that opens, paste the code from below into the Expression field, and then click Select Features in the bottom right of the window.\n\n \"SA4_name_2021\" =  'Gold Coast' \n OR\n \"SA4_name_2021\" =  'Sunshine Coast' \n  OR\n \"SA4_name_2021\" =  'Toowoomba' \n OR\n  \"GCCSA_name_2021\"  LIKE  '%Brisbane%' \n\nThis is SQL code, which is great for querying databases. This code selects any row that matches any of the criteria (this OR that). The first three look for exact matches, the last one looks to match the pattern given. The % acts like wildcard, so it’s looking for any row that contains Brisbane.\n\n\nClose the Select by Expression window and Attribute Table\nYou should see the SEQ SA2 areas highlighted in yellow (you may need to turn off other layers or zoom in).\nTo permanently save this selection, right click on the reprojected SA2 layer, and select Export &gt; Save Selected Features As...\nSave your file as SA2_SEQ\nMake sure the CRS stays as EPSG:7856 - GDA2020 / MGA zone 56, then click OK\n\nIf you haven’t done so already, untick and hide all the original layers we aren’t using any more."
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#analysis-spatial-overlaps",
    "href": "qgis/Essentials/2 - Vector Analysis.html#analysis-spatial-overlaps",
    "title": "Vector Analysis",
    "section": "Analysis: Spatial Overlaps",
    "text": "Analysis: Spatial Overlaps\nLet’s find out how much of our Koala Priority areas are already under federally recognised protection. To do this we will use the Intersection tool. This tool is similar to the Clip tool, but rather than just cutting out the overlapping area, it also combines the Attribute Tables of the two layers.\n\nIntersection\n\nGo to Vector &gt; Geoprocessing Tools &gt; Intersection\nUnder Input Layer select CAPAD_Reproj\nUnder Overlay Layer select KPA_Reproj\nClick Run\n\nWe get an error Feature (26) from “CAPAD_Reproj” has invalid geometry. This is caused by little issues in the polygon layer. Sometimes when polygons are drawn or exported from online sources, they will create errors, and sometimes little slither polygons on the edges. We can investigate the source of these errors using the Check validity tool, but for today, we’re simply going to fix them with the Fix Geometries tool from the Processing Toolbox.\n\n\nFix Geometries\n\nOpen the Processing Toolbox by clicking the cog icon from the top menu  (alternatively go to View &gt; Panels &gt; Processing Toolbox)\nIn the Processing Toolbox window Search for “Fix geometries”\nDouble-click on the Fix geometries option\nIn the Fix Geometries window, select CAPAD_Reproj from the Input layer options, then click Run\nRight click Fixed Geometries in the Layer panel, click Rename Layer, and change it to CAPAD_Fixed\n\nYou can now re-run the Intersection tool with the resulting CAPAD_Fixed layer (instead of the CAPAD2020_terrestrial_QLD layer)\n\nGo to Vector &gt; Geoprocessing Tools &gt; Intersection\nUnder Input Layer select CAPAD_Fixed\nUnder Overlay Layer select KPA_Reproj\nClick Run\n\nMagic. Our new layer with be the thin overlap between our two original layers, and will have their shared Attribute Tables. However, this is a double-edged sword, as it has retained the Area columns of the original CAPAD polygons. If we want to know our new shape’s area, we need to calculate that.\n\n\nField Calculator\nWe can use the Field Calculator to calculate the area of our polygon.\nSelect Intersection from the Layers panel, and the click the Open Field Calculator button \nIn the Field calculator window, type the following code into the Expression tab:\nsum($area)\n\n$area will give us the area of a single polygon - we could use this to create a new field in our Attribute Table based on area if we wanted to\nsum() will add together the area for every polygon in that layer.\nBelow the text box, you will see a field titled Preview:, the value following that contains the results of our expression. Copy that number.\nClick Cancel\n\nDo the same Field Calculator steps for the original koala_priority_area.\nYou can now use the Field calculator to determine the percentage of the Koala Priority area which is currently protected. 1506573200.936991 / 5776218019.211894 = 26%\nOnly 26%! Let’s look into this further. Perhaps our dataset is missing some new conservation areas.\nLet’s turn on the OpenStreetMap to see if we can see anything missing here. Let’s have a look at the dense collection of koala sightings near Springwood and the Daisy Hill Conservation Park (if you can’t find them, paste these coordinates -27.581128,153.176828 into the Coordinate box at the bottom of the window, and change the Scale to 1:10000). We can see that there are some protected bushlands in this area that aren’t in our CAPAD2020 dataset. It may be that these aren’t strict enough conservation areas, or our dataset may be out of date. Regardless, this gives us a good opportunity to use an important tool in GIS: Digitisation."
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#map-digitisation",
    "href": "qgis/Essentials/2 - Vector Analysis.html#map-digitisation",
    "title": "Vector Analysis",
    "section": "Map Digitisation",
    "text": "Map Digitisation\nYou may often need to create your own points, lines, and polygons when digitising satellite data, or simply highlighting a particular area. Let’s use the OpenStreeMap (in Browser, scroll down to XYZ Tiles, and double-click on OpenStreetMap) and digitise the Emu Street Bushland Refuge.\n\nGo to Layer &gt; Create Layer &gt; New GeoPackage Layer...\nClick the three dots ... next to the Database section\nNavigate to your data &gt; processed folder and save the file as ESBR_polygon\nFrom Geometry type select MultiPolygon\nMake sure the CRS is set to EPSG:7856 - GDA2020 / MGA zone 56\nLeave the other fields blank for now and click OK\n\nWe now have a brand new layer that we can add polygons to.\n\nSelect the new ESBR_polygon layer and then click the Toggle Editing pencil  from the top menu (or go to Layer &gt; Toggle Edititng\nOn your keyboard, press Ctrl + . (or click  Add Polygon Feature) to start adding a new polygon\nZoom in to a corner of the area you want to create the polygon, and then Left click to start drawing your polygon (You can use the mouse wheel to zoom in, and also press and drag on the mouse wheel to navigate)\n\nA red dotted line will now appear between that first point and your cursor.\n\nContinue adding points to your polygon until your return back to the start, Right click to stop digitising and create your polygon.\nLeave the fid as Autogenerate and click OK\nTo save what you’ve done, click the Save Layer Edits button next to the Toggle Editing button\nTo finish editing your layer click the Toggle Editing button\n\nYou now know how to digitise a polygon, but the same steps apply for creating a point or a line layer. We created a new layer here, and you can also do the same steps to edit a pre-exisitng layer too.\nThe Vertex Tool  will allow you to move the location of points (or corners of polygons) that you have already created (you also need to click the Toggle Editing button for this tool)\nDespite these missing Refuge area polygons, you can still see that there are a lot of koalas which are found outside of protected areas. In fact, most sightings seem to occur outside of protected areas! Is this poor protected area management, or might our data be biased by when and where people are more likely to encounter koalas?"
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#analysis-how-do-koalas-and-people-overlap",
    "href": "qgis/Essentials/2 - Vector Analysis.html#analysis-how-do-koalas-and-people-overlap",
    "title": "Vector Analysis",
    "section": "Analysis: How do koalas and people overlap?",
    "text": "Analysis: How do koalas and people overlap?\n\nCount Points in Polygons\nEarlier we looked at overlap between polygons, we can also look at points overlapping with a polygon. Let’s use the Count Points in Polygons tool to quickly count the number of points from a particular layer inside a polygon. We could look at a few things here, we could look at koala sightings in protected areas or in the priority areas, but let’s try to get an idea of how people and koala sightings overlap. You would expect there to be more koalas where there are fewer people, but perhaps our data is skewed by population levels.\nLet’s determine how many koalas are inside of each SA2 suburb.\n\nGo to Vector &gt; Analysis Tools &gt; Count Points in Polygons...\nIn the Polygons field select SA2_SEQ\nIn the Points field select Koalas_Reproj\nIn the Count field name field type in something like NUM_KOALAS\nClick the three dots ... next to the Count section, and click Save to File…\nNavigate to your processed folder and save the file as SA2_SEQ_koalas\nClick Run\n\nIf it’s being really slow, we might be able to benefit from the Fix Geometries tool again.\n\nClick Cancel in the Count Points in Polygons window, but leave it open for now\nIn the Processing Toolbox double-click on the Fix geometries option\n\nFor Input Layer choose Koalas_Reproj\nClick Run\n\nReturn to the Count Points in Polygons window, click Change Parameters\nChange the Points to the new Fixed geometries layer\nClick Run\n\nYou can now look at the Attribute Table (F6) for this layer to see the number of koala sightings in each suburb. Let’s visualise this.\n\nClick on the SA2_SEQ_koalas layer in the Layers panel\nOpen the Layer Styling Panel by pressing F7 (or fn + F7)\nChange the Symbology from Single Symbol to Graduated\nSet the Value to NUM_KOALAS\nChoose a Color ramp of your liking\nClick Classify\nYou might want to play with the Mode to get a feel for the data\n\nNow we can quickly see how many Koalas are in each suburb.\nWe can go further and use the Field Calculator to compare koala numbers to the current human population in that area, and create a new field with that information.\n\nClick on the Field Calculator button \n\nUnder Create a new field set the Output field name to KOALAS_PP\nSet the Output field type to Decimal number (real) (we need to choose this option to ensure that we have decimals in our output)\nIn the Expression tab enter \"NUM_KOALAS\" / \"ERP_2021\"\n\nERP stands for Estimated Resident Population\n\nClick OK\n\nNow you can change the Value in Layer Styling to KOALA_PP\n\nClick Classify again if needed\n\n\nWe can now see how koala populations compare with human populations."
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#wrap-up",
    "href": "qgis/Essentials/2 - Vector Analysis.html#wrap-up",
    "title": "Vector Analysis",
    "section": "Wrap up",
    "text": "Wrap up\nToday we explored projections, looked at a variety of data sources, questioned the quality of our data, used the Intersection tool, the Field Calculator, digitised a map, and used polygon point counts.\nAfter running these tests and analyses, do we feel that there is adequate protection and conservation areas for koalas in QLD? How might you show this?\nHow might you use these tools in your own analysis?"
  },
  {
    "objectID": "qgis/Essentials/2 - Vector Analysis.html#feedback",
    "href": "qgis/Essentials/2 - Vector Analysis.html#feedback",
    "title": "Vector Analysis",
    "section": "Feedback",
    "text": "Feedback\nPlease visit our website to provide feedback and find upcoming training courses we have on offer."
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html",
    "title": "Data Sources and Projections",
    "section": "",
    "text": "In this workshop, we will learn about:\n\n\n\nWhy we have them and what goes wrong without them\nGCS vs PCS\nLocal Projections\nArea Calculation differences\n\n\n\n\n\nLocal, State, Federal Gov Data\nInternational\nNGO\nCorporate (ESRI, etc)\nWMS etc"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#what-are-we-going-to-learn",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#what-are-we-going-to-learn",
    "title": "Data Sources and Projections",
    "section": "",
    "text": "In this workshop, we will learn about:\n\n\n\nWhy we have them and what goes wrong without them\nGCS vs PCS\nLocal Projections\nArea Calculation differences\n\n\n\n\n\nLocal, State, Federal Gov Data\nInternational\nNGO\nCorporate (ESRI, etc)\nWMS etc"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#what-are-projections",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#what-are-projections",
    "title": "Data Sources and Projections",
    "section": "What are Projections?",
    "text": "What are Projections?\nThis content is currently in Vector and in Field Work."
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#projections-1",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#projections-1",
    "title": "Data Sources and Projections",
    "section": "Projections",
    "text": "Projections\n\nWhat are projections?\nTo turn the geoid/spheroid shape of the Earth into a flat map, we need to squish, stretch, and distort the map to make it flat. The mathematical equations used to do this are what we’re talking about when we say “projections”. Imagine it like a soccer ball, if we have to squash it to make it flat, it’s not going to look nice and square like our maps do. So we pull and stretch it to make it flat and rectangular. There will always be some kind of distortion when we stretch our map like this. This is why the Mercator Projection makes Greenland look large, and Africa look smaller than it really is.\n\n\nWhy are projections important to us?\nWell, when we make these distortions, we have to compromise somewhere, and that means our lengths, or size or direction will be different to what it really is. To avoid this kind of distortion, often local projections are used. There are fewer compromises needed when focused on a small area. By using a local projection, we don’t need to worry about keeping Greenland looking the right shape if we’re focused on Brisbane. Going back to Soccer balls, if we cut out a single panel from the ball, it will be much easier to make that flat.\nThe trouble with using data of different projections is that they might be slightly off around the edges, giving us different total areas in a polygon, or showing a point outside a boundary, when it’s really inside. To avoid this, it’s often best to convert all of your data to using the same projection.\nToday we’re going to use a suitable local projection: EPSG:7856 - GDA2020 / MGA zone 56"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#set-the-project-projection",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#set-the-project-projection",
    "title": "Data Sources and Projections",
    "section": "Set the Project Projection",
    "text": "Set the Project Projection\nWe need to choose the projection for our current session of QGIS. Today we will be focusing on South East Queensland (SEQ), so we will choose GDA2020 / MGA zone 56. We will go into projections in more detail soon.\n\nGo to Project &gt; Properties select the CRS tab.\nIn the filter section, type “GDA2020 56”\nFrom the Coordinate Reference System list, select EPSG:7856 - GDA2020 / MGA zone 56\n\n\nYou will notice that the OpenStreetMap basemap looks very warped, except for the East Coast of Australia. This is because the projection we have selected is very focused on reducing distortion within the bounds of the projection’s area (Eastern Australia).\n\n\nReproject\nFor each of our layers, do the following:\n\nGo to Vector &gt; Data Management Tools &gt; Reproject Layer...\nChoose the layer in Input layer\nSet the Target CRS to EPSG:7856 - GDA2020 / MGA zone 56\n\nIf that option isn’t available, click  (Select CRS), and type “GDA2020 56” into the filter, the option should now appear under the Predefined Coordinate Reference Systems section.\n\nClick the three dots ... next to the Reprojected section, and click Save to File…\nNavigate to your data &gt; processed folder and save the file there. For example, save SA2_ERP_2021 as SA2_Reproj, CAPAD2020_terrestrial_QLD as CAPAD_Reproj, koala_reduced as Koalas_Reproj and koala_priority_area as KPA_Reproj\nClick Run\n\nYou won’t notice any difference, as QGIS is helpfully doing “on the fly projections” to make the layers sit nicely together. But now that you’ve reprojected your data, you can safely do your analyses."
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#council-data",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#council-data",
    "title": "Data Sources and Projections",
    "section": "Council Data",
    "text": "Council Data\nSunshine Coast MyMaps"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#federal-data",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#federal-data",
    "title": "Data Sources and Projections",
    "section": "Federal Data",
    "text": "Federal Data\nCSIRO’s Norfolk Island Data Portal CSIRO spatial products."
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#raster-data",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#raster-data",
    "title": "Data Sources and Projections",
    "section": "Raster Data",
    "text": "Raster Data\n\nDEM\nA Digital Elevation Model (DEM) is a common example of raster data, i.e. grid data that contains a value in each cell (a bit like the pixels in a coloured picture).\nFor this tutorial, we are using a DEM sourced from ELVIS - Geoscience Australia’s ELeVation Information System.\n\nGo to http://www.ga.gov.au/elvis/\nSearch for “St Lucia” in the Location Search search box and select the first result\nClick Order Data\nChoose “Draw” and “Box” and then click the Draw button\nClick on the map to start drawing a rectangle around your desired area\nThen click Search\nThe right panel will show you all the different datasets available in that area\nWe want the QLD Government Digital Elevation Model 1 Metre, click the down arrow on the right\nAs you hover over the different options, they will highlight a red box on the map, click the tick box and select all that overlap the area you’re interested in (note that there may be data from different years here)\nWhen you have the data you want, scroll to the bottom of the Order Data window\nSelect your industry, enter your email, tick the reCAPTCHA, and click the Order Datasets button\nYou should receive an email within 5 minutes, download the files from the link in the email, extract the folder to your project folder, and add them to your map.\n\n\n\nAerial Imagery\nThere are a few places you can aquire aerial photography, today we will look at two sources, one is freely available Government Data, the other is accessible from using your UQ credentials.\nAs a UQ student, you also have access to very high resoltuion imagery from NearMap. You can even access an array of imagery going back in time.\n\nGo to the UQ NearMap Portal\nEnter your UQ Student (@student.uq.edu.au) or Staff (@uq.edu.au) email address, with the appropriate domain selected. Click “Invite me”.\nYou should receive an email soon after, click the “Accept Invitation” button, and go through the account setup process.\nGo to Login and enter your email address, click “Next” and enter your password.\nFrom the top right select MapBrowser.\nType “St Lucia, QLD” in the search box, press enter\nYou can click the date down the bottom to look at different snapshots in time, and even compare maps side-by-side.\nTo save imagery from NearMap, simply click the “Exports” button on the left handside (it is an image icon)\nFrom the menu that appears change the “Export type” to “Georeferenced image”\nFrom “Projection” choose GDA2020 / MGA zone 56\nYou can increase and decrease the size of the bounding box by adjusting its corners, a smaller box means you can have a finer resolution, down to 0.075m. If we select all of UQ St Lucia in one go, the highest resolution we can have is 0.299m.\nOnce you’re happy with your selection click Download Files\nMove the downloaded zip file to your project folder, and open them in QGIS"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#more-data-sources",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#more-data-sources",
    "title": "Data Sources and Projections",
    "section": "More Data Sources",
    "text": "More Data Sources\n\nAerial Imagery\nThere are a few places you can aquire aerial photography, today we will look at two sources, one is freely available Government Data from QImagery, the other is accessible from using your UQ credentials.\n\nGo to QImagery\nRead and tick the “I acknowledge I have read and agree to the Terms & Conditions” box, and click Get Started\nClick the Search button, select ‘locality, town or city’ and search for “St Lucia” in the “Enter search term” search box and select the first result\nIt will zoom to your selected location then click the newly appeared Search button\nFrom here you can select from a wide array of images of QLD over many years.\nClick one of the drop-downs and hover over the options to see where those images are located. Preview the image by clicking View.\nYou can then download your desired images by clicking “Download” and selecting TIFF (georeferenced)\nMove the TIFF file(s) to your project folder, and open them in QGIS\n\nYou can also get historical images from Geoscience Australia’s Historical Aerial Photo (HAP) Collection"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#basemaps",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#basemaps",
    "title": "Data Sources and Projections",
    "section": "Basemaps",
    "text": "Basemaps\nLet’s start by making a map we might use in an Academic Paper or in an Article for the Public, where we want to focus their attention on our data. Unless we really need Satellite imagery, or everything on the OpenStreetMap, it is too busy and distracting.\n\nLet’s load in a new basemap.\n\nThere are many ways of doing this, in the past we’ve used the QuickMapServices plugin to load in new basemaps, now we can go to the next step and source them externally. We can do this with WMTS (Web Map Tile Service), WCS (Web Coverage Service), ArcGIS REST Servers, and XYZ Tiles.\nToday we’re going to use an XYZ Tile from CARTODB.\n\nScroll down the Browser panel until your see XYZ Tiles\nRight click XYZ Tiles and select New Connection...\n\nIn Name type Voyager (no labels)\nIn URL paste:\nhttps://a.basemaps.cartocdn.com/rastertiles/voyager_nolabels/{z}/{x}/{y}@2x.png\nIncrease the Max. Zoom Level to 20\n\nThis value depends on what is available from the given service in different parts of the world. Increasing that value beyond 20 for this map in Brisbane will show “Map data not yet available” when you zoom in very close.\n\nClick OK\n\nIn the Browser panel, expand XYZ Tiles and double click on Voyager (no labels)\nNow do the same for this Light Gray Basemap from ESRI, but set the Max. Zoom Level to 16:\nhttps://services.arcgisonline.com/arcgis/rest/services/Canvas/World_Light_Gray_Base/MapServer/tile/{z}/{y}/{x}\n\nArrange the layers so that the Voyager (no labels) layer is under your other layers (you can hide the Light Gray Basemap and OpenStreetMap for now).\nIsn’t that much less visually busy?!\n\nMore Web Mapping Services\nAdd any of these URLs via ArcGIS REST Servers in QGIS\nQLD Gov Aerial Basemap\nQLD Gov Roads\nQLD Heritage Areas\nMore QLD Gov Services\nBrisbane/SEQ Utilities\nBCC Data\nRandom User’s Data\n10000+ Searchable Feature Layers from ArcGIS\nNearMap API"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#vector-data",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#vector-data",
    "title": "Data Sources and Projections",
    "section": "Vector Data",
    "text": "Vector Data\n\nLot Plans\nYou can access a wide variety of QLD Government Data, including Spatial Data such as lot plans and vegetation maps, from QLD Spatial. There are three ways to access this data. You can download all of it, you can select a portion for download, or you can live load it into your project. Today we download the files covering our project area.\n\nTo access data from QLD Spatial go to https://qldspatial.information.qld.gov.au/\nSearch for “property boundaries”\nScroll down to “Property boundaries Queensland” and click Add to my list\nClick My List from the top menu\nClick View/extract in map\nUnder Extractable Data, click the box next to Property boundaries Queensland, it will become green\nClick Extract/download\nClick Choose an area\nSelect BRISBANE CITY from the Select LGA option\nChoose GeoPackage 1.0 from Select output format\nEnter your Email Address\nAccept the Terms and Conditions\nClick Extract/Download\nYou can can also just download the preprepared data here, just press the three dots and download.\nMove the downloaded zip file to your project raw data folder, and open the shapefile in QGIS\n\n\n\nQueensland Globe\nAnother way to access QSpatial Data is using the Queensland Globe portal.\n\nTo access data from Queensland Globe go to https://qldglobe.information.qld.gov.au\nAccept the T&Cs.\nClick Search, Select Locality (Suburb) within a Local Government Area, and search for the location you want and select it from the list.\nClick Layers, click Add Layers + here you can scroll through and filter different layer types\nWe want to tick the box next to Planning Cadastre &gt; Land Parcels &gt; Land Parcel (you may need to zoom in to see certain layers)\nTo export data click the Wrench Icon in the top right, and then click the Identify icon (i)\nUse the triangular Identify Polygon tool to select and area of interest. Double click when you’ve finished selecting your area.\nThe Layers menu will now show your selection. You can download all, or sections, of your selection.\nI will choose Land Parcel and then Download as a shp file.\nNote: You may need to disable other layers for this to work correctly. I needed to turn off the Transportation layer to prevent roads from being included in my selection.\n\n\n\nOnline Community Spatial Repositories\n\nKoala Sighting Data (encounters)\nIf we’re looking at Koalas, we should get some occurence/sighting data.\nWe’re getting our species observation data today from the Atlas of Living Australia. This is an Australia Biodiversity occurrence database. It pulls data from a variety of different sources, including government data, individual collectors and community groups. This means that this data will contain sampling bias and will often simply represent encounters, rather than using robust sampling and collection methods. So, while we need to use this data with caution, it’s still a useful dataset!\nYou need to create an account and request the exact dataset you need, so to speed things up today, we’ve provided the data already cleaned and processed the data in the download link above.\nSome similar online repositories include the Global Biodiversity Information Facility (GBIF) and iNaturalist\n\n\nCleaning and processing the ALA data\nWhat do we mean by processed? Well, the ALA dataset has 206 columns by default. This means that each occurrence has 206 associated cells, and when multiplied by ~200,000 sightings, our data gets huge (&gt;300mb!). To save time (and storage space!) today we have already deleted 200 of those columns (bringing the dataset down to 15mb).\n\n\n\nQLD Government Spatial Data\nWe’ve seen the QSpatial data portal in previous sessions, and today we will be getting two lots of data from here.\n\nKoala Priority Areas\nKoala Priority Areas are areas in SEQ which have been identified as key areas for conservation as part of the South East Queensland Koala Conservation Strategy 2019-2024. You can search for “Koala Priority Areas” in QSpatial, or by going directly to the data.\nLet’s get a resource to compare with these QLD government priority areas…\n\n\n\nFederal Environment Data\n\nProtected Areas\nThe Federal Environment Department has a variety of different spatial datasets that you can browse through. Today we are going to be using the Collaborative Australian Protected Areas Database (CAPAD) 2020, which is a compilation of government, Indigenous and privately protected areas for Australia. You can search for “CAPAD” in on the Environment Department website, or by going directly to the data.\nFinally let’s get some data to put all of our protected areas and observations into context…\n\n\n\nAustralian Bureau of Statistics Data\nThe ABS is a huge source of data, however, it can be a bit difficult to find that data, and use it in a spatial context.\n\nDigital Boundary Files - SA2 - Suburb data\nThe ABS has a variety of ways that it splits its data up. These Digital Boundary Files are very useful for classifying data. They generally classify all of Australia into discrete Statistical Areas. Level 1 are the smallest, and Level 4 are the coarsest. (notably, the link above also has non-ABS Structures/boundary files such as Electoral areas and Postcodes). Today we are going to use the Statistical Area 2 data, which effectively represent suburbs, but we can take it a little further with more ABS data.\n\nPopulation Data\nThe ABS have a lot of useful data, today we will be using their population data. They provide it in excel format, as GeoPackages (by SA2 and LGAs), and as population grid raster files. Today we will be using their SA2 GeoPackages. This means we have our digital boundaries, and population in one!"
  },
  {
    "objectID": "qgis/Essentials/3 - Data Sources and Projections.html#get-some-elevation-data",
    "href": "qgis/Essentials/3 - Data Sources and Projections.html#get-some-elevation-data",
    "title": "Data Sources and Projections",
    "section": "Get some elevation data",
    "text": "Get some elevation data\nFor this tutorial, we are using a DEM sourced from the USGS website.\n\nGo to https://earthexplorer.usgs.gov/\nClick the World Features box, and then search for “Brisbane” in the “Feature Name” search box\nClick Show and select the first result\nZoom onto an area of interest around Brisbane and click “Use Map”\nClick the “Data Sets” button and then Digital Elevation &gt; SRTM, select “SRTM 1 Arc-Second Global” and click “Results”\n\n“SRTM” stands for “Shuttle Radar Topography Mission”. It provides global elevation data collected in 2000 by the space shuttle Endeavour.\nOur area covers two separate raster files. We can click on the foot icon to see the footprint of each file, and the picture icon to see what the DEM looks like."
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html",
    "title": "Styling Themes and Templates",
    "section": "",
    "text": "Main aims:\n\nCreate a pretty map for output\nAutomate our map description\nUse templates\n\nIf we have time:\n\nLearn to use Web Mapping Services\nGeoreference an Image"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#todays-learning-goals",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#todays-learning-goals",
    "title": "Styling Themes and Templates",
    "section": "",
    "text": "Main aims:\n\nCreate a pretty map for output\nAutomate our map description\nUse templates\n\nIf we have time:\n\nLearn to use Web Mapping Services\nGeoreference an Image"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#the-brief",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#the-brief",
    "title": "Styling Themes and Templates",
    "section": "The Brief",
    "text": "The Brief\nWe need to use our spatial files to make a map that:\n\nShows the project outline\nShow the access paths\nCategorises the artefacts\n\nThe current map in our project does accomplish these goals, but it’s not inviting to look at.\nTo fix this, we need to ask some questions:\nWho is the intended audience for our map?\n\nA good looking map for a Report map may look different to an Academic Paper or a Technical map or to a map for the Public.\n\nWhat story am I trying to tell?\n\nDo you want to highlight a particular pattern in the data?\n\nYou can use shapes and colour (esp. saturation) to bring your viewer to focus on certain elements of the map.\n\nDoes it need to look friendly or more professional?\n\nYour choice of a colour palette can bring cohesion to your map.\n\nDo you have a lot of dense information you need to convey?\n\nPerhaps you need to make more than one map.\n\nDo you need to show what the land surface looks like, or not?\n\nThat brings us to our next question:\n\n\nWhat basemap does my map need?\nThe basemap sets the tone for the rest of the layers in the map, as they can greatly change the visual complexity of the map.\n\nSatellite image - Geographically informative, but visually busy\nStreet map - Geographically informative, but visually busy\nHistorical image - Informative and busy, but black and white imagery can be less visually busy\nSimple topo map - Provides some information, but less visually busy\nNo basemap - Centres focus on data, but provides no geographic context"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#basemaps",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#basemaps",
    "title": "Styling Themes and Templates",
    "section": "Basemaps",
    "text": "Basemaps\nLet’s start by making a map we might use in an Academic Paper or in an Article for the Public, where we want to focus their attention on our data. Unless we really need Satellite imagery, or everything on the OpenStreetMap, it is too busy and distracting.\nLet’s load in a new basemap.\nThere are many ways of doing this, in the past we’ve used the QuickMapServices plugin to load in new basemaps, now we can go to the next step and source them externally. We can do this with WMTS (Web Map Tile Service), WCS (Web Coverage Service), ArcGIS REST Servers, and XYZ Tiles.\nToday we’re going to use the Voyager (no labels) XYZ Tile from CARTODB and Light Gray Basemap from ESRI.\nIsn’t that much less visually busy?!"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#colours",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#colours",
    "title": "Styling Themes and Templates",
    "section": "Colours",
    "text": "Colours\nThe random colours that QGIS gives you aren’t always pretty, so let’s change the colours.\nChoosing a colour palette can be difficult and overwhelming, but once you have one, you can keep using those colours to form a more harmonious looking map. What story are you telling? Do you want your map to be bright and saturated, or warm and earthy?\nThe built in color ramps provide some good options I quite like rainfall (in Precipitation), Set1 (in QGIS), and wiki-knutux (in Topography).\nToday we’re being fancy, we’re going to import and build our own Color Ramp and Color Palette.\n\nIn your internet browser, navigate to colorbrewer2.org\n\nSet “Number of data classes” to 7\nSet “Nature of data classes” to “qualitative”\nChoose Set2 (should be the second from the right)\nClick and drag to highlight the 7 HEX codes listed (they should look like this #66c2a5)\n\nCopy those with Ctrl + C (or Cmd + C)\n\n\nBack in QGIS navigate to Settings &gt; Options...\n\nClick the Colors from the left menu\nFrom the top right of the window click the ... button and select New Palette..., name it Report Palette\nAdd your copied colours by clicking Paste colors on the right\nClick the ... button again and tick the Show in Color Buttons box\nClick OK\n\n\nWe now have a custom palette we can use throughout our projects!\nUnfortunately we need to set up the Color Ramp separately.\n\n\nNavigate to Settings &gt; Style Manager...\n\nClick the  Add item button at the bottom and select Color Presets...\n\nSelect the colour that appeared there and remove it by pressing  Remove color at the bottom\nAdd your copied colours by clicking Paste colors\nClick OK\n\nChange the Destination to Default\nGive it a meaningful Name like Report Colour Ramp\nAdd the Tag Palettes\nTick Add to favourites (this means it will appear in the color ramp dropdown, and not just in the All Color Ramps section)\nClick Save\n\nClick Close\n\nYou can also use the Style Manager to edit the default options and Favorites that appear in the Layer Styling window.\nNow we’ve set up our colours, we can start using them!"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#change-the-symbology",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#change-the-symbology",
    "title": "Styling Themes and Templates",
    "section": "Change the Symbology",
    "text": "Change the Symbology\n\nPoint Geometry\n\nCategories\n\nSelect the Artefacts layer from the Layer Styling panel\nIn the Layer Styling panel, change Single Symbol to Categorized\nFrom Value select Artefact Type\nFrom Color ramp choose our Report Colour Ramp\nClick the Classify button\n\n\n\nSymbols\nWith the Voyager (no labels) basemap, we can reduce the complexity of our symbology to make a cleaner looking map.\nIf you want, you can change the properties of all symbols at once:\n\nSimply click in the white space below your symbol classes so that none are selected.\nIf you click on the button next to Symbol, it will take you to Symbol SettingsWARNING if you edit any individual symbols before this step, it will reset any changes you made to those individual symbols.\n\nTry increasing the size of the symbols to 3mm\nClick Simple Marker and change the Symbol layer type to Filled Marker\n\nNow click Simple Fill and change its Symbol layer type to Outline: Simple Line\nChange the Stroke width to 0.4\nThis gives our points a very clean and simple appearance\n\n\nClick the back arrow button next to Symbol Settings\n\nNow that we have a nice colour scheme, let’s give it a new shape.\n\nDouble click on the symbol of the Artefact Scatter\n\nClick Filled Marker - this will allow us to change many things including the shape of the marker\n\nFrom the bottom of the window select a shape, let’s go with the Triangle\n\n\nClick the back arrow button next to Artefact Scatter\n\n\n\n\nPolygon Geometry\nDepending on your map, you may want your polygon to remain solid, to be transparent, have hatched lines, or simply be an outline. As our project area has items inside it, but an unimportant basemap, we can use an outline with a slightly transparent background to bring focus.\n\nOpen the Layer Styling panel by pressing F7 (or fn+F7)\nSelect the Project_area layer from either the Layer Styling panel, or the Layers panel.\nUnder Fill, click Simple Fill\n\nSet the Stroke width to 0.8mm\nClick the dropdown next to Fill color and select orange from our Report Palette\n\nClick the colour again and change the Opacity to 15%\n\n\n\nThat’s nicer, but let’s make it fancy. Let’s add a dropshadow.\n\nClick the  Add symbology layer next to Fill to add another fill symbol\n(You can add as many of these as you like, you can even change this with Symbol layer type to Arrows, Hashed lines, Filled lines, and more.)\nClick the new Simple Fill\n\nChange Symbol layer type from Simple Fill to Outline: Simple Line\nSet the Stroke width to 3\nScroll to the bottom, tick Draw Effects, then click the  Customise effects button (The one next to “Enable symbol layer”, not the one in the “Layer Rendering” section!)\n\nUntick Source\nTick and select Drop Shadow\n\nChange the Blur Radius to 6mm\nChange the Opacity to 30%\n\n\nClick the back arrow button next to Effects Properties\n\n\n\n\nLine Geometry\nWe can make our lines stand out. Sometimes it can be as simple as picking a contrasting colour, changing the width, or adding more symbol layers (with dashes, or arrows, or horizontal lines).\nIn this case, we want to keep the attention on the point data, let’s keep the paths, but reduce their contrast.\n\nSelect the Paths layer from the Layer Styling panel\nUnder Line, click Simple Line\n\nChange the Color to a colour in your Report Palette that is different to your points, I’m going to use green\nIncrease the Stroke width to 0.4mm\n\nTo reduce the focus on the paths, in the Layers panel, drag the Paths layer below the Project_area layer"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#themes",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#themes",
    "title": "Styling Themes and Templates",
    "section": "Themes",
    "text": "Themes\nWe can use themes to create multiple looks for our map that we can easily swap between. Let’s create a theme for our Data Map\n\nClick the Eye icon (Manage Map Themes) at the top of the Layers panel, and click Add theme...\n\nLet’s name our new theme Data Main, and click OK\n\n\nNothing exciting has happened yet, let’s change the layers a little to see the power of Themes."
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#styles",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#styles",
    "title": "Styling Themes and Templates",
    "section": "Styles",
    "text": "Styles\nStyles work similarly to Themes, but instead of changing which layers are present, it changes between different Layer Styling options.\nIf you want to try different looks for a feature, but not have to undo everything, you can save them as Styles\n\nIn the Layers panel, Right click on Project_area &gt; Styles &gt; Rename Current...\n\nLet’s start by changing the name of our current style from default to Data Main\n\nLet’s create a new style, Right click on Project_area &gt; Styles &gt; Add...\n\nName the style Data Inset\n\nNow any Layer Style edits we do will be attached to the Data Inset style\n\n\nSelect the Project_area layer from the Layer Styling panel\n\nUnder Fill, click Simple Fill\nClick the Arrow Up on the right to move it above Simple Line\nChange the Fill color to an Opacity of 100%\nChange the Stroke width to 0.4mm\n\n\nNow we have a slightly different style to our Project_area that will look better in an inset map. We can edit this style and revert back to the original Data Main style whenever we like, we will explore how to use that with Themes next.\n\nThemes (again)\nNow that we’ve made some style changes, we can see what themes do.\n\nIn the Layers panel, hide the Voyager (no labels), Paths and Artefacts layers by unticking the boxes next to them.\nUnhide the Light Gray Basemap\n\n\n\nClick the Eye icon (Manage Map Themes) at the top of the Layers panel, and click Add theme...\n\nLet’s name our new theme Data Inset, and click OK\n\nNow, click the Eye icon again\n\nYou will see that there are two check box options at the bottom: Data Inset and Data Main\nYou can cycle between these two themes by choosing one or the other\nIf you want to update a theme, simply hide/unhide layers, change the layer Styles, go to Eye icon &gt; Replace theme... and then select the theme you want to overwrite.\n\nSave your project"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#layout-manager",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#layout-manager",
    "title": "Styling Themes and Templates",
    "section": "Layout Manager",
    "text": "Layout Manager\nNow we can prepare our map for export.\n\nNavigate to Project &gt; Layout Manager...\n\nUnder New from Template click Create, name the map Data Map\n\nThis will open the Layout Manager\n\n\nPage Properties\nBefore we do anything, let’s set up out environment.\n\nNavigate to Layout &gt; Page Properties..\n\nHere we can choose the size and orientation of our map.\nSize: A4 is often sensible, as it means you know the map will fit neatly into a report.\n\nHowever you may need to make the size suit the data, or the requirements of where you’re submitting the map\nWe’ll make ours 200x200\n\nOrientation: Portrait means you can have a full page map without rotating the page in your report. But some spatial layouts make more sense in Landscape. Use your judgement.\n\nToday we have manually changed the size, so this isn’t needed.\n\n\n\n\n\nGuides\nGuides seem unnecessary, but they make lining things up much much easier.\nWe will use a guide to place our map details.\n\nIn the right panel, click Guides\nClick  Add new guide under Vertical Guides (if your canvas is a Landscape, or you want your legend at the bottom, choose Horizontal Guides for this step)\nA new row should appear, click on the 0 and change it to 140\n\n\n\nMap\n\nAdd your map by clicking the map icon in the left menu, or navigating Add Item &gt; Add Map\n\nYour mouse will now be a +\nIf you hover over the top corner of the canvas, the mouse should snap to the corner\nClick and drag until your mouse snaps to the corner created by the bottom of the canvas, and the guide you added\n\nIn the Items panel on the right, double click on Map 1 and rename it Main\n\nGiving Items clear names makes this process much more straightforward\n\n\n\n\nScale\nOkay, we have our map, but it’s not zoomed in right. This is always a little tricky.\nYou could click the Move item content button on the left menu(or press C on your keyboard), as this would allow you to drag the map around internally, and zoom in with your scroll wheel. But there is an easier way!\n\nNavigate back to your qgis_reports window\n\nRight click on your Project_area layer and select Zoom to Layer(s)\n\nNavigate back to your Project Map window\n\nIn the right menu, click Item Properties\nYou will see these options: \nClick the first orange arrow button to Set Map Extent to Match Main Canvas Extent\nClick the third orange arrow button to Set Map Scale to Match Main Canvas Scale\n\nThe other buttons do the reverse\n\nI like to then round the Scale up to a nice round number from something like 3814 to 4000\n\nWhile you’re here, scroll to the bottom of the Item Properties, and tick the box for Frame, it adds a simple border to our map\n\n\n\nInset Map\nYou can add your inset map to the blank space at the side of you map canvas, or you can put it on top of you main map in unused space. We don’t have a lot of space around our map, so we’ll put it to the right. Guides are useful here too.\n\nIn the right menu, click Guides\n\nClick  Add new guide under Horizontal Guides twice\n\nIn the new row changethe 0 to 155\nIn the other new row change the 0 to 95\n\n\nAdd your map by clicking the map icon in the left menu, or navigating Add Item &gt; Add Map\n\nHover over the corner created by the top horizontal guide and the vertical guide, the mouse should snap to the corner\n\nClick and drag until your mouse snaps to the corner created by the side of the canvas, and the lower guide you added\n\n\nZoom out on the inset map, by selecting it from the Items tab and following the same approach as the Main map\n\nOr by using Move item content button on the left menu (or press C on your keyboard), clicking on the inset and using the scroll wheel\n\nIn the Items panel on the right, double click on Map 2 and rename it Inset\n\nNow we have our maps added, we can bring our themes into play again.\n\n\nThemes (again!)\n\nSelect Main from the Items panel\n\nIn Item Properties, you will see Layers section\nTick Follow map theme and from the dropdown change none to Main\nNow this map is linked to the Main theme and will only update when we change that theme, or the layers attributed to the theme\n\nRepeat this step for Inset\n\nThis is also a big advantage for using Styles, as the point is a better representation of our site on the inset map.\n\n\nText\nBefore we add any text, it’s worth thinking about what you want the font to be. You can manually set the font for each item in your Layout, or you can set the default font.\n\nNavigate to Settings &gt; Options\n\nFrom the left menu, select Layouts\nChange the default font to your preferred font. I’m going to select Sitka Text Semibold\n\n\n\n\nTitle\n\nAdd a text box to your map by clicking the Add Label icon in the left menu, or navigating Add Item &gt; Add Label\nClick and drag in the empty canvas below the map where you want to put your title\n\nIn the Item Properties panel remove the Lorem ipsum text, and add Brisbane Botanic Gardens\nUnder Appearance click the Font box to open the Label Font window\n\nChange the text size to 18, you can make other font changes here too\nClick the back arrow button next to Label Font\n\n\nIn the Items panel on the right, double click on Brisbane Botanic Gardens and rename it Title\n\nOkay, that’s a some fairly basic text, let’s do something interesting with the descriptive text.\n\n\nDynamic Text\n\nAdd another text box to your map by clicking the Add Label icon in the left menu, or navigating Add Item &gt; Add Label\n\nClick and drag in the empty canvas below the inset map\nIn the Items panel on the right, double click on “Lorem ipsum” and rename it Description\n\nIn the Item Properties panel remove the “Lorem ipsum” text and then enter:\n\nCreated by:\nDate:\nScale: 1:\nDatum:\nNormally we’d have to enter the details for each of these manually, but we can use Dynamic Text to do it for us\n\n\n\nIn the Item Properties panel, click next to Date:, so the cursor is sitting there\n\nUnder the Main Properties text box, click Dynamic Text &gt; Current Date &gt; Day/Month/Year (26/09/2025)\nThis will insert code that looks like this: [%format_date(now(), 'dd/MM/yyyy')%] which automatically adds today’s date\n\nNow repeat those steps for the rest:\n\nClick next to Scale: 1:\n\nClick Dynamic Text &gt; Map Properties &gt; Main &gt; Scale (4000)\n\nThe code will look like this: [%format_number(item_variables('Main')['map_scale'] which automatically adds the main map’s scale\n\n\nClick next to Datum:\n\nClick Dynamic Text &gt; Map Properties &gt; Main &gt; CRS Name (GDA2020 / MGA zone 56)\n\nThe code will look like this: [%item_variables('Main')['map_crs_description']%] which automatically adds the main map’s CRS\n\n\n\nUnder Appearance:\n\nSet the Horizontal margin and Vertical margin to 2mm\n\n\nLet’s add another text box for our sources, but we’ll make the font smaller\n\nAdd another text box to your map by clicking the Add Label icon in the left menu, or navigating Add Item &gt; Add Label\n\nClick and drag in the empty canvas below the inset map\nIn the Items panel on the right, double click on “Lorem ipsum” and rename it Sources\nIn the Item Properties panel remove the “Lorem ipsum” text and then enter:\n\nSources:\n\n\nClick next to Sources:\n\nClick Dynamic Text &gt; Layer Credits\n\nThe code will look like this: [%array_to_string(map_credits())%] which automatically adds the sources built in to some of the data used\nNote that this information lives in the Metadata (layer Properties &gt; Metadata &gt; Access under Rights) of the baselayers, and the layers we downloaded. Not all layers will necessarily have this information, and sometimes it’s very detailed and clunky. You can add this information in the layer’s metadata if it is missing.\nIt may be simpler to manually enter this to your map.\n\n\nUnder Appearance:\n\nSet the Horizontal margin and Vertical margin to 2mm\nClick Font\n\nSet the Size to 8mm\n\n\n\nYou could also add any extra text details such as the locality, disclaimers, or any other details needed.\n\n\nShapes\nWe can add a border around our layout. This isn’t necessary, but it looks nice! It also has greater customisability than the map frame options.\n\nAdd a rectangle to your map by clicking the Add Shape icon in the left menu, or navigating Add Item &gt; Add Shape &gt; Add Rectangle\n\nHover over the top left corner of the canvas, the mouse should snap to the corner\nClick and drag until your mouse snaps to the opposite corner of the canvas\n\nIn the Item Properties panel, click the box next to Style, this will take you to the Symbol Settings window\n\nClick Simple Fill\n\nChange Symbol layer type from Simple Fill to Outline: Simple Line\nIncrease the Stroke width to 1mm\nScroll to the bottom, tick Draw Effects, then click the  Customise effects button\n\nUntick Source\nTick and select Outer Glow\n\nChange the Spread to 0.8mm\nChange the Blur Radius to 2.5mm\nChange the Single color to Black\n\n\n\n\nIn the Items panel, change the name from &lt;Rectangle&gt; to Outline\n\nThen tick the lock box next to the Outline\nThis means it stays on top of everything else, but you won’t select it every time you click the map canvas\n\n\n\n\nLegend\n\nAdd a Legend your map by clicking the Add Legend icon in the left menu, or navigating Add Item &gt; Add Legend\n\nThe legend always has too much detail to start with. Let’s clean it up.\n\nIn the Item Properties panel, under Legend Items untick Auto update\n\nClick the drop down next to Artefacts, select the empty item, and then click the red – to remove it\nRemove the Imagery layers too\nRight click on Artefacts and select Hidden, we don’t need to see the group name\nDouble click on Project_area and rename it to Project Area\nDouble click on Paths – paths and rename it to Footpaths\n\nScroll down to Fonts and Text Formatting, under Item Labels click the Item font button\n\nChange the Size to 15\n\nScroll down to Symbol\n\nChangeSymbol width to 10\nChangeSymbol height to 12\n\n\n\nCustom Legend Symbols\nOkay, we have a legend, but let’s get really fancy with a custom polygon legend.\n\nSave your Layout\n\nLayout &gt; Save Project\n\nNavigate back to QGIS (it’s still open in another window)\n\nSelect the Project_area in the Layers Panel\nFrom the top toolbars open the  Field Calculator\n\nIn the Expression window paste geom_to_wkt($geometry)\nUnder the Expression window, right click on the text next to Preview: (it should start with “MultiSurface”\n\nSelect Copy Expression Value\n\nClose the Field Calculator\n\n\nBack in the Layout Manager, in the Item Properties panel, double click on Project Area\n\nUnder Patch, click the Shape box\n\nThere should be a large Shape box with some “Polygon” details inside. Delete this.\nPaste what you copied from the Field Calulator - it should be many lines\nBe careful to delete the single quotes ’ at the start and end of what you’ve just pasted in\nTick the Preserve aspect ratio box\n\nClick the back arrow button\n\nClick the back arrow button again\n\n\n\n\nNorth Arrow\n\nAdd a North Arrow to your map by clicking the Add North Arrow icon in the left menu, or navigating Add Item &gt; Add North Arrow\n\nClick and drag in the blank space under the map until you’re happy with the size of the arrow\nIn the Item Properties panel, under the SVG Images box, type arrow in the search bar\n\nChoose a North arrow you like\nScroll down to SVG Parameters\n\nSet the Fill color and Stroke color to Black\n\n\n\n\n\n\nScalebar\n\nAdd a scale bar to your map by clicking the Add Scale Bar icon in the left menu, or navigating Add Item &gt; Add Scale Bar\n\nYou can click and drag in the blank space under the map, although the scale bar size will be set in a moment\n\nIn the Item Properties panel:\n\nChange the Style from Single Box to Line Ticks Up\nScroll down to Appearance:\n\nChange the Label margin to 0mm\nChange Distance label placement from Above Segment Edges to Below Segment Edges\n\n\n\n\n\nFinessing\n\nGo to the Layout panel and scroll down to Resize Layout to Content\n\nSet the Top, Right, Left and Bottom Margin to 2mm\nClick Resize layout\nNow we can see the dark glow we added to the Outline, without interfering with our neat 200x200 layout\n\n\nSave your project.\n\nLayout &gt; Save Project\n\n\n\nExport options\nNow that we’re done we can export. Generally to PDF or Image. Today we will use image.\n\nLayout &gt; Export as Image...\n\nYou will see a popup warning about WMS servers. Some tile services have limits to the size of file you can export like this. If you exceed it, your basemap will be blank.\nClick OK\n\nNavigate to your project’s output folder, and give the file a meaningful name “Brisbane Botanic Gardens Map”, click Save\nThe Export resolution should automatically be a print quality 300dpi, and the width and height should match the page size we set at the beginning.\nClick Save\nNavigate to and open your file to make sure it worked!"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#save-a-map-template",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#save-a-map-template",
    "title": "Styling Themes and Templates",
    "section": "Save a Map Template",
    "text": "Save a Map Template\nThis is crucial! Save your hard work for next time!\n\nLayout &gt; Save as Template...\nNavigate to a folder you can easily find again, such as a broader QGIS folder.\nGive it a meaningful name “Report_Map_Template”\nClick Save"
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#load-a-map-template",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#load-a-map-template",
    "title": "Styling Themes and Templates",
    "section": "Load a Map Template",
    "text": "Load a Map Template\nNext time you need to make an export you can load your template in.\nOpen an old QGIS Project.\n\nNavigate to Project &gt; Layout Manager...\n\nUnder New from Template change Empty Layout to Specific, click the three dots and navigate to your Report_Map_Template, select it, and click Open\nClick Create\nGive the layout an appropriate name, and click OK\n\nThis will open the Layout Manager\n\nYou will see that the inset and main maps are in the wrong location, the title is wrong, the scale bar is off, and the Legend is empty. But you know how to fix these!\n\nMap Scale\n\nNavigate back to your QGIS window\n\nRight click on the most suitable layer and select Zoom to Layer(s)\n\nNavigate back to your Layout Manager window\n\nClick the Main from the Item panel, and click the Item Properties panel\n\nClick the first orange arrow button to Set Map Extent to Match Main Canvas Extent\nClick the third orange arrow button to Set Map Scale to Match Main Canvas Scale\n\nThe other buttons do the reverse\n\nRound the Scale up to a nice round number\n\nFix the inset map too\n\n\n\nScalebar\n\nClick the Scalebar from the Item panel\nIn the Item Properties panel, change Scalebar units to Metres or Kilometres - Change Fixed width to an appropriate unit\n\n\n\nLegend\n\nClick the Legend from the Item panel\nIn the Item Properties panel, under the Legend Items box and click the green + to add a layer\n\nDouble click on and rename the layer if needed\nRepeat for all layers you need to list\n\n\n\n\nTitle\n\nClick the Title from the Item panel\nIn the Item Properties panel, under the Main Properties rename the title\n\nAnd that’s it, you now have another map looking the way you want it, without too much hassle."
  },
  {
    "objectID": "qgis/Advanced topics/5 - Styling Themes and Templates.html#feedback",
    "href": "qgis/Advanced topics/5 - Styling Themes and Templates.html#feedback",
    "title": "Styling Themes and Templates",
    "section": "Feedback",
    "text": "Feedback\nPlease visit our website to provide feedback and find upcoming training courses we have on offer.\n\nGeoreferencing\nI will be happy to go over this in person, but if you need a guide, here is the QGIS how to"
  },
  {
    "objectID": "python/setup.html",
    "href": "python/setup.html",
    "title": "Python for Data Analysis",
    "section": "",
    "text": "Tip\n\n\n\nRegistrations available for our next intensive!\nBook for 3rd-5th Feb 2026",
    "crumbs": [
      "Python for Data Analysis"
    ]
  },
  {
    "objectID": "python/setup.html#overview",
    "href": "python/setup.html#overview",
    "title": "Python for Data Analysis",
    "section": "Overview",
    "text": "Overview\nWelcome to our three-day Python training intensive! This runs twice a year and the next intensive will be in early February.\nBy the end of the three days, you’ll have learnt the Python skills to manipulate, visualise and present data. We’ll spend roughly half the time learning content, and half the time working on a project in groups.\nAs we set up, there’s a few things to do, if you haven’t already\n\nInstall the software\nIntroduce yourself to your table\nJoin our Teams channel\nRegister your attendance",
    "crumbs": [
      "Python for Data Analysis"
    ]
  },
  {
    "objectID": "python/setup.html#software",
    "href": "python/setup.html#software",
    "title": "Python for Data Analysis",
    "section": "Software",
    "text": "Software\nWe are going to use Spyder for writing and running Python. This is a friendly interactive development environment (IDE) aimed at researchers. However, you are more than welcome to use your own!\nWe recommend installing the Anaconda distribution, which comes with Spyder and Python. You’re welcome to use your own IDE if you’d prefer.\nOnce you have Anaconda installed, launch Spyder, either by searching for “Spyder” on your computer or opening the Anaconda Navigator.\nWe’ll also be using the rendering and publishing tool Quarto from day 2. You’re welcome to try set this up, the easiest way is\n\nOpen an “Anaconda prompt” from the navigator\nRun conda install conda-forge::quarto\n\nYou can also install it directly from the Quarto website.\n\nGoogle Colab\nIf you aren’t able to install Python and a suitable IDE on your device (e.g. if you do not have permission) then we can find an online alternative for you, likely in the form of Google Colab. Let us know and we’ll help you get set up!",
    "crumbs": [
      "Python for Data Analysis"
    ]
  },
  {
    "objectID": "python/setup.html#creating-a-project",
    "href": "python/setup.html#creating-a-project",
    "title": "Python for Data Analysis",
    "section": "Creating a Project",
    "text": "Creating a Project\nIf you’re using Spyder, we recommend you create a project. Projects are just fancy folders, and they make it easier to access files (i.e. data) and export images (i.e. visualisations) all in the one place.\n\nOpen Spyder\nIn the Projects menu, click New Project…\nChoose New Directory, give your project a name and find an appropriate place on your computer for it.\nPress Create\n\nDone! We’ll work in this project for the duration of the intensives.",
    "crumbs": [
      "Python for Data Analysis"
    ]
  },
  {
    "objectID": "python/setup.html#workshops",
    "href": "python/setup.html#workshops",
    "title": "Python for Data Analysis",
    "section": "Workshops",
    "text": "Workshops\nOver these three days we’ll cover six sessions of content:\n\n\n\nSession\nDescription\n\n\n\n\nThe Fundamentals\nThe basics of Python. Variables, functions and modules.\n\n\nData processing\nImporting, manipulating and analysing data with pandas\n\n\nVisualisation\nCreating visualisations of our data with seaborn, matplotlib and plotly\n\n\nSharing and Publishing\nUsing GitHub for sharing and version control, as well as quarto for publishing dashboards and websites.\n\n\nStatistics\nDescriptive and inferential statistics, with some regressions and hypothesis testing, using scipy.stats and statsmodels\n\n\nProgramming Essentials\nPython tools everyone should know. Conditionals, loops, functions and importing scripts.\n\n\n\nThese content sessions are pretty packed, and we won’t have too much time to deviate. That’s why we’ll also have five project sessions - see The Project for details. You’re welcome to ask lengthier questions and play around there!",
    "crumbs": [
      "Python for Data Analysis"
    ]
  },
  {
    "objectID": "python/Essentials/3 - Visualisation.html",
    "href": "python/Essentials/3 - Visualisation.html",
    "title": "Visualisation",
    "section": "",
    "text": "In this third workshop we will cover",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "python/Essentials/3 - Visualisation.html#setting-up",
    "href": "python/Essentials/3 - Visualisation.html#setting-up",
    "title": "Visualisation",
    "section": "Setting up",
    "text": "Setting up\nWith the data manipulation tools from pandas, we can now visualise our data. For this workshop we’ll be working from the “../../data/Players2024.csv” dataset, which we should bring in with pandas:\n\nimport pandas as pd\ndf = pd.read_csv(\"../../data/Players2024.csv\")\n\nTake a quick peak at the dataset to remind yourself\n\nprint(df)\n\n                        name  birth_date  height_cm   positions nationality  \\\n0               James Milner  1986-01-04      175.0    Midfield     England   \n1        Anastasios Tsokanis  1991-05-02      176.0    Midfield      Greece   \n2              Jonas Hofmann  1992-07-14      176.0    Midfield     Germany   \n3                 Pepe Reina  1982-08-31      188.0  Goalkeeper       Spain   \n4              Lionel Carole  1991-04-12      180.0    Defender      France   \n...                      ...         ...        ...         ...         ...   \n5930  Oleksandr Pshenychnyuk  2006-05-01      180.0    Midfield     Ukraine   \n5931            Alex Marques  2005-10-23      186.0    Defender    Portugal   \n5932             Tomás Silva  2006-05-25      175.0    Defender    Portugal   \n5933             Fábio Sambú  2007-09-06      180.0      Attack    Portugal   \n5934          Hakim Sulemana  2005-02-19      164.0      Attack       Ghana   \n\n      age                                    club  \n0      38  Brighton and Hove Albion Football Club  \n1      33        Volou Neos Podosferikos Syllogos  \n2      32             Bayer 04 Leverkusen Fußball  \n3      42                             Calcio Como  \n4      33                      Kayserispor Kulübü  \n...   ...                                     ...  \n5930   18              ZAO FK Chornomorets Odessa  \n5931   18                  Boavista Futebol Clube  \n5932   18                  Boavista Futebol Clube  \n5933   17                  Boavista Futebol Clube  \n5934   19                    Randers Fodbold Club  \n\n[5935 rows x 7 columns]",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "python/Essentials/3 - Visualisation.html#seaborn-for-simple-visualisations",
    "href": "python/Essentials/3 - Visualisation.html#seaborn-for-simple-visualisations",
    "title": "Visualisation",
    "section": "Seaborn for simple visualisations",
    "text": "Seaborn for simple visualisations\nTo begin our visualisations, we’ll use the package seaborn, which allows you to quickly whip up decent graphs.\n\nimport seaborn as sns\n\n\nIt’s called “seaborn” as a reference to fictional character Sam Seaborn, whose initials are “sns”.\n\nSeaborn has three plotting functions\n\nsns.catplot(...) # for categorical plotting, e.g. bar plots, box plots etc.\nsns.relplot(...) # for relational plotting, e.g. line plots, scatter plots\nsns.displot(...) # for distributions, e.g. histograms\n\nWe’ll begin with the first.\n\nCategorical plots\nCategorical plots are produced with seaborn’s sns.catplot() function. There are two key pieces of information to pass:\n\nThe data\nThe variables\n\nLet’s see if there’s a relationship between the players’ heights and positions, by placing their positions on the \\(x\\) axis and heights on the \\(y\\).\n\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\")\n\n\n\n\n\n\n\n\nOur first graph! This is called a swarm plot; it’s like a scatter plot for categorical variables.\nIt’s already revealed two things to us about the data:\n\nThere are some incorrect heights - nobody is shorter than 25cm!\nSomeone’s position is “missing”\n\nLet’s get rid of these with the data analysis techniques from last session\n\n# Remove missing position\ndf = df[df[\"positions\"] != \"Missing\"]\n\n# Ensure reasonable heights\ndf = df[df[\"height_cm\"] &gt; 100]\n\nRun the plot again, it’s more reasonable now\n\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarningPlots not appearing\n\n\n\n\n\nIf your plots aren’t appearing, then it might be due to a known bug. The latest versions of Spyder and matplotlib solve the problem, but we can apply a fix locally for now.\nStep 1.\nCheck that it’s not a different issue. If you see any error message, then this bug is not the problem - you should solve the error first.\nAssuming there is no error message, this bug is featuring if\n\nThe plot is not appearing, and\nThe console has this output:\n\n&lt;seaborn.axisgrid.FacetGrid at 0x1e80c2e94f0&gt;\nTo apply a quick fix (and ensure that the plots are otherwise ok), try running\nplt.show()\nThis won’t fix the problem, but it will let you manually see the plots.\nStep 2.\nBefore you try to fix the issue manually, updating Spyder to the latest version should solve the issue.\n\nSave your work and close Spyder\nOpen the Anaconda Navigator\nPress the settings button on the Spyder pane\nPress “Update Application”\n\nOnce it’s done, relaunch Spyder and give it a go.\nStep 3.\nThere are three ways which might fix the bug if you can’t update Spyder. The first is to run\nplt.ion()\nTry running the plot again. If it works, great!\nIf it doesn’t work, try\nimport matplotlib as mpl\nmpl.rcParams[\"backend\"] = \"agg\"\nIf that doesn’t work, then you should adjust your Spyder settings.\n\nGo to Tools &gt; Preferences &gt; IPython Console &gt; Graphics\nUnder “Graphics Backend” change the setting to “Automatic”\n\nTry running your plots again.\nStep 4. If they still aren’t working, then ask a trainer for assistance.\n\n\n\n\nBar plots\nSwarm plots are interesting but not standard. You can change the plot type with the kind parameter\n\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"bar\")\n\n\n\n\n\n\n\n\n\nMany aspects of your plot can be adjusted by sending in additional parameters and is where seaborn excels.\n\nIt seems like goalkeepers are taller, but not by much. Let’s look at the standard deviation for each position by changing the estimator = parameter (default is mean)\n\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"bar\", estimator = \"std\")\n\n\n\n\n\n\n\n\nClearly there’s a lot less variation in goalkeepers - they’re all tall.\n\n\nBox plots\nLet’s make box plots instead. It’s the same procedure, just change to kind = \"box\" and remove estimator =\n\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"box\")\n\n\n\n\n\n\n\n\nJust as we predicted.\n\n\n\nDistributions\n\nHistograms\nLet’s move to the “Age” parameter now. We can look at the distribution of ages with\n\nsns.displot(data = df, x = \"age\")\n\n\n\n\n\n\n\n\nLooks a bit funny with those gaps - let’s change the number of bins with bins = 28\n\nsns.displot(data = df, x = \"age\", bins = 28)\n\n\n\n\n\n\n\n\nNow, what if you wanted to look at the distribution for different variables? We can make a separate distribution for each position with the col = \"positions\" argument, specifying a new column for each position\n\nsns.displot(data = df, x = \"age\", bins = 28, col = \"positions\")\n\n\n\n\n\n\n\n\n\n\nKernel density estimates\nFinally, you don’t have to do histograms. You could also do a Kernel Density Estimate, with kind = \"kde\" (let’s remove bins = and col =)\n\nsns.displot(data = df, x = \"age\", kind = \"kde\")\n\n\n\n\n\n\n\n\nIf you want a separate line for each position, we should indicate that each position needs a different colour/hue with hue = \"positions\"\n\nsns.displot(data = df, x = \"age\", hue = \"positions\", kind = \"kde\")\n\n\n\n\n\n\n\n\n\n\n\nRelational plots\nIt seems like players peak in their mid-twenties, but goalkeepers stay for longer. Let’s see if there’s a relationship between players’ age and height\n\nScatter plots\nWe’ll start with a scatter plot\n\nsns.relplot(data = df, x = \"age\", y = \"height_cm\")\n\n\n\n\n\n\n\n\nNot much of a trend there, although the bottom-right looks a bit emptier than the rest (could it be that short old players are the first to retire?).\nWe can use hue = to have a look at positions again\n\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n\n\n\n\n\n\n\nYup, goalkeepers are tall, and everyone else is a jumble.\n\n\nLine plots\nLet’s do a line plot of the average height per age.\n\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", kind = \"line\")\n\n\n\n\n\n\n\n\nSeems pretty flat, except the ends are a bit weird because there’s not much data. Let’s eliminate everything before 17 and after 38 and plot it\n\n# Create smaller dataframe\ncondition = (df[\"age\"] &gt; 17) & (df[\"age\"] &lt; 38)\ninner_ages = df[condition]\n\n# Line plot\nsns.relplot(data = inner_ages, x = \"age\", y = \"height_cm\", kind = \"line\")\n\n\n\n\n\n\n\n\nLooks a bit shaky but that’s just because it’s zoomed in - notice that we go from 182cm to 184cm. We’ll fix this when we look at matplotlib in the next section.\n\n\nCombining the two\nWe can combine our scatter and line plots together.\n\nMake the first plot as normal\nFor all additional (overlaying) plots, use an axes-level plot instead of sns.relplot() etc. These just draw the points/bars/lines, and are normally behind-the-scenes. There’s one for every plot type, and look like\n\nsns.lineplot()\nsns.scatterplot()\nsns.boxplot()\nsns.histplot()\netc.\n\n\nFor example,\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\")\n\n\n\n\n\n\n\n\n\nYou can’t include kind = inside an axes level plot\n\nLet’s swap the colour variable from the scatter plot to the line plot\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n\n\n\n\n\n\n\nFinally, let’s make the scatter dots smaller with s = 10 and grey with color = \"grey\".\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "python/Essentials/3 - Visualisation.html#going-deeper-with-matplotlib",
    "href": "python/Essentials/3 - Visualisation.html#going-deeper-with-matplotlib",
    "title": "Visualisation",
    "section": "Going deeper with matplotlib",
    "text": "Going deeper with matplotlib\nSeaborn is great for simple and initial visualisations, but when you need to make adjustments it gets tricky. At its core, seaborn is just a simple way of using matplotlib, an extensive and popular plotting package. It was created as a way of doing MATLAB visualisations with Python, so if you’re coming from there, things will feel familiar.\nPros\n\nCustomisable. You can tweak almost every parameter of the visualisations\nFast. It can handle large data\nPopular. Lots of people use it, and knowing it will help you collaborate\n\nCons - a bit programmy\n\nSteep-ish learning curve. Creating basic plots can be easy, but its set up with enough complexity that it takes a bit of work to figure out what’s going on.\nCumbersome. You can tweak almost everything, but this means that it can take some effort to tweak anything.\n\nWe’re barely going to touch the matplotlib surface, but we’ll look at some essentials.\nTo begin with, we want to bring in matplotlib as follows\n\nimport matplotlib.pyplot as plt\n\n\nSaving plots\nBefore we move to adjusting the plot, let’s just look at how you save it. While you can do this with seaborn, the matplotlib way is also very simple.\nAs a first step, you should make a new folder. Navigate using your file explorer to the project and create a new folder called “plots”.\nNext, save the current plot with plt.savefig(\"place_location_here\"), and we have to do this at the same time that we make the plot. So run all this code at once:\n\nplt.savefig(\"plots/first_saved_plot.png\")\n\n\n\nMaking modifications\n\nTitles\nNotice that the \\(y\\) axis has an ugly label? That’s because seaborn is just drawing from your dataframe.\nWe can change axis labels with plt.ylabel()\n\n# Plotting functions\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Customisation\nplt.ylabel(\"Height (cm)\")\n\nText(4.8166666666666655, 0.5, 'Height (cm)')\n\n\n\n\n\n\n\n\n\nand similarly you could change plt.xlabel(...).\n\nMake sure you run the above line at the same time as your plotting function. You can either * Highlight all the code and press F9 * Make a cell with #%% and press ctrl + enter\n\nWe can also change the legend title to “positions” with plt.legend()\n\n# Plotting functions\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Customisation\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"positions\")\n\n\n\n\n\n\n\n\nAnd its location with loc = \"lower left\"\n\n# Plotting functions\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Customisation\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"positions\")\n\n\n\n\n\n\n\n\nAnd give the whole plot a title with plt.title()\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"positions\")\nplt.title(\"Players' heights vs ages\")\n\nText(0.5, 1.0, \"Players' heights vs ages\")\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotations\nYou might want to annotate your plot with text and arrows. Text is simple with the plt.text() function; we just need to specify its coordinates and the contents.\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"positions\")\nplt.title(\"Players' heights vs ages\")\n\n# Annotations\nplt.text(38.5, 181, \"Not enough\\ndata for mean\")\n\nText(38.5, 181, 'Not enough\\ndata for mean')\n\n\n\n\n\n\n\n\n\n\nThe characters \\n mean ‘new line’\n\nWe could annotate with arrows too. This is more complex, using the plt.annotate() function:\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"positions\")\nplt.title(\"Players' heights vs ages\")\n\n# Annotations\nplt.text(38.5, 181, \"Not enough\\ndata for mean\")\nplt.annotate(text = \"No short\\nolder players\", xy = [37,165], xytext = [40,172],\n             arrowprops = dict(width = 1, headwidth = 10, headlength = 10, \n                          facecolor = \"black\"))\n\nText(40, 172, 'No short\\nolder players')\n\n\n\n\n\n\n\n\n\n\nI’ve split this over multiple lines, but its still one function - check the brackets\n\nAll together, our plot has become\n\n\nAxis limits\nThe last feature we’ll look at is editing axis limits. Let’s try to make more room in the bottom left for the legend with the functions plt.xlim() and plt.ylim()\n\n# Figure level plot\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"positions\", loc = \"lower left\")\nplt.title(\"Players' heights vs ages\")\n\n# Annotations\nplt.text(38.5, 181, \"Not enough\\ndata for mean\")\nplt.annotate(\"No short\\nolder players\", [37,165], [40,172], \n             arrowprops = dict(width = 1,headwidth = 10,headlength = 10, \n                               facecolor = \"black\"))\n\n# Axis limits\nplt.xlim([10,45])\nplt.ylim([150,210])\n\n\n\n\n\n\n\n\nI’m not sure that looks any better, but you get the idea!",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "python/Essentials/3 - Visualisation.html#interactivity-with-plotly",
    "href": "python/Essentials/3 - Visualisation.html#interactivity-with-plotly",
    "title": "Visualisation",
    "section": "Interactivity with plotly",
    "text": "Interactivity with plotly\nFor the last part of this section, we’re going to briefly look at making interactive plots with plotly.\nWe bring in the tools with\n\nimport plotly.express as px\n\n\nYou’ll probably need to install it first - use either\nconda install plotly\nOR\npip install plotly\ndepending on your installation.\n\nPlotly works by creating a visualisation like we’ve been doing, and then loading it into something dynamic, like a web browser. Spyder does not support interactive plots. This means we need to change the default settings with\n\nimport plotly.io as pio\npio.renderers.default = \"browser\"\n\nNow, plots should all load in your default browser.\n\nThe basics\nWe make plotly graphs very similarly to seaborn. Let’s take our first plot from above,\n\nsns.relplot(data = df, x = \"age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n\n\n\n\n\n\n\nand turn it into a plotly one.\n\nWe need to use px.scatter instead of sns.relplot\nWe need to use data_frame = instead of data =\nLet’s remove the s = and color = for now\nSave the plot as a variable\n\n\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\")\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nNotice how you can hover over the points now? It’s interactive!\n\n\nIntroducing more info and neatening up\nLike seaborn’s “hue”, we can use color = to introduce a third variable\n\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\")\n\n                            \n                                            \n\n\nAnd like seaborn’s “col”, we can facet with facet_col =\n\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\")\n\n                            \n                                            \n\n\nPersonally, I think these are too squished. We can specify the maximum number of columns with facet_col_wrap =\n\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2)\n\n                            \n                                            \n\n\nFinally, let’s adjust the information in the hover. We can give each point a name with hover_name = - how about their actual names?\n\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\")\n\n                            \n                                            \n\n\nAnd let’s also include their nationalities\n\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\",\n           hover_data = \"nationality\")\n\n                            \n                                            \n\n\n\n\nSaving interactive plots\nSince these are interactive, we can’t save them as normal. The easiest option is to save them as HTML files - like websites - which we can open from our browsers.\nFirst, save the plot into a variable\n\nfig = px.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n                 facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\",\n                 hover_data = \"nationality\")\n\nThen, write it to HTML\n\nfig.write_html(\"plot.html\")",
    "crumbs": [
      "Essentials",
      "Visualisation"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html",
    "href": "python/Essentials/2 - Data processing.html",
    "title": "Data Processing",
    "section": "",
    "text": "In this second workshop we will cover\nThis hands-on course – directed at intermediate users – looks at using the pandas module to transform and visualise tabular data.",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#setting-up",
    "href": "python/Essentials/2 - Data processing.html#setting-up",
    "title": "Data Processing",
    "section": "Setting up",
    "text": "Setting up\n\nIntroducing pandas\nPandas is a Python module that introduces dataframes to Python. It gives us the tools we need to clean and transform data with Python.\nTo be able to use the functions included in pandas, we have to first import it:\n\nimport pandas as pd\n\npd is the usual nickname for the pandas module.\n\nIf you get an error, like No module named 'pandas', you’ll need to install it first, using either conda install pandas or pip install pandas, depending on your Python installation.\n\n\nThe DataFrame object\nPandas is built upon one key feature: the DataFrame class. In Python we have different built-in types, like int for integers and string for characters. Pandas introduces a new type, DataFrame, which stores data like a spreadsheet.\n\n\n\nSetting up the workspace\nTo make life easy, we should set up our workspace well.\n\nOpen your project folder using your file explorer, and create a new folder called “data”.\nDownload the data for today’s session\nMove the file into your new “data” folder\nNext, open your project in Spyder, and create a new script called “analysis.py”.\nOpen the “Files” tab in Spyder and check that you see two objects:\n\nThe file “analysis.py”\nThe folder “data”\n\n\n\n\nImporting data\nPandas offers a simple way to access data with its read.csv() function. We’ll save it into the variable df_raw:\n\ndf_raw = pd.read_csv(\"../../data/Players2024.csv\")\n\n\nYou can also provide a URL instead of a file path!\n\n\n\nAside - File Paths and backslashes\nJust a quick detour to discuss file paths of which there are two types: absolute and relative\n\nAbsolute\nAbsolute file paths always start at the “top” of your file system, e.g. one of the drives (like C:) for Windows users, so they are never ambiguous. It’s like providing your full address from country to street number.\nC://Users/my_username/research/data/really_important_secret_data.csv\n\n\nRelative\nRelative file paths start from your current working directory, which is usually the top folder of a Spyder project. For files in my current folder, I just provide their name - like referring to another house on your street as “number 7”. Let’s assume we’re in the “research” folder.\nfile_in_my_current_folder.csv\nWe can go to down folders from our current location:\ndata/really_important_secret_data.csv\nAnd we can go up folders from our current location\n../../this_file_is_two_levels_up.csv\nOr a combination of the two (e.g. up one, then down into a different folder)\n../not_research/this_file_is_not_research.csv\nWhat matters is that the relative reference depends on where your code is and will break if you move the script!\n\n\nBackslashes\nOne last note: Windows uses backslashes for their file paths\nC:\\\\Users\\...\nBut Python uses backslashes as an escape character. For example, \"\\n\" is a newline, \"\\u1234\" is the unicode character U+1234 and confusingly \"\\\\\" is a single backslash. The easist way to get around this is by prefixing r to all strings: this makes them raw.\n\nwindows_url = r\"C:\\\\Users\\...\"\n\n\n\n\nInitial look at the data\nLet’s get back to data.\nWe can investigate the size of the data thanks to the shape attribute attached to all pandas dataframes:\n\ndf_raw.shape\n\n(5935, 7)\n\n\nThe dataset contains dozens of columns. What are their names?\n\ndf_raw.columns\n\nIndex(['name', 'birth_date', 'height_cm', 'positions', 'nationality', 'age',\n       'club'],\n      dtype='object')\n\n\nLet’s subset our data to focus on a handful of variables.\n\n\nCreating a backup\nData analysis in Python is safe because our variables are copies of the data - we aren’t actually changing the files until we explicitly overwrite them. However, Python also has no undo, so if I delete something in my analysis, I can’t get it back - I have to start all over again.\nOne way to mitigate this issue is by making a copy of the data\n\ndf = df_raw.copy()\n\nNow we have two variables: df is what we’ll use, and df_raw stores the raw data. If we ever need to restart, we can simply run df = df_raw.copy().",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#accessing-and-filtering-data",
    "href": "python/Essentials/2 - Data processing.html#accessing-and-filtering-data",
    "title": "Data Processing",
    "section": "Accessing and Filtering Data",
    "text": "Accessing and Filtering Data\nSo how do we access our data in Python? We use a type of indexing introduced by pandas, which revolves around using square brackets after the dataframe: df[...].\n\nAccessing columns\nTo access a column, index with its name: df[\"column_name\"]. For example,\n\ndf[\"name\"]\n\n0                 James Milner\n1          Anastasios Tsokanis\n2                Jonas Hofmann\n3                   Pepe Reina\n4                Lionel Carole\n                 ...          \n5930    Oleksandr Pshenychnyuk\n5931              Alex Marques\n5932               Tomás Silva\n5933               Fábio Sambú\n5934            Hakim Sulemana\nName: name, Length: 5935, dtype: object\n\n\nreturns the “name” column. We can access multiple by providing a list of names\n\n# Save the names in a list and then index\ncolumn_names = [\"name\", \"club\"]\ndf[column_names]\n\n# This is equivalent to\ndf[[\"name\", \"club\"]]\n\n\n\n\n\n\n\n\nname\nclub\n\n\n\n\n0\nJames Milner\nBrighton and Hove Albion Football Club\n\n\n1\nAnastasios Tsokanis\nVolou Neos Podosferikos Syllogos\n\n\n2\nJonas Hofmann\nBayer 04 Leverkusen Fußball\n\n\n3\nPepe Reina\nCalcio Como\n\n\n4\nLionel Carole\nKayserispor Kulübü\n\n\n...\n...\n...\n\n\n5930\nOleksandr Pshenychnyuk\nZAO FK Chornomorets Odessa\n\n\n5931\nAlex Marques\nBoavista Futebol Clube\n\n\n5932\nTomás Silva\nBoavista Futebol Clube\n\n\n5933\nFábio Sambú\nBoavista Futebol Clube\n\n\n5934\nHakim Sulemana\nRanders Fodbold Club\n\n\n\n\n5935 rows × 2 columns\n\n\n\nIf we want to do anything with it (like statistics or visualisation), it’s worth saving the column(s) as a new variable\n\ndf_subset = df[[\"name\", \"club\"]]\n\n\n\nAccessing rows\nThere’s a few ways to access rows. The easiest is by slicing, df[start_row : end_row]. For example, if you want rows 5 to 10,\n\ndf[5 : 10]\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\n5\nLudovic Butelle\n1983-04-03\n188.0\nGoalkeeper\nFrance\n41\nStade de Reims\n\n\n6\nDaley Blind\n1990-03-09\n180.0\nDefender\nNetherlands\n34\nGirona Fútbol Club S. A. D.\n\n\n7\nCraig Gordon\n1982-12-31\n193.0\nGoalkeeper\nScotland\n41\nHeart of Midlothian Football Club\n\n\n8\nDimitrios Sotiriou\n1987-09-13\n185.0\nGoalkeeper\nGreece\n37\nOmilos Filathlon Irakliou FC\n\n\n9\nAlessio Cragno\n1994-06-28\n184.0\nGoalkeeper\nItaly\n30\nAssociazione Calcio Monza\n\n\n\n\n\n\n\n\nNote that the end row is not included\n\nIf you want to access a single row, we need to use df.loc[] or df.iloc[]. These are the go-to methods for accessing data if the above indexing isn’t sufficient.\n\ndf.loc[] accesses rows by label (defaults to row number but could be anything)\ndf.iloc[] accesses rows by row number exclusively\n\nBy default they line up, so\n\ndf.loc[5]\ndf.iloc[5]\n\nname           Ludovic Butelle\nbirth_date          1983-04-03\nheight_cm                188.0\npositions           Goalkeeper\nnationality             France\nage                         41\nclub            Stade de Reims\nName: 5, dtype: object\n\n\nare often (but not always) the same.\nFinally, we can filter specific rows by a condition on one of the variables, e.g. only rows where variable \\(\\text{age} &gt; 25\\).\n\ndf[df[\"age\"] &gt; 25]\n# Or any other condition\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\n0\nJames Milner\n1986-01-04\n175.0\nMidfield\nEngland\n38\nBrighton and Hove Albion Football Club\n\n\n1\nAnastasios Tsokanis\n1991-05-02\n176.0\nMidfield\nGreece\n33\nVolou Neos Podosferikos Syllogos\n\n\n2\nJonas Hofmann\n1992-07-14\n176.0\nMidfield\nGermany\n32\nBayer 04 Leverkusen Fußball\n\n\n3\nPepe Reina\n1982-08-31\n188.0\nGoalkeeper\nSpain\n42\nCalcio Como\n\n\n4\nLionel Carole\n1991-04-12\n180.0\nDefender\nFrance\n33\nKayserispor Kulübü\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5155\nLeo Scienza\n1998-09-13\n175.0\nAttack\nBrazil\n26\n1. Fußballclub Heidenheim 1846\n\n\n5236\nMohamed Brahimi\n1998-09-17\n181.0\nAttack\nFrance\n26\nFK Fakel Voronezh\n\n\n5287\nNicolás Marotta\n1996-12-23\n186.0\nDefender\nArgentina\n27\nAthens Kallithea Football Club\n\n\n5471\nDaniel Sosah\n1998-09-21\n179.0\nAttack\nNiger\n26\nFK Kryvbas Kryvyi Rig\n\n\n5478\nEgas Cacintura\n1997-10-29\n174.0\nMidfield\nAngola\n26\nDinamo Makhachkala\n\n\n\n\n2757 rows × 7 columns\n\n\n\nAs with the column case, it’s useful to save this as a variable\n\ndf_filtered = df[df[\"age\"] &gt; 15]",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#basic-statistics",
    "href": "python/Essentials/2 - Data processing.html#basic-statistics",
    "title": "Data Processing",
    "section": "Basic statistics",
    "text": "Basic statistics\nHow might we perform some basic statistics on our data?\nTo check what kind of data each column is stored as, we can use the dtypes attribute:\n\ndf.dtypes\n\nname            object\nbirth_date      object\nheight_cm      float64\npositions       object\nnationality     object\nage              int64\nclub            object\ndtype: object\n\n\n\nIn general, pandas will bring in numbers with float64 and non-numeric data with object.\n\nThe describe() method is useful for descriptive statistics about our numerical columns:\n\ndf.describe()\n\n\n\n\n\n\n\n\nheight_cm\nage\n\n\n\n\ncount\n5935.000000\n5935.000000\n\n\nmean\n182.986352\n25.501769\n\n\nstd\n7.478313\n4.455595\n\n\nmin\n17.000000\n15.000000\n\n\n25%\n178.000000\n22.000000\n\n\n50%\n183.000000\n25.000000\n\n\n75%\n188.000000\n29.000000\n\n\nmax\n206.000000\n42.000000\n\n\n\n\n\n\n\nHowever, it will only show the two first ones and two last ones. We can focus on a specific column instead, for example one that was hidden previously:\n\ndf[\"age\"].describe()\n\ncount    5935.000000\nmean       25.501769\nstd         4.455595\nmin        15.000000\n25%        22.000000\n50%        25.000000\n75%        29.000000\nmax        42.000000\nName: age, dtype: float64\n\n\nOr a categorical column:\n\ndf[\"nationality\"].describe()\n\ncount      5935\nunique      135\ntop       Spain\nfreq        402\nName: nationality, dtype: object\n\n\n\nFor a categorical column, the information shown is different: for example, how many unique values there are, and what the most common value is.\n\nWhat if you want specific statistics about a particular column? Usually there are methods available:\n\n# Applicable to all columns\ndf[\"nationality\"].count()\ndf[\"nationality\"].unique()\n\n# For numeric columns only\ndf[\"height_cm\"].min()\ndf[\"height_cm\"].max()\ndf[\"height_cm\"].mean()\ndf[\"height_cm\"].median()\ndf[\"height_cm\"].std()\n# ...\n\nnp.float64(7.478312588515905)\n\n\nWe can use these methods to filter our data. For example, the row which has the maximum value of variable \\(x\\) is\n\nx_max = df[\"height_cm\"].max()\ndf[df[\"height_cm\"] == x_max]\n\n# Or in one line\ndf[df[\"height_cm\"] == df[\"height_cm\"].max()]\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\n4179\nKevin Gadellaa\n2003-04-08\n206.0\nGoalkeeper\nNetherlands\n21\nFootball Club Utrecht\n\n\n4810\nIsaak Touré\n2003-03-28\n206.0\nDefender\nFrance\n21\nUdinese Calcio\n\n\n5565\nDenys Tvardovskyi\n2003-06-13\n206.0\nGoalkeeper\nUkraine\n21\nFC Shakhtar Donetsk\n\n\n\n\n\n\n\nbecause we are looking for the row in df[\"height_cm\"] (the whole column) that has the value df[\"height_cm\"].max().",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#challenge",
    "href": "python/Essentials/2 - Data processing.html#challenge",
    "title": "Data Processing",
    "section": "Challenge",
    "text": "Challenge\nReduce your dataset to \\(\\le 3\\) variables (columns) and \\(\\le 100\\) rows using conditions by filtering down to a particular subset of your data.",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#adding-and-removing-columns",
    "href": "python/Essentials/2 - Data processing.html#adding-and-removing-columns",
    "title": "Data Processing",
    "section": "Adding and removing columns",
    "text": "Adding and removing columns\nSometimes we need to add new columns. It’s the same process as overwriting existing columns - let’s make a new column called “zeroes” where every row is 0\n\ndf[\"zeroes\"] = 0\n\nWe can also send in a column, for example\n\ndf[\"copy_of_names\"] = df[\"name\"]\n\nPerhaps most usefully, we can manipulate the column we send in. For example, the deviation from the mean \\[|\\bar{x} - x_i|\\] can be computed for each row’s height:\n\ncol_x = df[\"height_cm\"]\navg_x = df[\"height_cm\"].mean()\n\ndf[\"deviation_from_mean_height\"] = abs(col_x - avg_x)\n\n# Or all together on one line,\ndf[\"deviation_from_mean_height\"] = abs(df[\"height_cm\"] - df[\"height_cm\"].mean())\n\nwhere abs(...) takes the absolute value\nNotice that we subtracted a value from a column. We can also perform mathematics with multiple columns:\n\ndf[\"product\"] = df[\"age\"]*df[\"height_cm\"]\n\nLet’s remove these new columns that we don’t need with the method df.drop(columns = [...]):\n\ndf = df.drop(columns = [\"zeroes\", \"copy_of_names\", \"deviation_from_mean_height\", \"product\"])",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#summaries",
    "href": "python/Essentials/2 - Data processing.html#summaries",
    "title": "Data Processing",
    "section": "Summaries",
    "text": "Summaries\nAfter cleaning up our data, we need to analyse it. This usually involves some kind of aggregation. For example, what is the average \\(x\\) per year? requires aggregating over variable \\(x\\) for each year.\nFirst, we need to group by a specific variable\n\ngb = df.groupby(\"age\")\n\nThis thing in itself is a pretty abstract Python object, best thought of as a dataframe where we’ve identified a grouping variable.\nNext, we need to apply some aggregation to it (the groupby tells it to do it for each year)\n\navg_height_by_age = gb[\"height_cm\"].agg(\"mean\")\n\nOf course, we could have done this in one line:\n\navg_height_by_age = df.groupby(\"age\")[\"height_cm\"].agg(\"mean\")\n\nThis is a really useful tool, because now we have something we can visualise. As the next session will show us, the visualisation tools generally just take in numbers and turn them into dots. We need to do the stats beforehand.\nAs a taster, try running\n\navg_height_by_age.plot()",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#exporting-results",
    "href": "python/Essentials/2 - Data processing.html#exporting-results",
    "title": "Data Processing",
    "section": "Exporting results",
    "text": "Exporting results\nThe last step in the process is saving the data. Let’s say we want to take that final dataframe and export it to a csv. That’s what the df.to_csv() method is for\n\navg_height_by_age.to_csv(\"data/avg_height_by_age.csv\")\n\nThis will save the dataframe to a .csv file and place it in the data folder.",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Essentials/2 - Data processing.html#resources",
    "href": "python/Essentials/2 - Data processing.html#resources",
    "title": "Data Processing",
    "section": "Resources",
    "text": "Resources\n\nOfficial pandas documentation\n\nGetting started\n10 Minutes to pandas\nUser guide\n\nMore visualisation modules:\n\nAltair\nBokeh\nVega\nMatplotlib\n\nOur compilation of useful Python links",
    "crumbs": [
      "Essentials",
      "Data Processing"
    ]
  },
  {
    "objectID": "python/Advanced topics/5 - Statistics.html",
    "href": "python/Advanced topics/5 - Statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "This session is aimed as an overview of how to perform some statistical modelling with Python. It is a Python workshop, not a statistics workshop - if you’d like to better understand the statistical models, or need help deciding what’s best for you, please consult a statistics resource or contact a statistician.\nIn this session, we’ll cover\nWe’ll use three new modules: - numpy - scipy.stats - statsmodels",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "python/Advanced topics/5 - Statistics.html#setting-up",
    "href": "python/Advanced topics/5 - Statistics.html#setting-up",
    "title": "Statistics",
    "section": "Setting up",
    "text": "Setting up\nTo begin, create a new file for this session.\n\n\n\n\n\n\nWarningBe careful with the file name\n\n\n\nWe’ve encountered issues when calling this file statistics.py, so please choose a different name. Examples include,\n\nstats.py\nstats_workshop.py\nstatistics_workshop.py\n\nSpecifically, when you render Quarto files with seaborn plots, it gets confused and uses your file to compute statistics instead of its dependency.\n\n\nWe’ll be working from our “Players2024” dataset again. To bring it in and clean it up,\n\nimport pandas as pd\n\ndf = pd.read_csv(\"../../data/Players2024.csv\")\ndf = df[df[\"positions\"] != \"Missing\"]\ndf = df[df[\"height_cm\"] &gt; 100]",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "python/Advanced topics/5 - Statistics.html#descriptive-statistics",
    "href": "python/Advanced topics/5 - Statistics.html#descriptive-statistics",
    "title": "Statistics",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nWe’ll start with sample size. All dataframes have most descriptive statistics functions available right off the bat which we access via the . operator.\nTo calculate the number of non-empty observations in a column, say the numeric variable df[\"height_cm\"], we use the .count() method\n\ndf[\"height_cm\"].count()\n\nnp.int64(5932)\n\n\n\nMeasures of central tendancy\nWe can compute measures of central tendancy similarly. The average value is given by\n\ndf[\"height_cm\"].mean()\n\nnp.float64(183.04130141604855)\n\n\nthe median by\n\ndf[\"height_cm\"].median()\n\nnp.float64(183.0)\n\n\nand the mode by\n\ndf[\"height_cm\"].mode()\n\n0    185.0\nName: height_cm, dtype: float64\n\n\n\n.mode() returns a dataframe with the most frequent values as there can be multiple.\n\n\n\nMeasures of variance\nWe can also compute measures of variance. The minimum and maximum are as expected\n\ndf[\"height_cm\"].min()\ndf[\"height_cm\"].max()\n\nnp.float64(206.0)\n\n\nThe range is the difference\n\ndf[\"height_cm\"].min() - df[\"height_cm\"].max()\n\nnp.float64(-46.0)\n\n\nQuantiles are given by .quantile(...) with the fraction inside. The inter-quartile range (IQR) is the difference between 25% and 75%.\n\nq1 = df[\"height_cm\"].quantile(0.25)\nq3 = df[\"height_cm\"].quantile(0.75)\nIQR = q3 - q1\n\nA column’s standard deviation and variance are given by\n\ndf[\"height_cm\"].std()\ndf[\"height_cm\"].var()\n\nnp.float64(46.7683158241558)\n\n\nAnd the standard error of the mean (SEM) with\n\ndf[\"height_cm\"].sem()\n\nnp.float64(0.08879229764682213)\n\n\nYou can calculate the skewness and kurtosis (variation of tails) of a sample with\n\ndf[\"height_cm\"].skew()\ndf[\"height_cm\"].kurt()\n\nnp.float64(-0.4338044567190438)\n\n\nAll together, you can see a nice statistical summary with\n\ndf[\"height_cm\"].describe()\n\ncount    5932.000000\nmean      183.041301\nstd         6.838736\nmin       160.000000\n25%       178.000000\n50%       183.000000\n75%       188.000000\nmax       206.000000\nName: height_cm, dtype: float64\n\n\n\n\nMeasures of correlation\nIf you’ve got two numeric variables, you might want to examine covariance and correlation. These indicate how strongly the variables are linearly related. We’ll need to use the df[\"age\"] variable as well.\nThe covariance between “height_cm” and “age” is\n\ndf[\"height_cm\"].cov(df[\"age\"])\n\nnp.float64(0.5126608276592355)\n\n\n\nThe .cov() function compares the column it’s attached to (here df[\"height_cm\"]) with the column you input (here df[\"age\"]). This means we could swap the columns without issue:\n{python} df[\"age\"].cov(df[\"height_cm\"])\n\nSimilarly, we can find the Pearson correlation coefficient between two columns.\n\ndf[\"height_cm\"].corr(df[\"age\"])\n\nnp.float64(0.01682597901197298)\n\n\nYou can also specify “kendall” or “spearman” for their respective correlation coefficients\n\ndf[\"height_cm\"].corr(df[\"age\"], method = \"kendall\")\ndf[\"height_cm\"].corr(df[\"age\"], method = \"spearman\")\n\nnp.float64(0.007604345289158663)\n\n\n\n\nReminder about groupbys\nBefore we move to inferential statistics, it’s worth reiterating the power of groupbys discussed in the second workshop.\nTo group by a specific variable, like “positions”, we use\n\ngb = df.groupby(\"positions\")\n\nBy applying our statistics to the gb object, we’ll apply them to every variable for each position. Note that we should specify numeric_only = True, because these statistics won’t work for non-numeric variables\n\ngb.mean(numeric_only = True)\n\n\n\n\n\n\n\n\nheight_cm\nage\n\n\npositions\n\n\n\n\n\n\nAttack\n180.802673\n25.061108\n\n\nDefender\n184.193269\n25.716471\n\n\nGoalkeeper\n190.668508\n26.587017\n\n\nMidfield\n180.497017\n25.201671",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "python/Advanced topics/5 - Statistics.html#inferential-statistics",
    "href": "python/Advanced topics/5 - Statistics.html#inferential-statistics",
    "title": "Statistics",
    "section": "Inferential Statistics",
    "text": "Inferential Statistics\nInferential statistics requires using the module scipy.stats, which we’ll bring in with\n\nimport scipy.stats as stats\n\n\nSimple linear regressions\nLeast-squares regression for two sets of measurements can be performed with the function stats.linregress()”\n\nstats.linregress(x = df[\"age\"], y = df[\"height_cm\"])\n\nLinregressResult(slope=np.float64(0.025827494764561896), intercept=np.float64(182.38260451315895), rvalue=np.float64(0.01682597901197298), pvalue=np.float64(0.19506275453364344), stderr=np.float64(0.019930266529602007), intercept_stderr=np.float64(0.5159919571772644))\n\n\nIf we store this as a variable, we can access the different values with the . operator. For example, the p-value is\n\nlm = stats.linregress(x = df[\"age\"], y = df[\"height_cm\"])\nlm.pvalue\n\nnp.float64(0.19506275453364344)\n\n\n\nPlotting it\nNaturally, you’d want to plot this. We’ll need to use the overlaying techniques from the visualisation session. Let’s import seaborn and matplotlib\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nStart by making a scatterplot of the data,\n\nsns.relplot(data = df, x = \"age\", y = \"height_cm\")\n\n\n\n\n\n\n\n\nThen, you’ll need to plot the regression as a line. For reference,\n\\[ y = \\text{slope}\\times x + \\text{intercept}\\]\nSo\n\nsns.relplot(data = df, x = \"age\", y = \"height_cm\")\n\nx_lm = df[\"age\"]\ny_lm = lm.slope*x_lm + lm.intercept\nsns.lineplot(x = x_lm, y = y_lm, color = \"r\")\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)-tests\nWe can also perform \\(t\\)-tests with the scipy.stats module. Typically, this is performed to examine the statistical signficance of a difference between two samples’ means. Let’s examine whether that earlier groupby result for is accurate for heights, specifically, are goalkeepers taller than non-goalkeepers?\nLet’s start by separating the goalkeepers from the non-goalkeepers in two variables\n\ngoalkeepers = df[df[\"positions\"] == \"Goalkeeper\"]\nnon_goalkeepers = df[df[\"positions\"] != \"Goalkeeper\"]\n\nThe \\(t\\)-test for the means of two independent samples is given by\n\nstats.ttest_ind(goalkeepers[\"height_cm\"], non_goalkeepers[\"height_cm\"])\n\nTtestResult(statistic=np.float64(35.2144964816995), pvalue=np.float64(7.551647917141636e-247), df=np.float64(5930.0))\n\n\nYielding a p-value of \\(8\\times 10^{-247}\\approx 0\\), indicating that the null-hypothesis (heights are the same) is extremely unlikely.\n\n\nANOVAs\nWhat about the means of the other three? We could use an ANOVA to examine them. We use the stats.f_oneway() function for this. However, this requires us to send a list of samples in for each group, so we should separate the three positions.\n\ndefender = df[df[\"positions\"] == \"Defender\"].height_cm\nmidfield = df[df[\"positions\"] == \"Midfield\"].height_cm\nattack = df[df[\"positions\"] == \"Attack\"].height_cm\n\nWe can then perform the ANOVA on this list of samples\n\nstats.f_oneway(defender, midfield, attack)\n\nF_onewayResult(statistic=np.float64(199.74794987909772), pvalue=np.float64(2.6216423274516227e-84))\n\n\nWith \\(p = 3\\times10^{-84}\\), it looks like their positions are not all independent of height.\n\n\n\\(\\chi^2\\) tests\n\\(χ^2\\) tests are useful for examining the relationship of categorical variables by comparing the frequencies of each. Often, you’d use this if you can make a contingency table.\nWe only have one useful categorical variable here, “positions” (the others have too many unique values), so we’ll need to create another. Let’s see if there’s a relationship between players’ positions and names with the letter “a”.\nMake a binary column for players with the letter “a” in their names. To do this, we need to apply a string method to all the columns in the dataframe as follows\n\ndf[\"a_in_name\"] = df[\"name\"].str.contains(\"a\")\n\nLet’s cross tabulate positions with this new column\n\na_vs_pos = pd.crosstab(df[\"positions\"],df[\"a_in_name\"])\nprint(a_vs_pos)\n\na_in_name   False  True \npositions               \nAttack        291   1280\nDefender      355   1606\nGoalkeeper    149    575\nMidfield      312   1364\n\n\nThe \\(χ^2\\) test’s job is to examine whether players’ positions depend on the presence of “a” in their name. To evaluate it we need to send the contingency table in:\n\nstats.chi2_contingency(a_vs_pos)\n\nChi2ContingencyResult(statistic=np.float64(2.1808405074930404), pvalue=np.float64(0.5357320466340114), dof=3, expected_freq=array([[ 293.17211733, 1277.82788267],\n       [ 365.9519555 , 1595.0480445 ],\n       [ 135.10923803,  588.89076197],\n       [ 312.76668914, 1363.23331086]]))\n\n\n\n\nMore complex modelling\nIf you need to do more advanced statistics, particularly if you need more regressions, you’ll likely need to turn to a different package: statsmodels. It is particularly useful for statistical modelling.\nWe’ll go through three examples\n\nSimple linear regressions (like before)\nMultiple linear regressions\nLogistic regressions\n\nWhat’s nice about statsmodels is that it gives an R-like interface and summaries.\nTo start with, let’s import the tools. We’ll use the formula interface, which offers us an R-like way of creating models.\n\nimport statsmodels.formula.api as smf\n\n\nSimple linear regressions revisited\nLet’s perform the same linear regression as before, looking at the “age” and “height variables”. Our thinking is that players’ heights dictate how long they can play, so we’ll make \\(x = \\text{height\\_cm}\\) and \\(y = \\text{age}\\).\nThe first step is to make the set up the variables. We’ll use the function smf.ols() for ordinary least squares. It takes in two imputs:\n\nThe formula string, in the form y ~ X1 + X2 ...\nThe data\n\nWe create the model and compute the fit\n\nmod = smf.ols(\"age ~ height_cm\", df)\nres = mod.fit()\n\nDone! Let’s take a look at the results\n\nres.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nage\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n1.679\n\n\nDate:\nWed, 10 Dec 2025\nProb (F-statistic):\n0.195\n\n\nTime:\n15:06:19\nLog-Likelihood:\n-17279.\n\n\nNo. Observations:\n5932\nAIC:\n3.456e+04\n\n\nDf Residuals:\n5930\nBIC:\n3.457e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n23.4973\n1.549\n15.165\n0.000\n20.460\n26.535\n\n\nheight_cm\n0.0110\n0.008\n1.296\n0.195\n-0.006\n0.028\n\n\n\n\n\n\n\n\nOmnibus:\n204.256\nDurbin-Watson:\n0.269\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n206.613\n\n\nSkew:\n0.427\nProb(JB):\n1.36e-45\n\n\nKurtosis:\n2.671\nCond. No.\n4.91e+03\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 4.91e+03. This might indicate that there arestrong multicollinearity or other numerical problems.\n\n\n\nThat’s a lot nicer than with scipy. We can also make a plot by getting the model’s \\(y\\) values with res.fittedvalues\n\nsns.relplot(data = df, x = \"height_cm\", y = \"age\")\nsns.lineplot(x = df[\"height_cm\"], y = res.fittedvalues, color = \"black\")\n\n\n\n\n\n\n\n\n\n\nGeneralised linear models\nThe statsmodels module has lots of advanced statistical models available. We’ll take a look at one more: Generalised Linear Models. The distributions they include are\n\nBinomial\nPoisson\nNegative Binomial\nGaussian (Normal)\nGamma\nInverse Gaussian\nTweedie\n\nWe’ll use the binomial option to create logistic regressions.\nLogistic regressions examine the distribution of binary data. For us, we can compare the heights of goalkeepers vs non-goalkeepers again. Let’s make a new column which is 1 for goalkeepers and 0 for non-goalkeepers:\n\ndf[\"gk\"] = (df[\"positions\"] == \"Goalkeeper\")*1\n\n\nMultiplying by 1 turns True \\(\\rightarrow\\) 1 and False \\(\\rightarrow\\) 0\n\nNow, we can model this column with height. Specifically,\n\\[ \\text{gk} \\sim \\text{height\\_cm}\\]\nStart by making the model with the function smf.glm(). We need to specify the family of distributions; they all live in sm.families, which comes from a different submodule that we should import:\n\nimport statsmodels.api as sm\nmod = smf.glm(\"gk ~ height_cm\", data = df, family = sm.families.Binomial())\n\nNext, evaluate the results\n\nres = mod.fit()\n\nLet’s have a look at the summary:\n\nres.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ngk\nNo. Observations:\n5932\n\n\nModel:\nGLM\nDf Residuals:\n5930\n\n\nModel Family:\nBinomial\nDf Model:\n1\n\n\nLink Function:\nLogit\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-1583.5\n\n\nDate:\nWed, 10 Dec 2025\nDeviance:\n3167.0\n\n\nTime:\n15:06:19\nPearson chi2:\n4.02e+03\n\n\nNo. Iterations:\n7\nPseudo R-squ. (CS):\n0.1879\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nIntercept\n-53.2336\n1.927\n-27.622\n0.000\n-57.011\n-49.456\n\n\nheight_cm\n0.2745\n0.010\n26.938\n0.000\n0.255\n0.294\n\n\n\n\n\nFinally, we can plot the result like before\n\nsns.relplot(data = df, x = \"height_cm\", y = \"gk\")\nsns.lineplot(x = df[\"height_cm\"], y = res.fittedvalues, color = \"black\")",
    "crumbs": [
      "Advanced topics",
      "Statistics"
    ]
  },
  {
    "objectID": "project/template.html",
    "href": "project/template.html",
    "title": "Project template",
    "section": "",
    "text": "The code below is a template for your project. Feel free to use it, start from scratch or begin from the example projects you can find on the details page (or in the project gallery).\n\nRPython\n\n\n---\ntitle: Your project title\nauthor: Your team members' names\ndate: The date\n# The following are optional but recommended\nwarning: false\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show code\"\n    code-tools: true\n---\n\n## Introduction\n\nReplace this code as necessary!\n\nYou can start with a brief introduction, and maybe some setup code.\n\n- What modules are you using?\n- What dataset are you using?\n- What will you investigate?\n\n```{python}\n# Set up code\nimport pandas as pd\n\n# Load the data?\n```\n\n## Next section\n\nYou might want to start with data cleaning or other options. Check out the example project for ideas. Good luck!\n\n\n---\ntitle: Your project title\nauthor: Your team members' names\ndate: The date\n# The following are optional but recommended\nwarning: false\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show code\"\n    code-tools: true\n---\n\n## Introduction\n\nReplace this code as necessary!\n\nYou can start with a brief introduction, and maybe some setup code.\n\n- What modules are you using?\n- What dataset are you using?\n- What will you investigate?\n\n```{python}\n# Set up code\nimport pandas as pd\n\n# Load the data?\n```\n\n## Next section\n\nYou might want to start with data cleaning or other options. Check out the example project for ideas. Good luck!",
    "crumbs": [
      "The Project",
      "Project template"
    ]
  },
  {
    "objectID": "project/details.html",
    "href": "project/details.html",
    "title": "Overview",
    "section": "",
    "text": "The best way to learn is by doing. That’s why, over the these three days, you are tasked with analysing, visualising and reporting on a set of data!\nRoughly 50% of our intensive is dedicated to working on the project. Working in groups of 2-4, you’ll need to use the techniques we learn to draw some observations about your chosen dataset.\nThe end goal will be a quick fire (low stakes) one-minute presentation with a dashboard to complement.\nSee the datasets page for the data and below for submission details.",
    "crumbs": [
      "The Project",
      "Overview"
    ]
  },
  {
    "objectID": "project/details.html#project-outline",
    "href": "project/details.html#project-outline",
    "title": "Overview",
    "section": "Project outline",
    "text": "Project outline\nThere are a few key requirements for the project, but otherwise it’s up to you!\n\nAnalyse a dataset and create some visualisations\nPut together a final quarto report. Anything from a single figure to an interactive website will do!\nDeliver a quick fire one-minute presentation with your group\n\nWe’ll have 4 sessions during the intensive days to work on the project, totalling about five hours. The goal of these sessions is twofold\n\nTo work on the project, analysing data and creating visualisations\nTo dive deeper into the content, perfect for questions and conversations\n\nWhile you’ll be working in groups, everyone should practise analysing and visualising the data. We recommend distributing roles amongst the group, maybe looking at different variables or different presentation formats.\nYou’re welcome to use the project time however you’d like. Below is a rough guide if you’re unsure:\n\n\n\n\n\n\n\nSession\nRecommendation\n\n\n\n\nTuesday afternoon\nPick a dataset and play with the data, consider dividing roles amongst group\n\n\nWednesday morning\nMore exploratory analysis, start making visualisations\n\n\nWednesday afternoon\nPrepare format, continue analysing and creating visualisation.\n\n\nThursday morning\nPolish up results and finalise report, submit.\n\n\n\nThe presentations will be our last session for the program, Thursday 12:00pm.\nGood luck!",
    "crumbs": [
      "The Project",
      "Overview"
    ]
  },
  {
    "objectID": "project/details.html#design-and-submissions",
    "href": "project/details.html#design-and-submissions",
    "title": "Overview",
    "section": "Design and submissions",
    "text": "Design and submissions\nWe recommend starting from our template.\nWe’ve also put together an example reports which you’re welcome to look at - you can download the code from there.\n\nRPython\n\n\n\n\n\n\n\n\n\n\n\n\nGoalkeepers and their heights\n\n\n\n\n\n\n\n\nJan 1, 2026\n\n\nCameron West and Stéphane Guillou\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoalkeepers and their heights\n\n\n\n\n\n\n\n\nFeb 1, 2026\n\n\nCameron West and Stéphane Guillou\n\n\n\n\n\nNo matching items\n\n\n\n\nFinally, you can also see a gallery of examples on Quarto’s website.\n\nUploading the submission\nBelow are two ways you can upload your visualisations.\nYou should consider where your dashboard gets its data from. Our repo has all datasets in the data_sources folder, so you have two options:\n\nInclude the data in your dashboard’s folder that you upload.\nUse the relative reference ../../data_sources/data_set_of_your_choice.csv to access the data on our repo\n\nWe’ve used the second option in the example project.\nWhen you are ready to upload, you have two options:\n\nUpload dashboard to GitHub\nThis is the advanced way of doing things - we recommend this way, because it’ll show you a good insight into using GitHub.\n\nCreate a GitHub account and log in\nCreate a fork of our python-training-intensive repository. This is a copy of the repo in your account, changes will not automatically affect the main repo. Leave all settings unchanged.\nCreate a folder for your dashboard inside the Projects directory\n\nGo into the Projects folder, and click Add file \\(\\rightarrow\\) Create new file. This will be your folder.\nGive it a name but no content.\nPress Commit changes....\n\nUpload your files\n\nGo into your new folder and click Add file \\(\\rightarrow\\) Upload files.\nUpload your dashboard and associated files.\nPress Commit changes.\n\nMerge your repo with ours\n\nPress &lt;&gt; Code (top left) to go back to the top level of the repo\nPress Contribute \\(\\rightarrow\\) Open pull request to request merging your files into the main repo\nPress Create pull request when you’re ready.\nIf you need to make further changes, no worries - the pull request will stay up to date with these until approved or closed.\n\n\nGive it a go if you can!\nIf there’s any issues, we’ll leave a comment for you to fix up the merge and we’ll approve it when ready.\n\n\nUpload dashboard to Teams\nIf you’re having issues with the GitHub approach, we can upload it for you. Just put your folder with the dashboard into our Teams folder.",
    "crumbs": [
      "The Project",
      "Overview"
    ]
  },
  {
    "objectID": "gallery/R/25Winter/example_project/example_project.html",
    "href": "gallery/R/25Winter/example_project/example_project.html",
    "title": "Goalkeepers and their heights",
    "section": "",
    "text": "Set up code\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(plotly)\nlibrary(knitr)\n\nplayers_raw &lt;- read.csv(\"../../../../data/Players2024.csv\")"
  },
  {
    "objectID": "gallery/R/25Winter/example_project/example_project.html#a-glimpse-at-the-dataset",
    "href": "gallery/R/25Winter/example_project/example_project.html#a-glimpse-at-the-dataset",
    "title": "Goalkeepers and their heights",
    "section": "A glimpse at the dataset",
    "text": "A glimpse at the dataset\nWe’ll begin just by taking a glimpse at the dataset:\n\n\nShow code\nkable(head(players_raw))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\nJames Milner\n1986-01-04\n175\nMidfield\nEngland\n38\nBrighton and Hove Albion Football Club\n\n\nAnastasios Tsokanis\n1991-05-02\n176\nMidfield\nGreece\n33\nVolou Neos Podosferikos Syllogos\n\n\nJonas Hofmann\n1992-07-14\n176\nMidfield\nGermany\n32\nBayer 04 Leverkusen Fußball\n\n\nPepe Reina\n1982-08-31\n188\nGoalkeeper\nSpain\n42\nCalcio Como\n\n\nLionel Carole\n1991-04-12\n180\nDefender\nFrance\n33\nKayserispor Kulübü\n\n\nLudovic Butelle\n1983-04-03\n188\nGoalkeeper\nFrance\n41\nStade de Reims"
  },
  {
    "objectID": "gallery/R/25Winter/example_project/example_project.html#cleaning-the-data",
    "href": "gallery/R/25Winter/example_project/example_project.html#cleaning-the-data",
    "title": "Goalkeepers and their heights",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nThe data has a few issues, as the following plot shows:\n\n\nShow code\nggplot(players_raw, aes(x = positions, y = height_cm)) +\n  geom_boxplot() \n\n\n\n\n\n\n\n\n\nShow code\n#sns.catplot(df_raw, x = \"positions\", y = \"height_cm\")\n\n\nIt looks like some of the players’ positions and heights were recorded incorrectly. To clean, let’s remove the “Missing” positions and ensure that heights are reasonable:\n\n\nShow code\n# Remove missing position and ensure reasonable heights\nplayers &lt;- players_raw %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n\n\nTo confirm, let’s plot the outliers in a different colour\n\n\nShow code\n# Identify outliers\noutliers &lt;- anti_join(players_raw, players)\n\n# Plot\nggplot(players, aes(x = positions, y = height_cm)) +\n  geom_boxplot() + \n  geom_point(data = outliers, colour = \"red\")"
  },
  {
    "objectID": "gallery/R/25Winter/example_project/example_project.html#visualising-the-players-heights",
    "href": "gallery/R/25Winter/example_project/example_project.html#visualising-the-players-heights",
    "title": "Goalkeepers and their heights",
    "section": "Visualising the players’ heights",
    "text": "Visualising the players’ heights\nAfter cleaning the data we can now analyse the players’ heights to see if there’s differences between positions. Let’s make the boxplot without the outliers\n\n\nShow code\nggplot(players, aes(x = positions, y = height_cm)) +\n  geom_boxplot() +\n  labs(x = \"Position\", y = \"Height (cm)\") \n\n\n\n\n\n\n\n\n\nShow code\nggsave(\"tb.png\")\n\n\nIt looks like goalkeepers are taller than the rest!\nLet’s through the age variable into the mix, to see if players’ heights allow them to compete longer.\n\n\nShow code\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\n\nggplotly(p)\n\n\n\n\n\n\nIt doesn’t look like there’s a relationship between heights and ages, but clearly it affects their position!"
  },
  {
    "objectID": "gallery/R/25Winter/example_project/example_project.html#global-spread",
    "href": "gallery/R/25Winter/example_project/example_project.html#global-spread",
    "title": "Goalkeepers and their heights",
    "section": "Global spread",
    "text": "Global spread\nWe haven’t looked at the nationality column yet. Let’s draw up a map using plotly to see where the players come from.\n\n\nShow code\n# Change country names to match plotly reference\nplayers &lt;- players %&gt;% \n  mutate(nationality = case_match(nationality,\n                                  \"England\" ~ \"United Kingdom\",\n                                  \"Türkiye\" ~ \"Turkey\",\n                                  \"Cote d'Ivoire\" ~ \"Ivory Coast\",\n                                  \"Northern Ireland\" ~ \"United Kingdom\",\n                                  \"Wales\" ~ \"United Kingdom\",\n                                  .default = nationality))\n    \n# Make the country count\ncountries &lt;- players %&gt;%\n  group_by(nationality) %&gt;%\n  summarise(n = n())\n\n# Make the plot\ncountries %&gt;% \n  plot_ly(type = \"choropleth\", \n          locations = countries$nationality, \n          locationmode = \"country names\", \n          z = countries$n) %&gt;%\n  colorbar(title = \"# of Players\")"
  },
  {
    "objectID": "gallery/R/25Winter/Swagata & Sandhya's Project/Queensland hospital dataanalysis.html",
    "href": "gallery/R/25Winter/Swagata & Sandhya's Project/Queensland hospital dataanalysis.html",
    "title": "Queensland hospitals data analysis",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "gallery/R/25Winter/Swagata & Sandhya's Project/Queensland hospital dataanalysis.html#quarto-uses-markdown",
    "href": "gallery/R/25Winter/Swagata & Sandhya's Project/Queensland hospital dataanalysis.html#quarto-uses-markdown",
    "title": "Queensland hospitals data analysis",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "gallery/R/25Winter/Swagata & Sandhya's Project/Queensland hospital dataanalysis.html#running-code",
    "href": "gallery/R/25Winter/Swagata & Sandhya's Project/Queensland hospital dataanalysis.html#running-code",
    "title": "Queensland hospitals data analysis",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nlibrary(\"dplyr\")\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(\"ggplot2\")\nlibrary(\"plotly\")\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ plotly::filter() masks dplyr::filter(), stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nhospital_data &lt;- read.csv('../../../../data/hospital_data.csv')\n\n\n# Aggregate data per hospital (mean if multiple entries per hospital)\nplot_data &lt;- hospital_data %&gt;%\n  group_by(Facility.HHS.Desc) %&gt;%\n  summarise(avg_no_wait = mean(Patients.who.did.not.wait.for.treatment...., na.rm = TRUE)) %&gt;%\n  arrange(desc(avg_no_wait)) %&gt;%\n  slice_max(avg_no_wait, n = 20)  # Top 20\n\n# Create clearer horizontal barplot\nggplot(plot_data, aes(x = reorder(Facility.HHS.Desc, \n                                  avg_no_wait),\n                      y = avg_no_wait,\n                      fill = avg_no_wait)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Top 20 Hospitals by % of Patients Who Left Without Treatment\",\n    x = \"Hospital\",\n    y = \"% of Patients Who Did Not Wait\"\n  ) +\n  scale_fill_gradient(low = \"skyblue\", high = \"red\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.text.y = element_text(size = 11)\n  )\n\n\n\n\n\n\n\n# Calculate the average % of patients who did not wait per hospital\n\nbottom_20_plot_data &lt;- hospital_data %&gt;%\n  group_by(Facility.HHS.Desc) %&gt;%\n  summarise(avg_no_wait = mean(Patients.who.did.not.wait.for.treatment...., \n                               na.rm = TRUE)) %&gt;%\n  arrange(avg_no_wait) %&gt;%\n  slice_min(avg_no_wait, n = 20)  # Bottom 20 hospitals\n\n# Plot: bottom 20 hospitals with the lowest no-wait percentage\nggplot(bottom_20_plot_data, aes(x = reorder(Facility.HHS.Desc, avg_no_wait), y = avg_no_wait, fill = avg_no_wait)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Bottom 20 Hospitals by % of Patients Who Left Without Treatment\",\n    x = \"Hospital\",\n    y = \"% of Patients Who Did Not Wait\"\n  ) +\n  scale_fill_gradient(low = \"forestgreen\", high = \"yellow\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.text.y = element_text(size = 11))\n\n\n\n\n\n\n\n# Summarize total attendances per hospital (in case of duplicates or multiple rows)\ntop_20_attendance &lt;- hospital_data %&gt;%\n  group_by(Facility.HHS.Desc) %&gt;%\n  summarise(total_attendances = sum(Number.of.Attendances, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_attendances)) %&gt;%\n  slice_max(total_attendances, n = 20)\n\n# Plot the top 20 hospitals by attendance\nggplot(top_20_attendance, aes(x = reorder(Facility.HHS.Desc, total_attendances),\n                              y = total_attendances,\n                              fill = total_attendances)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Top 20 Hospitals by Number of Attendances\",\n    x = \"Hospital\",\n    y = \"Number of Attendances\"\n  ) +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.text.y = element_text(size = 11)\n  )\n\n\n\n\n\n\n\n# Filter for Triage 1, calculate average wait time, select top 20\nhospital_data |&gt;\n  filter(Triage.Category == \"1\") |&gt;\n  group_by(Facility.HHS.Desc) |&gt;\n  summarise(avg_wait = mean(Median.Waiting.time.to.treatment..minutes., na.rm = TRUE)) |&gt;\n  arrange(desc(avg_wait)) |&gt;\n  slice_max(avg_wait, n = 20) |&gt;\n  ggplot(aes(x = reorder(Facility.HHS.Desc, avg_wait), y = avg_wait)) +\n  geom_col(fill = \"darkred\") +\n  geom_text(aes(label = round(avg_wait, 1)), hjust = -0.1, size = 3.5, color = \"black\") +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 120)) +\n  labs(\n    title = \"Top 20 Hospitals by Average Wait Time (Triage 1)\",\n    x = \"Hospital\",\n    y = \"Average Waiting Time (Minutes)\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5),\n        axis.text.y = element_text(size = 11))\n\n\n\n\n\n\n\n# Analyze data by center\nTop_20 &lt;- hospital_data%&gt;%\n  filter(Facility.HHS.Desc!=\"Queensland\", Facility.HHS.Desc!=\"QUEENSLAND\")%&gt;%\n  group_by(Facility.HHS.Desc)%&gt;% \n  summarise(Number.of.Attendances = mean(Number.of.Attendances, na.rm=TRUE))%&gt;%\n  arrange(desc(Number.of.Attendances))%&gt;%\n  slice_max(Number.of.Attendances, n=20) \nTop_20 &lt;- arrange(Top_20, desc(Number.of.Attendances))\n\nlibrary(forcats)\n#Visualize using ggplot\nggplot(Top_20, aes(x = fct_inorder(Facility.HHS.Desc), y = Number.of.Attendances)) +\n  geom_col(fill = \"steelblue\") +\n  labs(title = \"Hospital Attendances\",\n       x = \"Facility\",\n       y = \"Number of Attendances\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n# Step 1: Identify top 10 hospitals by total attendance\ntop_10_hospitals &lt;- hospital_data |&gt;\n  group_by(Facility.HHS.Desc) |&gt;\n  summarise(total_attendance = sum(Number.of.Attendances, na.rm = TRUE), .groups = \"drop\") |&gt;\n  arrange(desc(total_attendance)) |&gt;\n  slice_max(total_attendance, n = 10)\n\n# Step 2: Filter main dataset for only these top hospitals\ntop_data &lt;- hospital_data |&gt;\n  filter(Facility.HHS.Desc %in% top_10_hospitals$Facility.HHS.Desc)\n\n# Step 3: Compute average waiting time for heatmap\nheatmap_data &lt;- top_data |&gt;\n  group_by(Facility.HHS.Desc, Triage.Category) |&gt;\n  summarise(Avg_Wait = mean(Median.Waiting.time.to.treatment..minutes., na.rm = TRUE), .groups = \"drop\")\n\n# Step 4: Create heatmap\nggplot(heatmap_data, aes(x = Triage.Category, y = Facility.HHS.Desc, fill = Avg_Wait)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(\n    name = \"Avg Wait (min)\",\n    low = \"lightyellow\",   # shortest waits\n    high = \"darkred\",      # longest waits\n    na.value = \"grey90\"\n  ) +\n  labs(\n    title = \"Avg Waiting Time (Top 10 Hospitals by Attendance)\",\n    x = \"Triage Category\",\n    y = \"Hospital\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 9),\n    plot.title = element_text(hjust = 0.5, face = \"bold\")\n  )\n\n\n\n\n\n\n\n# Group and summarise\ncor_data &lt;- hospital_data |&gt;\n  group_by(Facility.HHS.Desc) |&gt;\n  summarise(\n    avg_wait = mean(Median.Waiting.time.to.treatment..minutes., na.rm = TRUE),\n    total_attendance = sum(Number.of.Attendances, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Pearson correlation\ncor.test(cor_data$avg_wait, cor_data$total_attendance, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  cor_data$avg_wait and cor_data$total_attendance\nt = 1.528, df = 208, p-value = 0.128\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.03046599  0.23736356\nsample estimates:\n     cor \n0.105359 \n\n# Create contingency table\nwait_table &lt;- table(hospital_data$Triage.Category, hospital_data$Patients.who.did.not.wait.for.treatment....)\n\n# Chi-square test\nchisq.test(wait_table)\n\nWarning in chisq.test(wait_table): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  wait_table\nX-squared = 20474, df = 16662, p-value &lt; 2.2e-16\n\nhospital_data |&gt;\n  group_by(Facility.HHS.Desc) |&gt;\n  summarise(\n    mean_wait = mean(Median.Waiting.time.to.treatment..minutes., na.rm = TRUE),\n    sd_wait = sd(Median.Waiting.time.to.treatment..minutes., na.rm = TRUE),\n    iqr_wait = IQR(Median.Waiting.time.to.treatment..minutes., na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(mean_wait)) |&gt; \n  slice_head(n = 10)\n\n# A tibble: 10 × 4\n   Facility.HHS.Desc        mean_wait sd_wait iqr_wait\n   &lt;chr&gt;                        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 Caloundra Hospital            66.6    32.3     40.5\n 2 Roma Hospital                 66.5    43.3     85.3\n 3 Cooktown Hospital             65.0    40.8     78.1\n 4 Thursday Island Hospital      65.0    45.5     93.7\n 5 Longreach Hospital            64.8    45.3     92.0\n 6 Bamaga Hospital               64.8    42.0     86.2\n 7 Doomadgee Hospital            64.7    43.5     89.1\n 8 Moranbah Hospital             64.6    46.0     94.6\n 9 Cherbourg Hospital            64.4    40.3     78.5\n10 Charleville Hospital          64.2    47.9    100  \n\n# Simple linear model\nlm_model &lt;- lm(Median.Waiting.time.to.treatment..minutes. ~ Triage.Category + Number.of.Attendances, data = hospital_data)\nsummary(lm_model)\n\n\nCall:\nlm(formula = Median.Waiting.time.to.treatment..minutes. ~ Triage.Category + \n    Number.of.Attendances, data = hospital_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-63.24 -49.29  17.57  38.75  47.62 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            5.573e+01  1.112e+00  50.115  &lt; 2e-16 ***\nTriage.Category2      -3.334e+00  1.532e+00  -2.177  0.02952 *  \nTriage.Category3      -1.425e+00  1.532e+00  -0.930  0.35249    \nTriage.Category4       3.045e+00  1.531e+00   1.989  0.04677 *  \nTriage.Category5       7.514e+00  1.530e+00   4.910 9.24e-07 ***\nTriage.CategoryAll    -4.580e+01  4.223e+00 -10.844  &lt; 2e-16 ***\nTriage.CategoryALL     4.218e+00  1.566e+00   2.694  0.00708 ** \nNumber.of.Attendances -2.778e-05  1.602e-05  -1.734  0.08295 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.71 on 9266 degrees of freedom\n  (168 observations deleted due to missingness)\nMultiple R-squared:  0.02211,   Adjusted R-squared:  0.02137 \nF-statistic: 29.92 on 7 and 9266 DF,  p-value: &lt; 2.2e-16\n\nggplot(hospital_data, aes(x = Number.of.Attendances, y = Median.Waiting.time.to.treatment..minutes.)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(title = \"Effect of Attendance on Waiting Time\", x = \"Attendances\", y = \"Waiting Time (min)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 168 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 168 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html",
    "href": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html",
    "title": "QLD Fuel",
    "section": "",
    "text": "fuel &lt;- read.csv(\"../../../../data/qld_fuel.csv\")\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#import-the-dataset-load-packages",
    "href": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#import-the-dataset-load-packages",
    "title": "QLD Fuel",
    "section": "",
    "text": "fuel &lt;- read.csv(\"../../../../data/qld_fuel.csv\")\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#distribution-of-fuel-sites-grouped-by-fuel-type",
    "href": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#distribution-of-fuel-sites-grouped-by-fuel-type",
    "title": "QLD Fuel",
    "section": "Distribution of Fuel Sites, grouped by Fuel type",
    "text": "Distribution of Fuel Sites, grouped by Fuel type\n\nfuel |&gt; \n  ggplot(aes(x = Site_Latitude, y = Site_Longitude)) + \n  geom_jitter(aes(colour = Fuel_Type, label = Site_Suburb))\n\nWarning in geom_jitter(aes(colour = Fuel_Type, label = Site_Suburb)): Ignoring\nunknown aesthetics: label"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#most-popular-fuel-type",
    "href": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#most-popular-fuel-type",
    "title": "QLD Fuel",
    "section": "Most popular Fuel Type",
    "text": "Most popular Fuel Type\n\nfuel |&gt; \n  ggplot(aes(x = Fuel_Type)) + \n  geom_bar()"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#price-by-fuel-type",
    "href": "gallery/R/25Winter/Claudine & Emman/QLD_fuel.html#price-by-fuel-type",
    "title": "QLD Fuel",
    "section": "Price by Fuel Type",
    "text": "Price by Fuel Type\n\nfuel |&gt; \n  group_by(Fuel_Type) |&gt; \n  summarise(mean_Price = mean(Price)) |&gt; \n  ggplot() + \n  geom_col(aes(y = mean_Price, x = Fuel_Type))"
  },
  {
    "objectID": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html",
    "href": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html",
    "title": "Population: Presentation for R training",
    "section": "",
    "text": "The population dataset contains detailed population data (21983 observations) across 59 variables, including region, population, growth rate, births, deaths, and fertility over a wide year range. It also includes data on migration. Many of the variables are gender disaggregated."
  },
  {
    "objectID": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#population-the-data-set",
    "href": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#population-the-data-set",
    "title": "Population: Presentation for R training",
    "section": "",
    "text": "The population dataset contains detailed population data (21983 observations) across 59 variables, including region, population, growth rate, births, deaths, and fertility over a wide year range. It also includes data on migration. Many of the variables are gender disaggregated."
  },
  {
    "objectID": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#research-aim",
    "href": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#research-aim",
    "title": "Population: Presentation for R training",
    "section": "Research aim",
    "text": "Research aim\nThe aim of this project is to explore how the population varies over time in Cambodia, including differences between men and women."
  },
  {
    "objectID": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#step-1-import-explore-and-cut-down-data-set",
    "href": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#step-1-import-explore-and-cut-down-data-set",
    "title": "Population: Presentation for R training",
    "section": "Step 1: Import, explore and cut-down data set",
    "text": "Step 1: Import, explore and cut-down data set\nFirst, I imported the data set and libraries.\n\n# import csv\npopulation &lt;-read.csv(\"../../../../data/population.csv\")\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\nSecond, I explore regions, viewing just the output.\n\n\n  [1] \"World\"                                                      \n  [2] \"Sustainable Development Goal (SDG) regions\"                 \n  [3] \"Sub-Saharan Africa\"                                         \n  [4] \"Northern Africa and Western Asia\"                           \n  [5] \"Central and Southern Asia\"                                  \n  [6] \"Eastern and South-Eastern Asia\"                             \n  [7] \"Latin America and the Caribbean\"                            \n  [8] \"Oceania (excluding Australia and New Zealand)\"              \n  [9] \"Australia/New Zealand\"                                      \n [10] \"Europe and Northern America\"                                \n [11] \"Europe, Northern America, Australia, and New Zealand\"       \n [12] \"UN development groups\"                                      \n [13] \"More developed regions\"                                     \n [14] \"Less developed regions\"                                     \n [15] \"Least developed countries\"                                  \n [16] \"Less developed regions, excluding least developed countries\"\n [17] \"Less developed regions, excluding China\"                    \n [18] \"Land-locked Developing Countries (LLDC)\"                    \n [19] \"LLDC: Africa\"                                               \n [20] \"LLDC: Asia\"                                                 \n [21] \"LLDC: Europe\"                                               \n [22] \"LLDC: Latin America\"                                        \n [23] \"Small Island Developing States (SIDS)\"                      \n [24] \"SIDS Caribbean\"                                             \n [25] \"SIDS Pacific\"                                               \n [26] \"SIDS Atlantic, Indian Ocean and South China Sea (AIS)\"      \n [27] \"World Bank income groups\"                                   \n [28] \"High-and-upper-middle-income countries\"                     \n [29] \"Low-and-Lower-middle-income countries\"                      \n [30] \"High-income countries\"                                      \n [31] \"Low-and-middle-income countries\"                            \n [32] \"Middle-income countries\"                                    \n [33] \"Upper-middle-income countries\"                              \n [34] \"Lower-middle-income countries\"                              \n [35] \"Low-income countries\"                                       \n [36] \"No income group available\"                                  \n [37] \"Geographic regions\"                                         \n [38] \"Africa\"                                                     \n [39] \"Eastern Africa\"                                             \n [40] \"Burundi\"                                                    \n [41] \"Comoros\"                                                    \n [42] \"Djibouti\"                                                   \n [43] \"Eritrea\"                                                    \n [44] \"Ethiopia\"                                                   \n [45] \"Kenya\"                                                      \n [46] \"Madagascar\"                                                 \n [47] \"Malawi\"                                                     \n [48] \"Mauritius\"                                                  \n [49] \"Mayotte\"                                                    \n [50] \"Mozambique\"                                                 \n [51] \"Réunion\"                                                    \n [52] \"Rwanda\"                                                     \n [53] \"Seychelles\"                                                 \n [54] \"Somalia\"                                                    \n [55] \"South Sudan\"                                                \n [56] \"Uganda\"                                                     \n [57] \"United Republic of Tanzania\"                                \n [58] \"Zambia\"                                                     \n [59] \"Zimbabwe\"                                                   \n [60] \"Middle Africa\"                                              \n [61] \"Angola\"                                                     \n [62] \"Cameroon\"                                                   \n [63] \"Central African Republic\"                                   \n [64] \"Chad\"                                                       \n [65] \"Congo\"                                                      \n [66] \"Democratic Republic of the Congo\"                           \n [67] \"Equatorial Guinea\"                                          \n [68] \"Gabon\"                                                      \n [69] \"Sao Tome and Principe\"                                      \n [70] \"Northern Africa\"                                            \n [71] \"Algeria\"                                                    \n [72] \"Egypt\"                                                      \n [73] \"Libya\"                                                      \n [74] \"Morocco\"                                                    \n [75] \"Sudan\"                                                      \n [76] \"Tunisia\"                                                    \n [77] \"Western Sahara\"                                             \n [78] \"Southern Africa\"                                            \n [79] \"Botswana\"                                                   \n [80] \"Eswatini\"                                                   \n [81] \"Lesotho\"                                                    \n [82] \"Namibia\"                                                    \n [83] \"South Africa\"                                               \n [84] \"Western Africa\"                                             \n [85] \"Benin\"                                                      \n [86] \"Burkina Faso\"                                               \n [87] \"Cabo Verde\"                                                 \n [88] \"Côte d'Ivoire\"                                              \n [89] \"Gambia\"                                                     \n [90] \"Ghana\"                                                      \n [91] \"Guinea\"                                                     \n [92] \"Guinea-Bissau\"                                              \n [93] \"Liberia\"                                                    \n [94] \"Mali\"                                                       \n [95] \"Mauritania\"                                                 \n [96] \"Niger\"                                                      \n [97] \"Nigeria\"                                                    \n [98] \"Saint Helena\"                                               \n [99] \"Senegal\"                                                    \n[100] \"Sierra Leone\"                                               \n[101] \"Togo\"                                                       \n[102] \"Asia\"                                                       \n[103] \"Central Asia\"                                               \n[104] \"Kazakhstan\"                                                 \n[105] \"Kyrgyzstan\"                                                 \n[106] \"Tajikistan\"                                                 \n[107] \"Turkmenistan\"                                               \n[108] \"Uzbekistan\"                                                 \n[109] \"Eastern Asia\"                                               \n[110] \"China\"                                                      \n[111] \"China, Hong Kong SAR\"                                       \n[112] \"China, Macao SAR\"                                           \n[113] \"China, Taiwan Province of China\"                            \n[114] \"Dem. People's Republic of Korea\"                            \n[115] \"Japan\"                                                      \n[116] \"Mongolia\"                                                   \n[117] \"Republic of Korea\"                                          \n[118] \"Southern Asia\"                                              \n[119] \"Afghanistan\"                                                \n[120] \"Bangladesh\"                                                 \n[121] \"Bhutan\"                                                     \n[122] \"India\"                                                      \n[123] \"Iran (Islamic Republic of)\"                                 \n[124] \"Maldives\"                                                   \n[125] \"Nepal\"                                                      \n[126] \"Pakistan\"                                                   \n[127] \"Sri Lanka\"                                                  \n[128] \"South-Eastern Asia\"                                         \n[129] \"Brunei Darussalam\"                                          \n[130] \"Cambodia\"                                                   \n[131] \"Indonesia\"                                                  \n[132] \"Lao People's Democratic Republic\"                           \n[133] \"Malaysia\"                                                   \n[134] \"Myanmar\"                                                    \n[135] \"Philippines\"                                                \n[136] \"Singapore\"                                                  \n[137] \"Thailand\"                                                   \n[138] \"Timor-Leste\"                                                \n[139] \"Viet Nam\"                                                   \n[140] \"Western Asia\"                                               \n[141] \"Armenia\"                                                    \n[142] \"Azerbaijan\"                                                 \n[143] \"Bahrain\"                                                    \n[144] \"Cyprus\"                                                     \n[145] \"Georgia\"                                                    \n[146] \"Iraq\"                                                       \n[147] \"Israel\"                                                     \n[148] \"Jordan\"                                                     \n[149] \"Kuwait\"                                                     \n[150] \"Lebanon\"                                                    \n[151] \"Oman\"                                                       \n[152] \"Qatar\"                                                      \n[153] \"Saudi Arabia\"                                               \n[154] \"State of Palestine\"                                         \n[155] \"Syrian Arab Republic\"                                       \n[156] \"Türkiye\"                                                    \n[157] \"United Arab Emirates\"                                       \n[158] \"Yemen\"                                                      \n[159] \"Europe\"                                                     \n[160] \"Eastern Europe\"                                             \n[161] \"Belarus\"                                                    \n[162] \"Bulgaria\"                                                   \n[163] \"Czechia\"                                                    \n[164] \"Hungary\"                                                    \n[165] \"Poland\"                                                     \n[166] \"Republic of Moldova\"                                        \n[167] \"Romania\"                                                    \n[168] \"Russian Federation\"                                         \n[169] \"Slovakia\"                                                   \n[170] \"Ukraine\"                                                    \n[171] \"Northern Europe\"                                            \n[172] \"Denmark\"                                                    \n[173] \"Estonia\"                                                    \n[174] \"Faroe Islands\"                                              \n[175] \"Finland\"                                                    \n[176] \"Guernsey\"                                                   \n[177] \"Iceland\"                                                    \n[178] \"Ireland\"                                                    \n[179] \"Isle of Man\"                                                \n[180] \"Jersey\"                                                     \n[181] \"Latvia\"                                                     \n[182] \"Lithuania\"                                                  \n[183] \"Norway\"                                                     \n[184] \"Sweden\"                                                     \n[185] \"United Kingdom\"                                             \n[186] \"Southern Europe\"                                            \n[187] \"Albania\"                                                    \n[188] \"Andorra\"                                                    \n[189] \"Bosnia and Herzegovina\"                                     \n[190] \"Croatia\"                                                    \n[191] \"Gibraltar\"                                                  \n[192] \"Greece\"                                                     \n[193] \"Holy See\"                                                   \n[194] \"Italy\"                                                      \n[195] \"Kosovo (under UNSC res. 1244)\"                              \n[196] \"Malta\"                                                      \n[197] \"Montenegro\"                                                 \n[198] \"North Macedonia\"                                            \n[199] \"Portugal\"                                                   \n[200] \"San Marino\"                                                 \n[201] \"Serbia\"                                                     \n[202] \"Slovenia\"                                                   \n[203] \"Spain\"                                                      \n[204] \"Western Europe\"                                             \n[205] \"Austria\"                                                    \n[206] \"Belgium\"                                                    \n[207] \"France\"                                                     \n[208] \"Germany\"                                                    \n[209] \"Liechtenstein\"                                              \n[210] \"Luxembourg\"                                                 \n[211] \"Monaco\"                                                     \n[212] \"Netherlands\"                                                \n[213] \"Switzerland\"                                                \n[214] \"Americas\"                                                   \n[215] \"Caribbean\"                                                  \n[216] \"Anguilla\"                                                   \n[217] \"Antigua and Barbuda\"                                        \n[218] \"Aruba\"                                                      \n[219] \"Bahamas\"                                                    \n[220] \"Barbados\"                                                   \n[221] \"Bonaire, Sint Eustatius and Saba\"                           \n[222] \"British Virgin Islands\"                                     \n[223] \"Cayman Islands\"                                             \n[224] \"Cuba\"                                                       \n[225] \"Curaçao\"                                                    \n[226] \"Dominica\"                                                   \n[227] \"Dominican Republic\"                                         \n[228] \"Grenada\"                                                    \n[229] \"Guadeloupe\"                                                 \n[230] \"Haiti\"                                                      \n[231] \"Jamaica\"                                                    \n[232] \"Martinique\"                                                 \n[233] \"Montserrat\"                                                 \n[234] \"Puerto Rico\"                                                \n[235] \"Saint Barthélemy\"                                           \n[236] \"Saint Kitts and Nevis\"                                      \n[237] \"Saint Lucia\"                                                \n[238] \"Saint Martin (French part)\"                                 \n[239] \"Saint Vincent and the Grenadines\"                           \n[240] \"Sint Maarten (Dutch part)\"                                  \n[241] \"Trinidad and Tobago\"                                        \n[242] \"Turks and Caicos Islands\"                                   \n[243] \"United States Virgin Islands\"                               \n[244] \"Central America\"                                            \n[245] \"Belize\"                                                     \n[246] \"Costa Rica\"                                                 \n[247] \"El Salvador\"                                                \n[248] \"Guatemala\"                                                  \n[249] \"Honduras\"                                                   \n[250] \"Mexico\"                                                     \n[251] \"Nicaragua\"                                                  \n[252] \"Panama\"                                                     \n[253] \"South America\"                                              \n[254] \"Argentina\"                                                  \n[255] \"Bolivia (Plurinational State of)\"                           \n[256] \"Brazil\"                                                     \n[257] \"Chile\"                                                      \n[258] \"Colombia\"                                                   \n[259] \"Ecuador\"                                                    \n[260] \"Falkland Islands (Malvinas)\"                                \n[261] \"French Guiana\"                                              \n[262] \"Guyana\"                                                     \n[263] \"Paraguay\"                                                   \n[264] \"Peru\"                                                       \n[265] \"Suriname\"                                                   \n[266] \"Uruguay\"                                                    \n[267] \"Venezuela (Bolivarian Republic of)\"                         \n[268] \"Northern America\"                                           \n[269] \"Bermuda\"                                                    \n[270] \"Canada\"                                                     \n[271] \"Greenland\"                                                  \n[272] \"Saint Pierre and Miquelon\"                                  \n[273] \"United States of America\"                                   \n[274] \"Oceania\"                                                    \n[275] \"Australia\"                                                  \n[276] \"New Zealand\"                                                \n[277] \"Melanesia\"                                                  \n[278] \"Fiji\"                                                       \n[279] \"New Caledonia\"                                              \n[280] \"Papua New Guinea\"                                           \n[281] \"Solomon Islands\"                                            \n[282] \"Vanuatu\"                                                    \n[283] \"Micronesia\"                                                 \n[284] \"Guam\"                                                       \n[285] \"Kiribati\"                                                   \n[286] \"Marshall Islands\"                                           \n[287] \"Micronesia (Fed. States of)\"                                \n[288] \"Nauru\"                                                      \n[289] \"Northern Mariana Islands\"                                   \n[290] \"Palau\"                                                      \n[291] \"Polynesia\"                                                  \n[292] \"American Samoa\"                                             \n[293] \"Cook Islands\"                                               \n[294] \"French Polynesia\"                                           \n[295] \"Niue\"                                                       \n[296] \"Samoa\"                                                      \n[297] \"Tokelau\"                                                    \n[298] \"Tonga\"                                                      \n[299] \"Tuvalu\"                                                     \n[300] \"Wallis and Futuna Islands\"                                  \n\n\nThird, I limited the data file to Cambodia by creating a new object.\nFourth, I limited the variables in the new object to those of interest for the research questions, by using a self referential selection on the object."
  },
  {
    "objectID": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#step-2-make-the-data-set-more-user-friendly",
    "href": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#step-2-make-the-data-set-more-user-friendly",
    "title": "Population: Presentation for R training",
    "section": "Step 2: Make the data set more user friendly",
    "text": "Step 2: Make the data set more user friendly\nAs I worked with the new data set, I simplified the icky variable names by defining a new set of names\n\nnew_names &lt;- c(\"Year\", \"TotalPop\", \"Age\", \"Migrants\", \"Males\", \"Females\", \"Births\", \"Dead_men\", \"Male_expect\", \"Dead_women\", \"Female_expect\")\ncolnames(Population_cam) &lt;- new_names"
  },
  {
    "objectID": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#step-3-data-analysis",
    "href": "gallery/R/25Winter/Chris/Population - Presentation for R Training.html#step-3-data-analysis",
    "title": "Population: Presentation for R training",
    "section": "Step 3: Data analysis",
    "text": "Step 3: Data analysis\n\nPopulation over time\nThis analysis below clearly shows the impact of the civil war and genocide on the Cambodian population.\n\nggplot (Population_cam,\naes (x = Year,  y = TotalPop)) +\ngeom_point() +\n  labs (caption = \"Total Population over time\", x = \"Year\", y = \"Population\")\n\n\n\n\n\n\n\n\nA comparison of males (blue) and females (pink) shows that the male population was more strongly affected and has yet to recover. While we would typically expect some skewing in the number of men based on female biased gender ratios (global pattern), Cambodia’s gender ratio is outside of usual ranges, due to the gendered impact of civil war and genocide on men (NIS 2019).\n\nggplot (Population_cam,\naes (x = Year,  y = TotalPop)) +\ngeom_point(aes(y = Males), colour=\"blue\") +\n  geom_point(aes(y = TotalPop), colour=\"black\") +\ngeom_point(aes(y = Females), colour = \"pink\") +\n  labs (caption = \"Population over time, by total and by gender\", x = \"Year\", y = \"Population\")\n\n\n\n\n\n\n\n\n\n\nAverage age over time\nGiven the total population changes, we would expect that average ages would change around the years of decline and incline in population, to reflect births / deaths and their impact on the age structure of the population.\nThis scatterplot was drawn to investigate. It illustrates the expected dip in average age during the civil war and genocide in the 1970s (which adversly affected older generations). However, it also illustrates a significant decline in age in the mid-1990s. This, with reasonably stable population change could mean either both a jump in deaths of older people and a jump in birth rate, or alternatively, a massive influx of younger migrants. If neither are true, then there is a data error in the base data set.\n\nggplot (Population_cam,\naes (x = Year,  y = Age)) +\ngeom_point()+\n  labs (caption = \"Average age by year\", x = \"Year\", y = \"Age\")\n\n\n\n\n\n\n\n\nThis analysis indicates unusual patterns in the orange line - migrants - driving the age changes seen in the 1990s\n\nggplot (Population_cam,\naes (x = Year,  y = TotalPop)) +\ngeom_point(aes(y = Births), colour=\"green\") +\n  geom_point(aes(y = Dead_men), colour=\"blue\") +\ngeom_point(aes(y = Dead_women), colour = \"pink\") +\n  geom_point (aes(y = Migrants), colour = \"orange\")+\n  labs (caption = \"Population over time, by births (green), male deaths (blue), female deaths (pink), and migrants (orange)\", x = \"Year\", y = \"Population\")\n\n\n\n\n\n\n\n\nIts next worth checking the average age of migrants to see if this might be the case - we can check summary (where we see the average number is low), and then by age, where we see emmigration (negative migration in the graph) is older people, and higher levels of immigration (positive migration) likely to cause the blip are younger people &lt;5 years of age. In reality, it is highly unlikely that a sudden influx of infants without adults occured.\n\nsummary (Population_cam$Migrants)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-193.008  -52.841  -21.504    7.204   -3.800  508.187 \n\n\n\nggplot(Population_cam,\n       aes(x = Migrants, y = Age)) + \n  geom_point()+\n  labs (caption = \"Migrant ages, all years\")\n\n\n\n\n\n\n\n\nWe could also run an linear model to see the extent to which variation in the population over time correlates with each of migration, male deaths, female deaths, and births.\nMigrants - poor explanation\n\n\n[1] 0.005408874\n\n\nBirths - explains significantly more\n\n\n[1] 0.6376123\n\n\nMale deaths - poor explanation\n\n\n[1] 0.05946311\n\n\nFemale deaths - poor explanation\n\n\n[1] 0.04332331\n\n\nA covariance shows strong correlation.\n\ncov (Population_cam$Year, Population_cam$TotalPop)\n\n[1] 86095.7\n\n\n\n\nConclusion\nIn this dataset, it appears that Births are a better predicter of total population than any other factor.\nThis analysis has identified what appears to be an issue with the migrant age data for some years, given a lack of reasoning for why large numbers of young people would be comming across the border; this is most likely a data recording issue for age of migrants."
  },
  {
    "objectID": "gallery/R/25Winter/Andrew Proj/report.html",
    "href": "gallery/R/25Winter/Andrew Proj/report.html",
    "title": "Workshop Project Report",
    "section": "",
    "text": "We are using the png, ggpubr, tidyverse and plotly libraries to examine our data. We can install and enable these libraries as follows, using an if loop to prevent repeat installation.\n\ninst_list = c(\"tidyverse\", \"plotly\", \"png\", \"ggpubr\")\n\nfor(i in inst_list){\n  if(!inst_list[i] %in% installed.packages()){\n    print(inst_list[i])\n    install.packages(inst_list[i])\n  }\n}\n\nlibrary(png)\nlibrary(ggpubr)\nlibrary(tidyverse)\nlibrary(plotly)"
  },
  {
    "objectID": "gallery/R/25Winter/Andrew Proj/report.html#analysing-a-dataset-in-r",
    "href": "gallery/R/25Winter/Andrew Proj/report.html#analysing-a-dataset-in-r",
    "title": "Workshop Project Report",
    "section": "",
    "text": "We are using the png, ggpubr, tidyverse and plotly libraries to examine our data. We can install and enable these libraries as follows, using an if loop to prevent repeat installation.\n\ninst_list = c(\"tidyverse\", \"plotly\", \"png\", \"ggpubr\")\n\nfor(i in inst_list){\n  if(!inst_list[i] %in% installed.packages()){\n    print(inst_list[i])\n    install.packages(inst_list[i])\n  }\n}\n\nlibrary(png)\nlibrary(ggpubr)\nlibrary(tidyverse)\nlibrary(plotly)"
  },
  {
    "objectID": "gallery/R/25Winter/Andrew Proj/report.html#melbourne-housing-data",
    "href": "gallery/R/25Winter/Andrew Proj/report.html#melbourne-housing-data",
    "title": "Workshop Project Report",
    "section": "Melbourne Housing Data",
    "text": "Melbourne Housing Data\nThe dataset we have chosen is the Melbourne Housing Dataset. We can import the data and run a summary as follows:\n\nmelb_data_raw &lt;- read.csv(\"data/melb_data.csv\")\nsummary(melb_data_raw)\n\n       X            Suburb            Address              Rooms       \n Min.   :    1   Length:13580       Length:13580       Min.   : 1.000  \n 1st Qu.: 3396   Class :character   Class :character   1st Qu.: 2.000  \n Median : 6790   Mode  :character   Mode  :character   Median : 3.000  \n Mean   : 6790                                         Mean   : 2.938  \n 3rd Qu.:10185                                         3rd Qu.: 3.000  \n Max.   :13580                                         Max.   :10.000  \n                                                                       \n     Type               Price            Method            SellerG         \n Length:13580       Min.   :  85000   Length:13580       Length:13580      \n Class :character   1st Qu.: 650000   Class :character   Class :character  \n Mode  :character   Median : 903000   Mode  :character   Mode  :character  \n                    Mean   :1075684                                        \n                    3rd Qu.:1330000                                        \n                    Max.   :9000000                                        \n                                                                           \n     Date              Distance        Postcode       Bedroom2     \n Length:13580       Min.   : 0.00   Min.   :3000   Min.   : 0.000  \n Class :character   1st Qu.: 6.10   1st Qu.:3044   1st Qu.: 2.000  \n Mode  :character   Median : 9.20   Median :3084   Median : 3.000  \n                    Mean   :10.14   Mean   :3105   Mean   : 2.915  \n                    3rd Qu.:13.00   3rd Qu.:3148   3rd Qu.: 3.000  \n                    Max.   :48.10   Max.   :3977   Max.   :20.000  \n                                                                   \n    Bathroom          Car           Landsize         BuildingArea  \n Min.   :0.000   Min.   : 0.00   Min.   :     0.0   Min.   :    0  \n 1st Qu.:1.000   1st Qu.: 1.00   1st Qu.:   177.0   1st Qu.:   93  \n Median :1.000   Median : 2.00   Median :   440.0   Median :  126  \n Mean   :1.534   Mean   : 1.61   Mean   :   558.4   Mean   :  152  \n 3rd Qu.:2.000   3rd Qu.: 2.00   3rd Qu.:   651.0   3rd Qu.:  174  \n Max.   :8.000   Max.   :10.00   Max.   :433014.0   Max.   :44515  \n                 NA's   :62                         NA's   :6450   \n   YearBuilt    CouncilArea          Lattitude        Longtitude   \n Min.   :1196   Length:13580       Min.   :-38.18   Min.   :144.4  \n 1st Qu.:1940   Class :character   1st Qu.:-37.86   1st Qu.:144.9  \n Median :1970   Mode  :character   Median :-37.80   Median :145.0  \n Mean   :1965                      Mean   :-37.81   Mean   :145.0  \n 3rd Qu.:1999                      3rd Qu.:-37.76   3rd Qu.:145.1  \n Max.   :2018                      Max.   :-37.41   Max.   :145.5  \n NA's   :5375                                                      \n  Regionname        Propertycount  \n Length:13580       Min.   :  249  \n Class :character   1st Qu.: 4380  \n Mode  :character   Median : 6555  \n                    Mean   : 7454  \n                    3rd Qu.:10331  \n                    Max.   :21650  \n                                   \n\n\nData has been imported to a ‘raw’ data object, to be drawn from to produce usable data."
  },
  {
    "objectID": "gallery/R/25Winter/Andrew Proj/report.html#data-cleaning",
    "href": "gallery/R/25Winter/Andrew Proj/report.html#data-cleaning",
    "title": "Workshop Project Report",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nThis data includes some values we would like to change before we continue, so we can load the data into a new object for manipulation. From the summary, we can see that the oldest house was built in 1196. Since Melbourne was settled in 1835, this datapoint is a clear outlier and suggests it may be a typo. Therefore we can mutate this datapoint as we load the data into a new object:\n\nmelb_data &lt;- melb_data_raw %&gt;% mutate(YearBuilt = \n                                        ifelse(YearBuilt &lt; 1800,NA,YearBuilt))\n\nNo other clear outliers/typos exist. Landsize of 0 appears to relate to apartments. Postcode, latitude, longitude, distance all within reasonable bounds."
  },
  {
    "objectID": "gallery/R/25Winter/Andrew Proj/report.html#exploring-data",
    "href": "gallery/R/25Winter/Andrew Proj/report.html#exploring-data",
    "title": "Workshop Project Report",
    "section": "Exploring Data",
    "text": "Exploring Data\nTo explore the data, we can create an object called plot_map to store a ggplot of the data, using the latitude and longitude along the x and y axis. This can then be called with geom_point() to produce a plot.\n\nplot_map &lt;- ggplot(data = melb_data, mapping = aes(x = Longtitude, y = Lattitude))\n\nplot_map + geom_point(mapping = aes(colour = YearBuilt)) + \n              theme_classic() + scale_color_viridis_c()\n\n\n\n\n\n\n\n\nThis graph uses the latitude and longitude attributes of the dataset to produce a scatterplot of all house sales in Melbourne, the sum of these data points approximates the geography of Melbourne. The colours can show some hotspots for builds during certain years.\nWe can overlay this graph on a map of melbourne to show how the areas relate to the real world by taking a map of Melbourne from google and using it as a background image for the graph. This is read in using the png library, and limits are set on the x,y coords of graph to fit image:\n\nmap_img &lt;- png::readPNG(\"./data/map_desaturated.png\")\n\nplot_map + background_image(map_img) + geom_point((mapping = aes(colour = \n              YearBuilt))) + theme_classic() + scale_color_viridis_c() + \n              coord_cartesian(xlim = c(144.4,145.7), ylim = c(-38.2, -37.4))\n\n\n\n\n\n\n\n\nThis can alternatively be done using ggmap() rather than an image for the background, however this requires API access.\nThis data can be aggregated by region as follows:\n\ntooltip_data &lt;- melb_data %&gt;% \n  group_by(Regionname) %&gt;% \n  summarise(Latitude = median(Lattitude), Longitude = median(Longtitude), Houses = \n              sum(Type == \"h\"), Townhouses = sum(Type == \"t\"), Units = \n              sum(Type == \"u\"), Properties = n(), Mean_Price = median(Price), PropertySize = median(Landsize))\n\n\n\n# A tibble: 8 × 9\n  Regionname    Latitude Longitude Houses Townhouses Units Properties Mean_Price\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;\n1 Eastern Metr…    -37.8      145.   1173        118   180       1471    1010000\n2 Eastern Vict…    -38.0      145.     50          0     3         53     670000\n3 Northern Met…    -37.8      145.   2754        307   829       3890     806250\n4 Northern Vic…    -37.6      145.     41          0     0         41     540000\n5 South-Easter…    -38.0      145.    388         25    37        450     850000\n6 Southern Met…    -37.9      145.   2721        425  1549       4695    1250000\n7 Western Metr…    -37.8      145.   2290        239   419       2948     793000\n8 Western Vict…    -37.7      145.     32          0     0         32     400000\n# ℹ 1 more variable: PropertySize &lt;dbl&gt;\n\n\nThis table separates out the median price, latitude, longitude, number of houses/units/townhouses and land size of properties.\nThe goal was then to use these in plotly to have hoverable aggregated plot points, however I wasn’t able to finish this.\n\ntooltip_map &lt;- ggplot(data = tooltip_data, mapping = aes(x = Longitude, y = Latitude)) + background_image(map_img) + geom_point(data = tooltip_data, label = tooltip_data$Regionname, label2 = tooltip_data$Mean_Price, label3 = tooltip_data$Houses, label4 = tooltip_data$Units) + theme_classic() + scale_color_viridis_c() + \n  coord_cartesian(xlim = c(144.4,145.7), ylim = c(-38.2, -37.4))\n\nWarning in geom_point(data = tooltip_data, label = tooltip_data$Regionname, :\nIgnoring unknown parameters: `label`, `label2`, `label3`, and `label4`\n\ntooltip_map\n\n\n\n\n\n\n\nggplotly(tooltip_map)\n\n\n\n\n\n\nmelb &lt;- read.csv(\"data/melb_data.csv\")\nmelb |&gt;\n  summary() |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nSuburb\nAddress\nRooms\nType\nPrice\nMethod\nSellerG\nDate\nDistance\nPostcode\nBedroom2\nBathroom\nCar\nLandsize\nBuildingArea\nYearBuilt\nCouncilArea\nLattitude\nLongtitude\nRegionname\nPropertycount\n\n\n\n\n\nMin. : 1\nLength:13580\nLength:13580\nMin. : 1.000\nLength:13580\nMin. : 85000\nLength:13580\nLength:13580\nLength:13580\nMin. : 0.00\nMin. :3000\nMin. : 0.000\nMin. :0.000\nMin. : 0.00\nMin. : 0.0\nMin. : 0\nMin. :1196\nLength:13580\nMin. :-38.18\nMin. :144.4\nLength:13580\nMin. : 249\n\n\n\n1st Qu.: 3396\nClass :character\nClass :character\n1st Qu.: 2.000\nClass :character\n1st Qu.: 650000\nClass :character\nClass :character\nClass :character\n1st Qu.: 6.10\n1st Qu.:3044\n1st Qu.: 2.000\n1st Qu.:1.000\n1st Qu.: 1.00\n1st Qu.: 177.0\n1st Qu.: 93\n1st Qu.:1940\nClass :character\n1st Qu.:-37.86\n1st Qu.:144.9\nClass :character\n1st Qu.: 4380\n\n\n\nMedian : 6790\nMode :character\nMode :character\nMedian : 3.000\nMode :character\nMedian : 903000\nMode :character\nMode :character\nMode :character\nMedian : 9.20\nMedian :3084\nMedian : 3.000\nMedian :1.000\nMedian : 2.00\nMedian : 440.0\nMedian : 126\nMedian :1970\nMode :character\nMedian :-37.80\nMedian :145.0\nMode :character\nMedian : 6555\n\n\n\nMean : 6790\nNA\nNA\nMean : 2.938\nNA\nMean :1075684\nNA\nNA\nNA\nMean :10.14\nMean :3105\nMean : 2.915\nMean :1.534\nMean : 1.61\nMean : 558.4\nMean : 152\nMean :1965\nNA\nMean :-37.81\nMean :145.0\nNA\nMean : 7454\n\n\n\n3rd Qu.:10185\nNA\nNA\n3rd Qu.: 3.000\nNA\n3rd Qu.:1330000\nNA\nNA\nNA\n3rd Qu.:13.00\n3rd Qu.:3148\n3rd Qu.: 3.000\n3rd Qu.:2.000\n3rd Qu.: 2.00\n3rd Qu.: 651.0\n3rd Qu.: 174\n3rd Qu.:1999\nNA\n3rd Qu.:-37.76\n3rd Qu.:145.1\nNA\n3rd Qu.:10331\n\n\n\nMax. :13580\nNA\nNA\nMax. :10.000\nNA\nMax. :9000000\nNA\nNA\nNA\nMax. :48.10\nMax. :3977\nMax. :20.000\nMax. :8.000\nMax. :10.00\nMax. :433014.0\nMax. :44515\nMax. :2018\nNA\nMax. :-37.41\nMax. :145.5\nNA\nMax. :21650\n\n\n\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA’s :62\nNA\nNA’s :6450\nNA’s :5375\nNA\nNA\nNA\nNA\nNA"
  },
  {
    "objectID": "gallery/R/25Winter/Adriel Project/Report-Test.html",
    "href": "gallery/R/25Winter/Adriel Project/Report-Test.html",
    "title": "FC Barcelona Team Analysis",
    "section": "",
    "text": "FC Barcelona (Futbol Club Barcelona ) is a football club founded in 1899 by a group of Swiss, Catalan, German, and English footballers led by Joan Gamper[@fcbarce2025]. The club motto “Més que un club” meaning “More than a club”[@fcbarce2025]."
  },
  {
    "objectID": "gallery/R/25Winter/Adriel Project/Report-Test.html#background",
    "href": "gallery/R/25Winter/Adriel Project/Report-Test.html#background",
    "title": "FC Barcelona Team Analysis",
    "section": "",
    "text": "FC Barcelona (Futbol Club Barcelona ) is a football club founded in 1899 by a group of Swiss, Catalan, German, and English footballers led by Joan Gamper[@fcbarce2025]. The club motto “Més que un club” meaning “More than a club”[@fcbarce2025]."
  },
  {
    "objectID": "gallery/R/25Winter/Adriel Project/Report-Test.html#fc-barcelona-player-2023-2024",
    "href": "gallery/R/25Winter/Adriel Project/Report-Test.html#fc-barcelona-player-2023-2024",
    "title": "FC Barcelona Team Analysis",
    "section": "FC Barcelona Player 2023-2024",
    "text": "FC Barcelona Player 2023-2024\nTable below shows football player that plays for FC Barcelona.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#|eval: False\n\n\ndataset &lt;- read.csv(\"../../../../data/Players2024.csv\")\nsubset &lt;- dataset |&gt; filter(club==\"Futbol Club Barcelona\")\nsubset &lt;- subset |&gt; select(-club)\n\ncolnames(subset) &lt;- c(\"Name\", \"Birth Date\", \"Height\", \"Positions\",\"Nationality\",\"Age\")#change the column name\n\nsubset |&gt; knitr::kable(\"html\")\n\n\n\n\n\nName\n\n\nBirth Date\n\n\nHeight\n\n\nPositions\n\n\nNationality\n\n\nAge\n\n\n\n\n\n\nRobert Lewandowski\n\n\n1988-08-21\n\n\n185\n\n\nAttack\n\n\nPoland\n\n\n36\n\n\n\n\nWojciech Szczęsny\n\n\n1990-04-18\n\n\n196\n\n\nGoalkeeper\n\n\nPoland\n\n\n34\n\n\n\n\nMarc-André ter Stegen\n\n\n1992-04-30\n\n\n187\n\n\nGoalkeeper\n\n\nGermany\n\n\n32\n\n\n\n\nIñigo Martínez\n\n\n1991-05-17\n\n\n182\n\n\nDefender\n\n\nSpain\n\n\n33\n\n\n\n\nAndreas Christensen\n\n\n1996-04-10\n\n\n187\n\n\nDefender\n\n\nDenmark\n\n\n28\n\n\n\n\nIñaki Peña\n\n\n1999-03-02\n\n\n184\n\n\nGoalkeeper\n\n\nSpain\n\n\n25\n\n\n\n\nDani Olmo\n\n\n1998-05-07\n\n\n179\n\n\nMidfield\n\n\nSpain\n\n\n26\n\n\n\n\nFrenkie de Jong\n\n\n1997-05-12\n\n\n181\n\n\nMidfield\n\n\nNetherlands\n\n\n27\n\n\n\n\nFerran Torres\n\n\n2000-02-29\n\n\n184\n\n\nAttack\n\n\nSpain\n\n\n24\n\n\n\n\nJules Koundé\n\n\n1998-11-12\n\n\n180\n\n\nDefender\n\n\nFrance\n\n\n25\n\n\n\n\nEric García\n\n\n2001-01-09\n\n\n182\n\n\nDefender\n\n\nSpain\n\n\n23\n\n\n\n\nAnsu Fati\n\n\n2002-10-31\n\n\n178\n\n\nAttack\n\n\nSpain\n\n\n21\n\n\n\n\nRonald Araujo\n\n\n1999-03-07\n\n\n192\n\n\nDefender\n\n\nUruguay\n\n\n25\n\n\n\n\nAlejandro Balde\n\n\n2003-10-18\n\n\n175\n\n\nDefender\n\n\nSpain\n\n\n20\n\n\n\n\nMarc Casadó\n\n\n2003-09-14\n\n\n172\n\n\nMidfield\n\n\nSpain\n\n\n21\n\n\n\n\nFermín López\n\n\n2003-05-11\n\n\n174\n\n\nMidfield\n\n\nSpain\n\n\n21\n\n\n\n\nGerard Martín\n\n\n2002-02-26\n\n\n186\n\n\nDefender\n\n\nSpain\n\n\n22\n\n\n\n\nPau Víctor\n\n\n2001-11-26\n\n\n184\n\n\nAttack\n\n\nSpain\n\n\n22\n\n\n\n\nPablo Torre\n\n\n2003-04-03\n\n\n173\n\n\nMidfield\n\n\nSpain\n\n\n21\n\n\n\n\nHéctor Fort\n\n\n2006-08-02\n\n\n185\n\n\nDefender\n\n\nSpain\n\n\n18\n\n\n\n\nPau Cubarsí\n\n\n2007-01-22\n\n\n184\n\n\nDefender\n\n\nSpain\n\n\n17\n\n\n\n\nMarc Bernal\n\n\n2007-05-26\n\n\n191\n\n\nMidfield\n\n\nSpain\n\n\n17\n\n\n\n\nTable.1 FC Barcelona Player Season 2023-2024"
  },
  {
    "objectID": "gallery/R/25Winter/Adriel Project/Report-Test.html#la-masia",
    "href": "gallery/R/25Winter/Adriel Project/Report-Test.html#la-masia",
    "title": "FC Barcelona Team Analysis",
    "section": "La Masia",
    "text": "La Masia\nFC Barcelona’s success is contributed by it’s youth football academy called La Masia (The Farmhouse). It is considered as the best youth system in world football. It can be seen in the figure below that the majority of FC Barcelona players from Spain.\n\nlibrary(ggplot2)\nsubset |&gt; ggplot(mapping=aes(x=Positions,fill=Nationality))+\n  geom_bar()\n\n\n\n\nFigure 1. FC Barcelona Player Based on Nationality and Positions\n\n\n\n\nThis is further shown in the figure below where for every position (except Goalkeeper) FC Barcelona has a young player (age below 25) coming from La Masia.\n\nsubset |&gt; ggplot(aes(x=Age, \n                     fill=Nationality))+\n  geom_histogram(binwidth = 1.5)+\n  scale_fill_manual(values=c(\"#a50044\",\"#004d98\",\"#edbb00\",\"#ffed02\",\"#db0030\",\"#157b6d\",\"#456789\"))+\n  facet_wrap(vars(Positions))\n\n\n\n\nFigure 2. FC Barcelona Player Based on Age, Nationality and Positions\n\n\n\n\nThe success of FC Barcelona in the footballing world shows the importance of developing young talent through club academy. This not only beneficial for the club but also the player."
  },
  {
    "objectID": "gallery/Python/25Winter/example_project/example_project.html",
    "href": "gallery/Python/25Winter/example_project/example_project.html",
    "title": "Goalkeepers and their heights",
    "section": "",
    "text": "Set up code\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\n\ndf_raw = pd.read_csv(\"../../../../data/Players2024.csv\")"
  },
  {
    "objectID": "gallery/Python/25Winter/example_project/example_project.html#a-glimpse-at-the-dataset",
    "href": "gallery/Python/25Winter/example_project/example_project.html#a-glimpse-at-the-dataset",
    "title": "Goalkeepers and their heights",
    "section": "A glimpse at the dataset",
    "text": "A glimpse at the dataset\nWe’ll begin just by taking a glimpse at the dataset:\n\n\nShow code\ndf_raw.head(10)\n\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\n0\nJames Milner\n1986-01-04\n175.0\nMidfield\nEngland\n38\nBrighton and Hove Albion Football Club\n\n\n1\nAnastasios Tsokanis\n1991-05-02\n176.0\nMidfield\nGreece\n33\nVolou Neos Podosferikos Syllogos\n\n\n2\nJonas Hofmann\n1992-07-14\n176.0\nMidfield\nGermany\n32\nBayer 04 Leverkusen Fußball\n\n\n3\nPepe Reina\n1982-08-31\n188.0\nGoalkeeper\nSpain\n42\nCalcio Como\n\n\n4\nLionel Carole\n1991-04-12\n180.0\nDefender\nFrance\n33\nKayserispor Kulübü\n\n\n5\nLudovic Butelle\n1983-04-03\n188.0\nGoalkeeper\nFrance\n41\nStade de Reims\n\n\n6\nDaley Blind\n1990-03-09\n180.0\nDefender\nNetherlands\n34\nGirona Fútbol Club S. A. D.\n\n\n7\nCraig Gordon\n1982-12-31\n193.0\nGoalkeeper\nScotland\n41\nHeart of Midlothian Football Club\n\n\n8\nDimitrios Sotiriou\n1987-09-13\n185.0\nGoalkeeper\nGreece\n37\nOmilos Filathlon Irakliou FC\n\n\n9\nAlessio Cragno\n1994-06-28\n184.0\nGoalkeeper\nItaly\n30\nAssociazione Calcio Monza"
  },
  {
    "objectID": "gallery/Python/25Winter/example_project/example_project.html#cleaning-the-data",
    "href": "gallery/Python/25Winter/example_project/example_project.html#cleaning-the-data",
    "title": "Goalkeepers and their heights",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nThe data had a few issues, as the following plot shows:\n\n\nShow code\nsns.catplot(df_raw, x = \"positions\", y = \"height_cm\")\n\n\n\n\n\n\n\n\n\nIt looks like some of the players’ positions and heights were recorded incorrectly. To clean, let’s remove the “Missing” positions and ensure that heights are reasonable:\n\n\nShow code\ndf = df_raw.copy()\n\n# Remove missing position\ndf = df[df[\"positions\"] != \"Missing\"]\n\n# Ensure reasonable heights\ndf = df[df[\"height_cm\"] &gt; 100]\n\n\nTo confirm, let’s plot the outliers in a different colour\n\n\nShow code\n# Identify outliers\noutliers = pd.concat([df_raw,df]).drop_duplicates(keep = False)\n\nsns.catplot(df, x = \"positions\", y = \"height_cm\")\nsns.stripplot(outliers, x = \"positions\", y = \"height_cm\", color = \"r\")"
  },
  {
    "objectID": "gallery/Python/25Winter/example_project/example_project.html#visualising-the-players-heights",
    "href": "gallery/Python/25Winter/example_project/example_project.html#visualising-the-players-heights",
    "title": "Goalkeepers and their heights",
    "section": "Visualising the players’ heights",
    "text": "Visualising the players’ heights\nAfter cleaning the data we can now analyse the players’ heights to see if there’s differences between positions. A box plot can show the distribution of heights:\n\n\nShow code\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"box\", order = [\"Goalkeeper\", \"Defender\", \"Midfield\", \"Attack\"])\nplt.xlabel(\"Position\")\nplt.ylabel(\"Height (cm)\")\nplt.savefig(\"tb.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\nIt looks like goalkeepers are taller than the rest!\nLet’s through the age variable into the mix, to see if players’ heights allow them to compete longer.\n\n\nShow code\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\",\n           hover_data = \"nationality\", labels = {\"height_cm\": \"Height (cm)\",\n                                                 \"positions\": \"Position\"})\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nIt doesn’t look like there’s a relationship between heights and ages, but clearly it affects their position!"
  },
  {
    "objectID": "gallery/Python/25Winter/example_project/example_project.html#global-spread",
    "href": "gallery/Python/25Winter/example_project/example_project.html#global-spread",
    "title": "Goalkeepers and their heights",
    "section": "Global spread",
    "text": "Global spread\nWe haven’t looked at the nationality column yet. Let’s draw up a map using plotly to see where the players come from.\n\n\nShow code\n# Change country names to match plotly reference\ndf[\"nationality\"] = df[\"nationality\"].replace([\"England\", \"Türkiye\", \"Cote d'Ivoire\", \n                                               \"Northern Ireland\", \"Wales\"], \n                                               [\"United Kingdom\", \"Turkey\", \"Ivory Coast\",\n                                                \"United Kingdom\", \"United Kingdom\"])\n\n# Make the count\ncountries = df.value_counts(\"nationality\")\n\n# Make the plot\npx.choropleth(locations = countries.index, locationmode = \"country names\", color = countries,\n              labels = {\"locations\": \"Country\", \"color\": \"# of players\"})\n\n\n                            \n                                            \n\n\nLooks like most players are from Europe. Pan and zoom to see the finer details."
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html",
    "title": "GDP per Cap in different continents",
    "section": "",
    "text": "We will first load the essential packages and dataset\n\n\nSet up code\n#Import data\nimport pandas as pd \n\ndf = pd.read_csv(\"../../../../data/gapminder.csv\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#loading-the-datasets-and-packages",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#loading-the-datasets-and-packages",
    "title": "GDP per Cap in different continents",
    "section": "",
    "text": "We will first load the essential packages and dataset\n\n\nSet up code\n#Import data\nimport pandas as pd \n\ndf = pd.read_csv(\"../../../../data/gapminder.csv\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#inspect-data",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#inspect-data",
    "title": "GDP per Cap in different continents",
    "section": "Inspect data",
    "text": "Inspect data\n\n\nShow code\ndf.columns\ndf.info()\ndf.describe() \ndf.dtypes\ndf[\"lifeExp\"] \ndf[\"lifeExp\"].unique()\ndf[\"lifeExp\"].describe()\ndf[\"continent\"].describe()\ndf[\"continent\"]\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   country    1704 non-null   object \n 1   year       1704 non-null   int64  \n 2   pop        1704 non-null   float64\n 3   continent  1704 non-null   object \n 4   lifeExp    1704 non-null   float64\n 5   gdpPercap  1704 non-null   float64\ndtypes: float64(3), int64(1), object(2)\nmemory usage: 80.0+ KB\n\n\n0         Asia\n1         Asia\n2         Asia\n3         Asia\n4         Asia\n         ...  \n1699    Africa\n1700    Africa\n1701    Africa\n1702    Africa\n1703    Africa\nName: continent, Length: 1704, dtype: object"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#filter-and-subset-the-data-and-grouping",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#filter-and-subset-the-data-and-grouping",
    "title": "GDP per Cap in different continents",
    "section": "Filter and subset the data and grouping",
    "text": "Filter and subset the data and grouping\n\n\nShow code\nsubset_con=df[[\"continent\", \"gdpPercap\", \"year\"]]\nsummary_con= subset_con.groupby(\"continent\")[\"gdpPercap\"].mean()\nsummary_con= summary_con.reset_index()"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#visualize-the-data",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#visualize-the-data",
    "title": "GDP per Cap in different continents",
    "section": "Visualize the data",
    "text": "Visualize the data\nSummary of mean GDP per Cap in different continents\n\n\nShow code\nimport seaborn as sns\nsns.catplot(data=df,\n            x=\"continent\",\n            y=\"gdpPercap\",\n            kind=\"box\",\n            estimator=\"std\",\n            hue=\"continent\"\n            ) \n\n\n\n\n\nGPD per Capital in different continents"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#visualize-the-data-1",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#visualize-the-data-1",
    "title": "GDP per Cap in different continents",
    "section": "Visualize the data",
    "text": "Visualize the data\nSummary of GDP per Cap in different continents\n\n\nShow code\nsns.catplot(data=summary_con,\n            x=\"continent\",\n            y=\"gdpPercap\",\n            kind=\"box\",\n            estimator=\"std\",\n            hue=\"continent\"\n            )"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#interactive-plot",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#interactive-plot",
    "title": "GDP per Cap in different continents",
    "section": "Interactive plot",
    "text": "Interactive plot\n\n\nShow code\nimport plotly.express as px\nimport matplotlib.pyplot as plt\npx.scatter(data_frame = df, x = \"continent\", y = \"gdpPercap\", color = \"continent\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Prince/gapminder2025.html#make-a-global-chloropeth",
    "href": "gallery/Python/25Winter/Prince/gapminder2025.html#make-a-global-chloropeth",
    "title": "GDP per Cap in different continents",
    "section": "Make a global chloropeth",
    "text": "Make a global chloropeth\nWe will now visualize it on a world map\n\n\nShow code\n# Compute mean GDP per capita per continent\ncontinent_gdp = df.groupby(\"continent\")[\"gdpPercap\"].mean()\n\n# Map each country's continent GDP\ndf[\"continent_gdp\"] = df[\"continent\"].map(continent_gdp)\n\n# Drop duplicates to keep only one row per country\ncountry_continent_gdp = df.drop_duplicates(\"country\")[[\"country\", \"continent_gdp\"]]\n\n#plot\npx.choropleth(country_continent_gdp,\n                    locations=\"country\",\n                    locationmode=\"country names\",\n                    color=\"continent_gdp\",\n                    color_continuous_scale=\"Plasma\",\n                    title=\"Continent-Level Avg GDP per Capita (Mapped by Country)\",\n                    labels={\"continent_gdp\": \"Continent Avg GDP\"})\n\n\n                            \n                                            \nGPD per Capital in different continents"
  },
  {
    "objectID": "gallery/Python/25Winter/Group2/group_project.html",
    "href": "gallery/Python/25Winter/Group2/group_project.html",
    "title": "Queensland Fuel Price",
    "section": "",
    "text": "This Report will focus on Fuel price by Fuel types, Suburbs and change by months\n\nModules that used: pandas, seaborn\nDataset of Queensland Fuel Price (Fuel prices by the pump in Queensland)\nData from Data from the Queensland Government’s Open Data Portal\nInvestigation includes Fuel price corolation by types, date and suburbs"
  },
  {
    "objectID": "gallery/Python/25Winter/Group2/group_project.html#introduction",
    "href": "gallery/Python/25Winter/Group2/group_project.html#introduction",
    "title": "Queensland Fuel Price",
    "section": "",
    "text": "This Report will focus on Fuel price by Fuel types, Suburbs and change by months\n\nModules that used: pandas, seaborn\nDataset of Queensland Fuel Price (Fuel prices by the pump in Queensland)\nData from Data from the Queensland Government’s Open Data Portal\nInvestigation includes Fuel price corolation by types, date and suburbs"
  },
  {
    "objectID": "gallery/Python/25Winter/Group2/group_project.html#average-fuel-prices-by-fuel-types",
    "href": "gallery/Python/25Winter/Group2/group_project.html#average-fuel-prices-by-fuel-types",
    "title": "Queensland Fuel Price",
    "section": "Average Fuel Prices by Fuel Types",
    "text": "Average Fuel Prices by Fuel Types\n\n\nShow code\n# Set up code\nimport pandas as pd\ndf=pd.read_csv(\"../../../../data/qld_fuel.csv\")\nimport seaborn as sns\nfp=df[\"Price\"]\nft=df[\"Fuel_Type\"]\nimport matplotlib.pyplot as plt\nsns.barplot(data=df, x=ft, y=fp, errorbar=None, width=0.6, palette=\"muted\")\n\nplt.xticks(rotation=45, ha='right')\n\nplt.title(\"Average Fuel Prices by Type in QLD\")\nplt.xlabel(\"Fuel Type\")\nplt.ylabel(\"Price ($/L)\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "gallery/Python/25Winter/Group2/group_project.html#fuel-price-by-suburbs",
    "href": "gallery/Python/25Winter/Group2/group_project.html#fuel-price-by-suburbs",
    "title": "Queensland Fuel Price",
    "section": "Fuel Price by Suburbs",
    "text": "Fuel Price by Suburbs\n\n\nShow code\ndf[\"TransactionDateutc\"] = pd.to_datetime(df[\"TransactionDateutc\"])\ndf[\"Price\"] = df[\"Price\"] / 100 \n\n# removing outliers \ndf = df[df[\"Price\"] &lt; 50] \ndf = df[df[\"Price\"] &gt; 10] \n\n# summary stats \nsummary_stats = df.groupby(\"Site_Suburb\")[\"Price\"].agg(min_price = \"min\", max_price = \"max\")\n\nsummary_stats[\"price_range\"] = summary_stats[\"max_price\"] - summary_stats[\"min_price\"]\n\n# Top 3 and bottom 3 suburbs \n\ntop3_change = summary_stats.sort_values(by=\"price_range\", ascending= False). head(3)\nbottom3_change = summary_stats.sort_values(by=\"price_range\", ascending= True). head(3)\n\nselected_suburbs = top3_change.index.tolist() + bottom3_change.index.tolist()\ndf_selected = df[df[\"Site_Suburb\"].isin(selected_suburbs)]\n\ndf_selected[\"Site_Suburb\"] = df_selected[\"Site_Suburb\"].str.strip().str.title()\n\n# Plot\nsns.catplot(data = df_selected, x = \"Site_Suburb\", y = \"Price\", kind = \"box\")\nplt.xlabel (\"Site_Suburb\")\nplt.ylabel (\"Price\")\nplt.savefig (\"tb.png\")\nplt.show()"
  },
  {
    "objectID": "gallery/Python/25Winter/Group2/group_project.html#price-by-time",
    "href": "gallery/Python/25Winter/Group2/group_project.html#price-by-time",
    "title": "Queensland Fuel Price",
    "section": "Price by Time",
    "text": "Price by Time\n\n\nShow code\ndf.describe()\n\n# remove nulls\ndf[df[\"X_id\"].notna()]\ndf_full_X_id = df[df[\"X_id\"].notna()]\ndf_full_X_id.shape\n\n\ndf[\"Site_Suburb\"].count()\ndf[\"Site_Suburb\"].unique()\ndf[\"Site_Suburb\"].value_counts()\n\ndf[\"Fuel_Type\"].count()\ndf[\"Fuel_Type\"].unique()\ndf[\"Fuel_Type\"].value_counts()\n\n\ndf[\"TransactionDateutc\"] = pd.to_datetime(df[\"TransactionDateutc\"])\ndf[\"date_only\"] = df[\"TransactionDateutc\"].dt.date\n\n\n\n\ngb = df.groupby(\"date_only\")\navg_price_by_date = gb[\"Price\"].agg(\"mean\").reset_index()\navg_price_by_date.to_csv(\"./data/avg_price_by_date.csv\")  # export subset\n\ndf[\"TransactionDateutc\"].dtypes\n\ndf[\"year_month\"] = df[\"TransactionDateutc\"].dt.to_period(\"M\")\ngb_year_month = df.groupby(\"year_month\")\navg_price_by_year_month = gb_year_month[\"Price\"].agg(\"mean\").reset_index()\navg_price_by_year_month.to_csv(\"./data/avg_price_by_year_month.csv\")\nimport seaborn as sns\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n\n\ntype(\"year_month\")\ntype(\"date_only\")\n\navg_price_by_year_month[\"year_month\"] = avg_price_by_year_month[\"year_month\"].dt.to_timestamp()\nsns.relplot(data = avg_price_by_date, x = \"date_only\", y = \"Price\", hue = \"Price\")\nsns.lineplot(data =avg_price_by_year_month, x = \"year_month\", y = \"Price\", color = \"red\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Preferences/ProjectCoffee.html",
    "href": "gallery/Python/25Winter/Coffee Preferences/ProjectCoffee.html",
    "title": "Coffee preferences",
    "section": "",
    "text": "We are investigating the relationship between coffee preferences and age, specifically preferred coffee style, amount consumed, coffee expertise and overall favourite coffee type from the tasing. The dataset we are using comes from a Great American Coffee Taste Test, during which thousands of people simultaneously blind-tasted the same four coffees.\n\n\nShow code\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Preferences/ProjectCoffee.html#introduction",
    "href": "gallery/Python/25Winter/Coffee Preferences/ProjectCoffee.html#introduction",
    "title": "Coffee preferences",
    "section": "",
    "text": "We are investigating the relationship between coffee preferences and age, specifically preferred coffee style, amount consumed, coffee expertise and overall favourite coffee type from the tasing. The dataset we are using comes from a Great American Coffee Taste Test, during which thousands of people simultaneously blind-tasted the same four coffees.\n\n\nShow code\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "gallery/Python/25Winter/Australia and Cambodia Populations/project_report.html",
    "href": "gallery/Python/25Winter/Australia and Cambodia Populations/project_report.html",
    "title": "Life expectancy comparison between Australian and Cambodian populations between 1950 and 2023",
    "section": "",
    "text": "We wanted to look at life expectancy and population over tie between Australia and Cambodia to compare differences bettwen diferent regions We used the popultion csvand extracted data from Janyary population column and also identified australia and Cambodia We generated graphs using seaborn and can see the effect of the war in Cambodiaduring the late 70s\n\n\nShow code\n# Set up code\nimport pandas as pd\n\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\n\n\ndf_raw = pd.read_csv(\"../../../../data/population.csv\")\n\ndf = df_raw.copy()\n\nplt.show()\n\ndf_raw.shape\n\ndf_raw.columns\n\nWorld=df.loc[df[\"Region\"]==\"World\"]\n\nsns.lineplot(data=World, x=\"Year\", y=\"Jan.Population\")\n\n\n \n\ndf_raw = pd.read_csv(\"../../../../data/population.csv\")\n\nplt.show()\n\ndf_raw.shape\n\ndf_raw.columns\n\n \n\ndf[\"Jan.Population\"]\n\nAustralia=df.loc[df[\"Region\"]==\"Australia\"]\n\nsns.lineplot(data=Australia, x=\"Year\", y=\"Life.Expectancy.at.Birth..both.sexes..years.\")\n\nCambodia=df.loc[df[\"Region\"]==\"Cambodia\"]\n\nsns.lineplot(data=Cambodia, x=\"Year\", y=\"Life.Expectancy.at.Birth..both.sexes..years.\")\n\n\n\nsns.lineplot(data=Cambodia, x=\"Year\", y=\"Jan.Population\")\n\n            \n\ncountries = [\"Australia\", \"Cambodia\",]\n\ndf_countries = df[df[\"Region\"].isin(countries)].copy()\n\n \n\nplt.figure(figsize=(10, 6))\n\nfor country in countries:\n\n    subset = df_countries[df_countries[\"Region\"] == country]\n\n    plt.plot(subset[\"Year\"], subset[\"Jan.Population\"], label=country)\n\nplt.xlabel(\"Year\")\n\nplt.ylabel(\"Population\")\n\nplt.title(\"Population Over Time\")\n\nplt.legend()\n\nplt.grid(True)\n\nplt.show()\n\n \n\nplt.figure(figsize=(10, 6))\n\nfor country in countries:\n\n    subset = df_countries[df_countries[\"Region\"] == country]\n\n    plt.plot(subset[\"Year\"], subset[\"Life.Expectancy.at.Birth..both.sexes..years.\"], label=country)\n\nplt.xlabel(\"Year\")\n\nplt.ylabel(\"Life Expectancy at Birth\")\n\nplt.title(\"Life Expectancy Over Time\")\n\nplt.legend()\n\nplt.grid(True)\n\nplt.show()"
  },
  {
    "objectID": "gallery/Python/25Winter/Australia and Cambodia Populations/project_report.html#introduction",
    "href": "gallery/Python/25Winter/Australia and Cambodia Populations/project_report.html#introduction",
    "title": "Life expectancy comparison between Australian and Cambodian populations between 1950 and 2023",
    "section": "",
    "text": "We wanted to look at life expectancy and population over tie between Australia and Cambodia to compare differences bettwen diferent regions We used the popultion csvand extracted data from Janyary population column and also identified australia and Cambodia We generated graphs using seaborn and can see the effect of the war in Cambodiaduring the late 70s\n\n\nShow code\n# Set up code\nimport pandas as pd\n\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\n\n\ndf_raw = pd.read_csv(\"../../../../data/population.csv\")\n\ndf = df_raw.copy()\n\nplt.show()\n\ndf_raw.shape\n\ndf_raw.columns\n\nWorld=df.loc[df[\"Region\"]==\"World\"]\n\nsns.lineplot(data=World, x=\"Year\", y=\"Jan.Population\")\n\n\n \n\ndf_raw = pd.read_csv(\"../../../../data/population.csv\")\n\nplt.show()\n\ndf_raw.shape\n\ndf_raw.columns\n\n \n\ndf[\"Jan.Population\"]\n\nAustralia=df.loc[df[\"Region\"]==\"Australia\"]\n\nsns.lineplot(data=Australia, x=\"Year\", y=\"Life.Expectancy.at.Birth..both.sexes..years.\")\n\nCambodia=df.loc[df[\"Region\"]==\"Cambodia\"]\n\nsns.lineplot(data=Cambodia, x=\"Year\", y=\"Life.Expectancy.at.Birth..both.sexes..years.\")\n\n\n\nsns.lineplot(data=Cambodia, x=\"Year\", y=\"Jan.Population\")\n\n            \n\ncountries = [\"Australia\", \"Cambodia\",]\n\ndf_countries = df[df[\"Region\"].isin(countries)].copy()\n\n \n\nplt.figure(figsize=(10, 6))\n\nfor country in countries:\n\n    subset = df_countries[df_countries[\"Region\"] == country]\n\n    plt.plot(subset[\"Year\"], subset[\"Jan.Population\"], label=country)\n\nplt.xlabel(\"Year\")\n\nplt.ylabel(\"Population\")\n\nplt.title(\"Population Over Time\")\n\nplt.legend()\n\nplt.grid(True)\n\nplt.show()\n\n \n\nplt.figure(figsize=(10, 6))\n\nfor country in countries:\n\n    subset = df_countries[df_countries[\"Region\"] == country]\n\n    plt.plot(subset[\"Year\"], subset[\"Life.Expectancy.at.Birth..both.sexes..years.\"], label=country)\n\nplt.xlabel(\"Year\")\n\nplt.ylabel(\"Life Expectancy at Birth\")\n\nplt.title(\"Life Expectancy Over Time\")\n\nplt.legend()\n\nplt.grid(True)\n\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UQ Library Training Intensives",
    "section": "",
    "text": "UQ Library Training Intensives\nWelcome to our training intensives!\nHere you can find all the material for our three-day intensives, which run twice a year.\nThe next batch will be in late Jan / early Feb 2026.\nR with RStudio\nTraining Intensive\n\n27th to 29th Jan 2026 Python for Data Analysis\nTraining Intensive\n\n3rd to 5th Feb 2026 QGIS\nTraining Intensive\n\n10th to 12th Feb 2026"
  },
  {
    "objectID": "gallery/project_gallery.html",
    "href": "gallery/project_gallery.html",
    "title": "Project gallery",
    "section": "",
    "text": "Goalkeepers and their heights\n\n\n\nPython\n\n26Summer\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nCameron West and Stéphane Guillou\n\n\nFeb 1, 2026\n\n\n\n\n\n\n\n\n\n\n\nGoalkeepers and their heights\n\n\n\nR\n\n26Summer\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nCameron West and Stéphane Guillou\n\n\nJan 1, 2026\n\n\n\n\n\n\n\n\n\n\n\nMel Property\n\n\n\nR\n\n25Winter\n\ndata: melb_data.csv\n\n\n\n\n\n\n\nSandya & Buddhika\n\n\nJul 17, 2025\n\n\n\n\n\n\n\n\n\n\n\nQueensland hospitals data analysis\n\n\n\nR\n\n25Winter\n\ndata: hospital_data.csv\n\n\n\n\n\n\n\nSwagata & Sandhya\n\n\nJul 17, 2025\n\n\n\n\n\n\n\n\n\n\n\nPopulation: Presentation for R training\n\n\n\nR\n\n25Winter\n\ndata: population.csv\n\n\n\n\n\n\n\n\n\n\nJul 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nLife expectancy comparison between Australian and Cambodian populations between 1950 and 2023\n\n\n\nPython\n\n25Winter\n\ndata: population.csv\n\n\n\n\n\n\n\nRob Cincotta and Diana Sanabria\n\n\nJul 10, 2025\n\n\n\n\n\n\n\n\n\n\n\nMy Python project\n\n\n\nPython\n\n25Winter\n\n\n\n\n\n\n\nNahar\n\n\nJul 10, 2025\n\n\n\n\n\n\n\n\n\n\n\nCoffee Survey\n\n\n\nPython\n\n25Winter\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nPawatsada Sanlom\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Coffee Preference\n\n\n\nPython\n\n25Winter\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nKim, Janine, Sera & Akansha\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nCoffee preferences\n\n\n\nPython\n\n25Winter\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nHannah, Orlando and Grace\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nMy Python Report\n\n\n\nPython\n\n25Winter\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nYuli Astriani & Elisabeth Natalia Palan Bolen\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nQueensland Fuel Price\n\n\n\nPython\n\n25Winter\n\ndata: qld_fuel.csv\n\n\n\n\n\n\n\nNana, Jia Vei Yar, Yawen\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nGDP per Cap in different continents\n\n\n\nPython\n\n25Winter\n\ndata: gapminder.csv\n\n\n\n\n\n\n\nPrince\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nmy python report\n\n\n\nPython\n\n25Winter\n\ndata: gapminder.csv\n\n\n\n\n\n\n\nSisay\n\n\nJul 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nFC Barcelona Team Analysis\n\n\n\nR\n\n25Winter\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nAdriel Wijaya\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nGood Reads\n\n\n\nR\n\n25Winter\n\ndata: books.csv\n\n\n\n\n\n\n\nAisha Aslam\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nWorkshop Project Report\n\n\n\nR\n\n25Winter\n\ndata: melb_data.csv\n\n\n\n\n\n\n\nAndrew\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nProject Hospital Report\n\n\n\nR\n\n25Winter\n\ndata: hospital_data.csv\n\n\n\n\n\n\n\nCasey Atkins & Jess\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nQLD fuel\n\n\n\nR\n\n25Winter\n\ndata: qld_fuel.csv\n\n\n\n\n\n\n\n\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nQLD Fuel\n\n\n\nR\n\n25Winter\n\ndata: qld_fuel.csv\n\n\n\n\n\n\n\n\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nMy Report\n\n\n\nR\n\n25Winter\n\ndata: books.csv\n\n\n\n\n\n\n\nCathy\n\n\nJul 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nGoalkeepers and their heights\n\n\n\nPython\n\n25Winter\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nCameron West and Stéphane Guillou\n\n\nJun 23, 2025\n\n\n\n\n\n\n\n\n\n\n\nGoalkeepers and their heights\n\n\n\nR\n\n25Winter\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nCameron West and Stéphane Guillou\n\n\nJun 23, 2025\n\n\n\n\n\n\n\n\n\n\n\nQueensland Fuel Price in 2023\n\n\n\nPython\n\n25Summer\n\ndata: qld_fuel.csv\n\n\n\n\n\n\n\nAdelia & Lauren\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nGoodreads\n\n\n\nPython\n\n25Summer\n\ndata: books.csv\n\n\n\n\n\n\n\nCaira\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nFuel Consumption\n\n\n\nPython\n\n25Summer\n\n\n\n\n\n\n\nEdison Vargas\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nFuel Consumption\n\n\n\nPython\n\n25Summer\n\ndata: qld_fuel.csv\n\n\n\n\n\n\n\nEdison Vargas\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nGoodreads document\n\n\n\nPython\n\n25Summer\n\ndata: books.csv\n\n\n\n\n\n\n\nEmma\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nBird Strikes and Aeroplane Damages in the U.S. (1990-1999)\n\n\n\nPython\n\n25Summer\n\ndata: birds_strikes.csv\n\n\n\n\n\n\n\nLiz & Koyo\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nThe popular author\n\n\n\nPython\n\n25Summer\n\ndata: books.csv\n\n\n\n\n\n\n\nGoodread\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nProject-Python\n\n\n\nPython\n\n25Summer\n\ndata: melb_data.csv\n\n\n\n\n\n\n\n\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\nAeroplane Bird Strike Incidents\n\n\n\nPython\n\n25Summer\n\ndata: birds_strikes.csv\n\n\n\n\n\n\n\nKoyo Yanagisawa\n\n\nJan 15, 2025\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing the Relationship between Ratings and Reviews for Books\n\n\n\nPython\n\n25Summer\n\ndata: books.csv\n\n\n\n\n\n\n\nNurul Najihah\n\n\nJan 15, 2025\n\n\n\n\n\n\n\n\n\n\n\nGoalkeepers and their heights\n\n\n\nPython\n\n25Summer\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nCameron West and Stéphane Guillou\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nCOFFEE\n\n\n\nR\n\n25Summer\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nAdelia\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nGoodreads books published in 2006\n\n\n\nR\n\n25Summer\n\ndata: books.csv\n\n\n\n\n\n\n\nBrittnee, Cleo, & David\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nBirdStrikes\n\n\n\nR\n\n25Summer\n\ndata: birds_strikes.csv\n\n\n\n\n\n\n\n\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nCoffee\n\n\n\nR\n\n25Summer\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nCaira Loo\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n📝 Coffee vs Employment status\n\n\n\nR\n\n25Summer\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nDawn\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nMelbourne Housing\n\n\n\nR\n\n25Summer\n\ndata: melb_data.csv\n\n\n\n\n\n\n\n\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nHospital Data\n\n\n\nR\n\n25Summer\n\ndata: hospital_data.csv\n\n\n\n\n\n\n\n\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nImpact of Birth Month on Football careers\n\n\n\nR\n\n25Summer\n\ndata: Players2024.csv\n\n\n\n\n\n\n\nMehershad Wadia\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nBird Strike Dashboard\n\n\n\nR\n\n25Summer\n\ndata: birds_strikes.csv\n\n\n\n\n\n\n\nEdiana\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nCoffee\n\n\n\nR\n\n25Summer\n\ndata: coffee_survey.csv\n\n\n\n\n\n\n\nWarren\n\n\nJan 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "gallery/Python/25Summer/Edison/fuel_project.html",
    "href": "gallery/Python/25Summer/Edison/fuel_project.html",
    "title": "Fuel Consumption",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv(\"./data/data/qld_fuel.csv\")\nprint(df)\n\n        Unnamed: 0    SiteId                   Site_Name   Site_Brand  \\\n0                1  61290151               Liberty Surat      Liberty   \n1                2  61290151               Liberty Surat      Liberty   \n2                3  61290151               Liberty Surat      Liberty   \n3                4  61291313          Lowes Mungindi Opt           BP   \n4                5  61291313          Lowes Mungindi Opt           BP   \n...            ...       ...                         ...          ...   \n615972      615973  61478211  Metro Petroleum Walkerston   Metro Fuel   \n615973      615974  61478211  Metro Petroleum Walkerston   Metro Fuel   \n615974      615975  61478212      Pitt Stop Classic Café  Independent   \n615975      615976  61478212      Pitt Stop Classic Café  Independent   \n615976      615977  61478212      Pitt Stop Classic Café  Independent   \n\n       Sites_Address_Line_1 Site_Suburb Site_State  Site_Post_Code  \\\n0        61 Burrowes Street       Surat        QLD            4417   \n1        61 Burrowes Street       Surat        QLD            4417   \n2        61 Burrowes Street       Surat        QLD            4417   \n3         126 Barwon Street    Mungindi        QLD            4497   \n4         126 Barwon Street    Mungindi        QLD            4497   \n...                     ...         ...        ...             ...   \n615972          2 Dutton St  Walkerston        QLD            4751   \n615973          2 Dutton St  Walkerston        QLD            4751   \n615974          34 Palm Ave    Seaforth        QLD            4741   \n615975          34 Palm Ave    Seaforth        QLD            4741   \n615976          34 Palm Ave    Seaforth        QLD            4741   \n\n        Site_Latitude  Site_Longitude    Fuel_Type  Price  \\\n0          -27.151687      149.067742       Diesel   1999   \n1          -27.151687      149.067742  PULP 98 RON   2159   \n2          -27.151687      149.067742     Unleaded   1959   \n3          -28.973467      148.983829       Diesel   1990   \n4          -28.973467      148.983829     Unleaded   1920   \n...               ...             ...          ...    ...   \n615972     -21.160166      149.063728     Unleaded   1959   \n615973     -21.160166      149.063728     Unleaded   1989   \n615974     -20.899741      148.964986     Unleaded   2049   \n615975     -20.899741      148.964986     Unleaded   2039   \n615976     -20.899741      148.964986     Unleaded   2099   \n\n         TransactionDateutc  X_id  \n0       2023-10-12 21:56:00   NaN  \n1       2023-12-30 06:54:00   NaN  \n2       2023-12-30 06:54:00   NaN  \n3       2023-06-12 22:00:00   NaN  \n4       2023-06-12 22:00:00   NaN  \n...                     ...   ...  \n615972  2023-09-20 05:14:00   NaN  \n615973  2023-09-25 08:08:00   NaN  \n615974  2023-04-09 04:15:00   NaN  \n615975  2023-04-09 04:24:00   NaN  \n615976  2023-09-25 06:26:00   NaN  \n\n[615977 rows x 14 columns]\n\n\n\n# initial exploration\ndf.columns\n\ndf.info()\n\ndf.head()\n\ndf[\"Fuel_Type\"]\n\npd.unique(df[\"Fuel_Type\"])\n\ndf.describe()\n\ndf[\"Fuel_Type\"].describe()\n\npd.unique(df[\"Site_Suburb\"])\n\ndf[\"Site_Suburb\"].describe()\n\npd.unique(df[\"Site_State\"])\n\ndf[\"Site_State\"].describe()\n\n\ndf[5 : 10]\n\npd.unique(df[\"Site_Name\"])\n\ndf[\"Site_Name\"].describe()\n\ndf.dtypes\n\ndf[\"Price\"].describe()\n\ndf[\"Site_Brand\"].describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 615977 entries, 0 to 615976\nData columns (total 14 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   Unnamed: 0            615977 non-null  int64  \n 1   SiteId                615977 non-null  int64  \n 2   Site_Name             615977 non-null  object \n 3   Site_Brand            615977 non-null  object \n 4   Sites_Address_Line_1  615977 non-null  object \n 5   Site_Suburb           615977 non-null  object \n 6   Site_State            615977 non-null  object \n 7   Site_Post_Code        615977 non-null  int64  \n 8   Site_Latitude         615977 non-null  float64\n 9   Site_Longitude        615977 non-null  float64\n 10  Fuel_Type             615977 non-null  object \n 11  Price                 615977 non-null  int64  \n 12  TransactionDateutc    615977 non-null  object \n 13  X_id                  121457 non-null  float64\ndtypes: float64(3), int64(4), object(7)\nmemory usage: 65.8+ MB\n\n\ncount       615977\nunique          25\ntop       7 Eleven\nfreq        118040\nName: Site_Brand, dtype: object\n\n\n\n# summaries\ngb = df.groupby(\"Fuel_Type\")\n\navg_fuel_by_price = gb[\"Price\"].agg(\"mean\")\n\nplt.ion()\navg_fuel_by_price.plot()\nplt.show()\n\n# Ensure reasonable heights\ndf = df[ (500 &lt; df[\"Price\"]) & (df[\"Price\"] &lt; 4000)]\n\ndf[\"unit_price\"] = df[\"Price\"] / 1000\n\ndf.to_csv(\"./data/filtered_fuel.csv\")\n\nsns.catplot(data = df, x = \"Fuel_Type\", y = \"Price\")\nplt.show()\n\n\nsns.catplot(data = df, x = \"Site_State\", y = \"Fuel_Type\")\nplt.show()\n\n\n# Remove unleaded Fuel_type\ndf1 = df[df[\"Fuel_Type\"] != \"Unleaded\"]\n\n# sns.catplot(data = df1, x = \"Site_State\", y = \"Fuel_Type\")\nplt.show()\n\n# Remove unknown Site_Brand\ndf2 = df[df[\"Site_Brand\"] != \"Unknown\"]\n\n# sns.catplot(data = df2, x = \"Site_State\", y = \"Site_Brand\", kind = \"bar\")\nplt.show()\n\n\nsns.displot(data = df, x = \"Price\", hue = \"Fuel_Type\", kind = \"kde\")\nplt.show()\n\nsns.displot(data = df, x = \"unit_price\", hue = \"Fuel_Type\", kind = \"kde\")\nplt.show()\n\n# sns.catplot(data=df, x=\"unit_price\", y=\"Fuel_type\")\nplt.show()\n\n\n\n\n\n\n\n\n/tmp/ipykernel_2732/3688228111.py:13: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nfuel = pd.read_csv(\"./data/data/qld_fuel.csv\")\nimport geopandas \nfuel_geo = geopandas.GeoDataFrame(fuel, geometry = geopandas.points_from_xy(x = fuel.Site_Longitude, y = fuel.Site_Latitude)) \nfuel_geo.plot()\n\n\n\n\n\n\n\n\n\nimport plotly.express as px\nfigure = px.scatter(data_frame = df, x = \"Fuel_Type\", y = \"unit_price\", color = \"Site_State\",\n           facet_col = \"Site_State\", hover_name = \"Site_Brand\",\n           hover_data = \"Site_Suburb\")\n\nfigure.write_html(\"fuel.html\")\n\n\nimport pandas as pd\nfuel = pd.read_csv(\"./data/data/qld_fuel.csv\")\nimport geopandas \nfuel_geo = geopandas.GeoDataFrame(fuel, geometry = geopandas.points_from_xy(x = fuel.Site_Longitude, y = fuel.Site_Latitude)) \nfuel_geo.plot()"
  },
  {
    "objectID": "gallery/Python/25Winter/Another coffee survey/Pawatsada.html",
    "href": "gallery/Python/25Winter/Another coffee survey/Pawatsada.html",
    "title": "Coffee Survey",
    "section": "",
    "text": "1.1 Import modules and dataset\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\n\ndf = pd.read_csv(\"../../../../data/coffee_survey.csv\")\n\n\n1.2 Data Exploration\n\n\nShow code\ndf.head(10)\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nage\ncups\nwhere_drink\npurchase_other\nfavourite\nfavorite_specify\nadditions\nadditions_other\nsweetener\n...\nmost_paid\nmost_willing\nvalue_cafe\nspent_equipment\nvalue_equipment\ngender\neducation_level\nemployment_status\nnumber_children\npolitical_affiliation\n\n\n\n\n0\n1\n&lt;18 years old\n3\nAt home, At the office, At a cafe\nNaN\nPourover\nNaN\nNo - just black, Milk, dairy alternative, or c...\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nOther (please specify)\nBachelor's degree\nEmployed full-time\nMore than 3\nDemocrat\n\n\n1\n2\n&gt;65 years old\n3\nAt the office, At a cafe\nNaN\nCortado\nNaN\nNo - just black\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n3\n25-34 years old\n1\nAt home, At the office, On the go\nNaN\nRegular drip coffee\nNaN\nMilk, dairy alternative, or coffee creamer, Su...\nNaN\nGranulated Sugar, Brown Sugar\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nFemale\nBachelor's degree\nEmployed full-time\nNaN\nDemocrat\n\n\n3\n4\n18-24 years old\n2\nAt the office\nNaN\nIced coffee\nNaN\nMilk, dairy alternative, or coffee creamer\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n5\n45-54 years old\n2\nAt home, At the office, At a cafe, On the go\nNaN\nRegular drip coffee\nNaN\nNo - just black\nNaN\nNaN\n...\n$4-$6\n$8-$10\nNo\n$500-$1000\nYes\nMale\nMaster's degree\nEmployed full-time\n2\nNo affiliation\n\n\n5\n6\n&gt;65 years old\n1\nAt home\nNaN\nRegular drip coffee\nNaN\nNo - just black\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6\n7\n25-34 years old\n2\nAt home, At the office\nNaN\nPourover\nNaN\nNo - just black\nNaN\nNaN\n...\n$2-$4\nMore than $20\nYes\n$50-$100\nYes\nMale\nMaster's degree\nUnemployed\nNaN\nIndependent\n\n\n7\n8\n35-44 years old\n1\nAt the office, At home\nNaN\nIced coffee\nNaN\nNo - just black\nNaN\nNaN\n...\n$10-$15\nMore than $20\nYes\n$100-$300\nYes\nMale\nBachelor's degree\nEmployed full-time\n3\nNo affiliation\n\n\n8\n9\n45-54 years old\nMore than 4\nAt home\nNaN\nPourover\nNaN\nNo - just black\nNaN\nNaN\n...\n$10-$15\n$15-$20\nYes\n$300-$500\nYes\nMale\nBachelor's degree\nEmployed full-time\n3\nNo affiliation\n\n\n9\n10\n35-44 years old\n1\nAt the office, At a cafe, At home\nNaN\nCappuccino\nNaN\nMilk, dairy alternative, or coffee creamer, Su...\nNaN\nGranulated Sugar, Brown Sugar\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n10 rows × 43 columns\n\n\n\nAge exploration\n\n\nShow code\nsns.catplot(data = df, x = \"age\", kind=\"count\", height=5, aspect=2)\n\n\n\n\n\n\n\n\n\n\nAge 25 to 34 range is the highest age range among coffee customers.\n\n1.3 Data Filtering\n\n\nShow code\ndf_focused = df[[\"age\", \"where_drink\", \"favourite\", 'style']].copy()\ndf_focused.head(10)\n\n\n\n\n\n\n\n\n\nage\nwhere_drink\nfavourite\nstyle\n\n\n\n\n0\n&lt;18 years old\nAt home, At the office, At a cafe\nPourover\nBright\n\n\n1\n&gt;65 years old\nAt the office, At a cafe\nCortado\nFruity\n\n\n2\n25-34 years old\nAt home, At the office, On the go\nRegular drip coffee\nSweet\n\n\n3\n18-24 years old\nAt the office\nIced coffee\nNutty\n\n\n4\n45-54 years old\nAt home, At the office, At a cafe, On the go\nRegular drip coffee\nFloral\n\n\n5\n&gt;65 years old\nAt home\nRegular drip coffee\nFull Bodied\n\n\n6\n25-34 years old\nAt home, At the office\nPourover\nFloral\n\n\n7\n35-44 years old\nAt the office, At home\nIced coffee\nFruity\n\n\n8\n45-54 years old\nAt home\nPourover\nFull Bodied\n\n\n9\n35-44 years old\nAt the office, At a cafe, At home\nCappuccino\nNutty\n\n\n\n\n\n\n\n\nFocusing on 4 attributes including age, where to drink, favourite, and style of drinking coffee."
  },
  {
    "objectID": "gallery/Python/25Winter/Another coffee survey/Pawatsada.html#introduction",
    "href": "gallery/Python/25Winter/Another coffee survey/Pawatsada.html#introduction",
    "title": "Coffee Survey",
    "section": "",
    "text": "1.1 Import modules and dataset\n\n\nShow code\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\n\ndf = pd.read_csv(\"../../../../data/coffee_survey.csv\")\n\n\n1.2 Data Exploration\n\n\nShow code\ndf.head(10)\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nage\ncups\nwhere_drink\npurchase_other\nfavourite\nfavorite_specify\nadditions\nadditions_other\nsweetener\n...\nmost_paid\nmost_willing\nvalue_cafe\nspent_equipment\nvalue_equipment\ngender\neducation_level\nemployment_status\nnumber_children\npolitical_affiliation\n\n\n\n\n0\n1\n&lt;18 years old\n3\nAt home, At the office, At a cafe\nNaN\nPourover\nNaN\nNo - just black, Milk, dairy alternative, or c...\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nOther (please specify)\nBachelor's degree\nEmployed full-time\nMore than 3\nDemocrat\n\n\n1\n2\n&gt;65 years old\n3\nAt the office, At a cafe\nNaN\nCortado\nNaN\nNo - just black\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n3\n25-34 years old\n1\nAt home, At the office, On the go\nNaN\nRegular drip coffee\nNaN\nMilk, dairy alternative, or coffee creamer, Su...\nNaN\nGranulated Sugar, Brown Sugar\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nFemale\nBachelor's degree\nEmployed full-time\nNaN\nDemocrat\n\n\n3\n4\n18-24 years old\n2\nAt the office\nNaN\nIced coffee\nNaN\nMilk, dairy alternative, or coffee creamer\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n5\n45-54 years old\n2\nAt home, At the office, At a cafe, On the go\nNaN\nRegular drip coffee\nNaN\nNo - just black\nNaN\nNaN\n...\n$4-$6\n$8-$10\nNo\n$500-$1000\nYes\nMale\nMaster's degree\nEmployed full-time\n2\nNo affiliation\n\n\n5\n6\n&gt;65 years old\n1\nAt home\nNaN\nRegular drip coffee\nNaN\nNo - just black\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n6\n7\n25-34 years old\n2\nAt home, At the office\nNaN\nPourover\nNaN\nNo - just black\nNaN\nNaN\n...\n$2-$4\nMore than $20\nYes\n$50-$100\nYes\nMale\nMaster's degree\nUnemployed\nNaN\nIndependent\n\n\n7\n8\n35-44 years old\n1\nAt the office, At home\nNaN\nIced coffee\nNaN\nNo - just black\nNaN\nNaN\n...\n$10-$15\nMore than $20\nYes\n$100-$300\nYes\nMale\nBachelor's degree\nEmployed full-time\n3\nNo affiliation\n\n\n8\n9\n45-54 years old\nMore than 4\nAt home\nNaN\nPourover\nNaN\nNo - just black\nNaN\nNaN\n...\n$10-$15\n$15-$20\nYes\n$300-$500\nYes\nMale\nBachelor's degree\nEmployed full-time\n3\nNo affiliation\n\n\n9\n10\n35-44 years old\n1\nAt the office, At a cafe, At home\nNaN\nCappuccino\nNaN\nMilk, dairy alternative, or coffee creamer, Su...\nNaN\nGranulated Sugar, Brown Sugar\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n10 rows × 43 columns\n\n\n\nAge exploration\n\n\nShow code\nsns.catplot(data = df, x = \"age\", kind=\"count\", height=5, aspect=2)\n\n\n\n\n\n\n\n\n\n\nAge 25 to 34 range is the highest age range among coffee customers.\n\n1.3 Data Filtering\n\n\nShow code\ndf_focused = df[[\"age\", \"where_drink\", \"favourite\", 'style']].copy()\ndf_focused.head(10)\n\n\n\n\n\n\n\n\n\nage\nwhere_drink\nfavourite\nstyle\n\n\n\n\n0\n&lt;18 years old\nAt home, At the office, At a cafe\nPourover\nBright\n\n\n1\n&gt;65 years old\nAt the office, At a cafe\nCortado\nFruity\n\n\n2\n25-34 years old\nAt home, At the office, On the go\nRegular drip coffee\nSweet\n\n\n3\n18-24 years old\nAt the office\nIced coffee\nNutty\n\n\n4\n45-54 years old\nAt home, At the office, At a cafe, On the go\nRegular drip coffee\nFloral\n\n\n5\n&gt;65 years old\nAt home\nRegular drip coffee\nFull Bodied\n\n\n6\n25-34 years old\nAt home, At the office\nPourover\nFloral\n\n\n7\n35-44 years old\nAt the office, At home\nIced coffee\nFruity\n\n\n8\n45-54 years old\nAt home\nPourover\nFull Bodied\n\n\n9\n35-44 years old\nAt the office, At a cafe, At home\nCappuccino\nNutty\n\n\n\n\n\n\n\n\nFocusing on 4 attributes including age, where to drink, favourite, and style of drinking coffee."
  },
  {
    "objectID": "gallery/Python/25Winter/Another coffee survey/Pawatsada.html#data-analysis",
    "href": "gallery/Python/25Winter/Another coffee survey/Pawatsada.html#data-analysis",
    "title": "Coffee Survey",
    "section": "2. Data Analysis",
    "text": "2. Data Analysis\n2.1 Preferred Coffee Places by Age Group\n#Manage “where_drink” : spliting words\n\n\nShow code\ndf_focused['where_drink'] = df_focused['where_drink'].fillna('')\ndf_focused['where_list']=df_focused['where_drink'].str.split(pat=\", \")\ndf_focused.head()\n\n\n\n\n\n\n\n\n\nage\nwhere_drink\nfavourite\nstyle\nwhere_list\n\n\n\n\n0\n&lt;18 years old\nAt home, At the office, At a cafe\nPourover\nBright\n[At home, At the office, At a cafe]\n\n\n1\n&gt;65 years old\nAt the office, At a cafe\nCortado\nFruity\n[At the office, At a cafe]\n\n\n2\n25-34 years old\nAt home, At the office, On the go\nRegular drip coffee\nSweet\n[At home, At the office, On the go]\n\n\n3\n18-24 years old\nAt the office\nIced coffee\nNutty\n[At the office]\n\n\n4\n45-54 years old\nAt home, At the office, At a cafe, On the go\nRegular drip coffee\nFloral\n[At home, At the office, At a cafe, On the go]\n\n\n\n\n\n\n\n#Manage “where_drink” : exploding and making them to list then one-hot for the list\n\n\nShow code\ndf_exploded = df_focused.explode('where_list')\ndummies = pd.crosstab(df_exploded.index, df_exploded['where_list'])\ndf_final = df_focused.join(dummies.groupby(dummies.index).sum())\ndf_final.head()\n\n\n\n\n\n\n\n\n\nage\nwhere_drink\nfavourite\nstyle\nwhere_list\n\nAt a cafe\nAt home\nAt the office\nNone of these\nOn the go\n\n\n\n\n0\n&lt;18 years old\nAt home, At the office, At a cafe\nPourover\nBright\n[At home, At the office, At a cafe]\n0\n1\n1\n1\n0\n0\n\n\n1\n&gt;65 years old\nAt the office, At a cafe\nCortado\nFruity\n[At the office, At a cafe]\n0\n1\n0\n1\n0\n0\n\n\n2\n25-34 years old\nAt home, At the office, On the go\nRegular drip coffee\nSweet\n[At home, At the office, On the go]\n0\n0\n1\n1\n0\n1\n\n\n3\n18-24 years old\nAt the office\nIced coffee\nNutty\n[At the office]\n0\n0\n0\n1\n0\n0\n\n\n4\n45-54 years old\nAt home, At the office, At a cafe, On the go\nRegular drip coffee\nFloral\n[At home, At the office, At a cafe, On the go]\n0\n1\n1\n1\n0\n1\n\n\n\n\n\n\n\n#Manage “where_drink” : exploring mean for each group of age\n\n\nShow code\ngroupby_age = df_final.groupby('age')[df_final.select_dtypes(include='number').columns].mean()\ngroupby_age.head()\n\n\n\n\n\n\n\n\n\n\nAt a cafe\nAt home\nAt the office\nNone of these\nOn the go\n\n\nage\n\n\n\n\n\n\n\n\n\n\n18-24 years old\n0.002398\n0.414868\n0.872902\n0.342926\n0.016787\n0.194245\n\n\n25-34 years old\n0.001055\n0.329641\n0.912975\n0.390295\n0.011603\n0.188291\n\n\n35-44 years old\n0.001095\n0.265060\n0.933187\n0.369113\n0.003286\n0.181818\n\n\n45-54 years old\n0.000000\n0.161972\n0.957746\n0.250000\n0.000000\n0.140845\n\n\n55-64 years old\n0.017045\n0.085227\n0.948864\n0.284091\n0.000000\n0.102273\n\n\n\n\n\n\n\n#Stacked bar plot\n\n\nShow code\ngroupby_age.plot(kind='bar', stacked=True, figsize=(10,6), colormap='tab20')\nplt.title('Preferred Coffee Places by Age Group')\nplt.ylabel('Proportion of Respondents')\nplt.xlabel('Age Group')\nplt.legend(title='Where People Drink Coffee', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n2.2 Preferred Type of Coffee by Age Group\n#Group favourite by Age\n\n\nShow code\nfavourite_by_agegroup = df_focused.groupby('age')['favourite'].value_counts().unstack().fillna(0)\n\n\n#Heatmap\n\n\nShow code\nplt.figure(figsize=(12, 6))\nsns.heatmap(favourite_by_agegroup, annot=True, fmt='.0f', cmap='YlGnBu')\nplt.title('Favorite Type by Age Group')\nplt.ylabel('Age Group')\nplt.xlabel('Favorite')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n2.3 Preferred Style of Coffee by Age Group\n#Group Style by Age\n\n\nShow code\nstyle_by_agegroup = df_focused.groupby('age')['style'].value_counts().unstack().fillna(0)\n\n\nGrouped bar plt\n\n\nShow code\nstyle_by_agegroup.T.plot(kind='bar', figsize=(12, 6))\nplt.title('Style Preference by Age Group')\nplt.ylabel('Number of Respondents')\nplt.xlabel('Style')\nplt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Horror/coffee.html",
    "href": "gallery/Python/25Winter/Coffee Horror/coffee.html",
    "title": "Analysis of Coffee Preference",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv(\"../../../../data/coffee_survey.csv\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot (data = df, \n             x = \"coffee_c_personal_preference\",\n             y = \"coffee_c_bitterness\",\n             kind = \"box\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Horror/coffee.html#comparing-personal-preferences-and-bitterness-for-coffeec",
    "href": "gallery/Python/25Winter/Coffee Horror/coffee.html#comparing-personal-preferences-and-bitterness-for-coffeec",
    "title": "Analysis of Coffee Preference",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv(\"../../../../data/coffee_survey.csv\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot (data = df, \n             x = \"coffee_c_personal_preference\",\n             y = \"coffee_c_bitterness\",\n             kind = \"box\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Horror/coffee.html#distribution-of-age",
    "href": "gallery/Python/25Winter/Coffee Horror/coffee.html#distribution-of-age",
    "title": "Analysis of Coffee Preference",
    "section": "Distribution of Age",
    "text": "Distribution of Age\n\nsns.displot(data = df, y = \"age\")"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Horror/coffee.html#distribution-of-favourite-coffee",
    "href": "gallery/Python/25Winter/Coffee Horror/coffee.html#distribution-of-favourite-coffee",
    "title": "Analysis of Coffee Preference",
    "section": "Distribution of Favourite coffee",
    "text": "Distribution of Favourite coffee\n\nsns.displot(data = df,\n            y = \"favourite\",\n            binwidth = 1)"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Horror/coffee.html#favourite-coffee-based-on-gender",
    "href": "gallery/Python/25Winter/Coffee Horror/coffee.html#favourite-coffee-based-on-gender",
    "title": "Analysis of Coffee Preference",
    "section": "Favourite coffee based on gender",
    "text": "Favourite coffee based on gender\n\nsns.displot(data = df, x = \"gender\", y = \"favourite\")\nplt.xticks(rotation=45, ha='right')\n\n([0, 1, 2, 3, 4],\n [Text(0, 0, 'Other (please specify)'),\n  Text(1, 0, 'Female'),\n  Text(2, 0, 'Male'),\n  Text(3, 0, 'Non-binary'),\n  Text(4, 0, 'Prefer not to say')])"
  },
  {
    "objectID": "gallery/Python/25Winter/Coffee Horror/coffee.html#preferred-coffee-style",
    "href": "gallery/Python/25Winter/Coffee Horror/coffee.html#preferred-coffee-style",
    "title": "Analysis of Coffee Preference",
    "section": "Preferred Coffee Style",
    "text": "Preferred Coffee Style\n\nnames = ['Pourover', 'Latte','Drip coffee', 'Cappuccino', 'Espresso','Cortado','Americano', 'Iced coffee', 'Mocha','Cold brew','Other', 'Blended drinks']\nsize = [1026, 654, 415, 330, 309, 295, 238, 147, 116, 108, 105, 45]\n# Create a circle at the center of the plot\nmy_circle = plt.Circle( (0,0), 0.7, color='white')\n# Give color names\nplt.pie(size, labels=names, colors=['red','green','blue','skyblue'])\np = plt.gcf()\np.gca().add_artist(my_circle)\n \n# Show the graph\nplt.show()"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html",
    "title": "My Python project",
    "section": "",
    "text": "Dengue fever is transmitted through the wound of an Aedes mosquito that harbors the dengue virus. Transmission occurs when the mosquito acquires the virus from an individual with circulating dengue virus in their bloodstream during a biting interaction. Symptoms typically manifest within four to six days post-infection and can persist for about ten days. While some cases present mild symptoms that could be mistaken for the flu or other viral infections, the potential development of severe complications should not be overlooked. This study aims to develop a some basic descriptive analysis capable of utilizing relevant information to show dengue outbreaks within the geographic regions of Bangladesh."
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#introduction",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#introduction",
    "title": "My Python project",
    "section": "",
    "text": "Dengue fever is transmitted through the wound of an Aedes mosquito that harbors the dengue virus. Transmission occurs when the mosquito acquires the virus from an individual with circulating dengue virus in their bloodstream during a biting interaction. Symptoms typically manifest within four to six days post-infection and can persist for about ten days. While some cases present mild symptoms that could be mistaken for the flu or other viral infections, the potential development of severe complications should not be overlooked. This study aims to develop a some basic descriptive analysis capable of utilizing relevant information to show dengue outbreaks within the geographic regions of Bangladesh."
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#dengue-cases-data-of-bangladesh",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#dengue-cases-data-of-bangladesh",
    "title": "My Python project",
    "section": "Dengue Cases data of Bangladesh",
    "text": "Dengue Cases data of Bangladesh"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#viewing-the-data-structure",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#viewing-the-data-structure",
    "title": "My Python project",
    "section": "Viewing the data structure",
    "text": "Viewing the data structure"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#descriptive-statistics-of-all-variables",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#descriptive-statistics-of-all-variables",
    "title": "My Python project",
    "section": "Descriptive Statistics of all variables",
    "text": "Descriptive Statistics of all variables"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#total-number-of-observations",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#total-number-of-observations",
    "title": "My Python project",
    "section": "Total number of observations:",
    "text": "Total number of observations:"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#measures-of-central-tendency",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#measures-of-central-tendency",
    "title": "My Python project",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#summary-of-statistics",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#summary-of-statistics",
    "title": "My Python project",
    "section": "Summary of statistics",
    "text": "Summary of statistics"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#inferential-statistics",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#inferential-statistics",
    "title": "My Python project",
    "section": "Inferential Statistics",
    "text": "Inferential Statistics"
  },
  {
    "objectID": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#checking-relationship-between-variables",
    "href": "gallery/Python/25Winter/Mst Noorunnahar/project_nahar.html#checking-relationship-between-variables",
    "title": "My Python project",
    "section": "Checking relationship between variables",
    "text": "Checking relationship between variables"
  },
  {
    "objectID": "gallery/Python/25Winter/Sisay/report.html",
    "href": "gallery/Python/25Winter/Sisay/report.html",
    "title": "my python report",
    "section": "",
    "text": "Markdown is a markup language * we can create test, heading, and graphs for relationship between variables"
  },
  {
    "objectID": "gallery/Python/25Winter/Sisay/report.html#introducing-markdown",
    "href": "gallery/Python/25Winter/Sisay/report.html#introducing-markdown",
    "title": "my python report",
    "section": "",
    "text": "Markdown is a markup language * we can create test, heading, and graphs for relationship between variables"
  },
  {
    "objectID": "gallery/Python/25Winter/Sisay/report.html#gapminder-data",
    "href": "gallery/Python/25Winter/Sisay/report.html#gapminder-data",
    "title": "my python report",
    "section": "gapminder data",
    "text": "gapminder data\nlet’s visualise life expectancy by gdp per captial:\n\n\n\n\n\nGDP per caspita would affect life expectancy\n\n\n\n\n##Effect of population size on GDP let’s visualise effect of populationy on gdp per captial:\n\n\n\n\n\npopulation size could affect GDP per capital\n\n\n\n\n##Effect of population size on lie expectancy let’s visualise effect of populationy on life expectancy:\n\n\n\n\n\npopulation size could affect life expectancy\n\n\n\n\n\n\n\n\n\ncontinent could affect life expectancy\n\n\n\n\n\n\n\n\n\ncontinent could affect life expectancy\n\n\n\n\n\n\n\n\n\npopulation distribution by continent"
  },
  {
    "objectID": "gallery/Python/26Summer/example_project/example_project.html",
    "href": "gallery/Python/26Summer/example_project/example_project.html",
    "title": "Goalkeepers and their heights",
    "section": "",
    "text": "Set up code\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nimport seaborn as sns\n\ndf_raw = pd.read_csv(\"../../../../data/Players2024.csv\")"
  },
  {
    "objectID": "gallery/Python/26Summer/example_project/example_project.html#a-glimpse-at-the-dataset",
    "href": "gallery/Python/26Summer/example_project/example_project.html#a-glimpse-at-the-dataset",
    "title": "Goalkeepers and their heights",
    "section": "A glimpse at the dataset",
    "text": "A glimpse at the dataset\nWe’ll begin just by taking a glimpse at the dataset:\n\n\nShow code\ndf_raw.head(10)\n\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\n0\nJames Milner\n1986-01-04\n175.0\nMidfield\nEngland\n38\nBrighton and Hove Albion Football Club\n\n\n1\nAnastasios Tsokanis\n1991-05-02\n176.0\nMidfield\nGreece\n33\nVolou Neos Podosferikos Syllogos\n\n\n2\nJonas Hofmann\n1992-07-14\n176.0\nMidfield\nGermany\n32\nBayer 04 Leverkusen Fußball\n\n\n3\nPepe Reina\n1982-08-31\n188.0\nGoalkeeper\nSpain\n42\nCalcio Como\n\n\n4\nLionel Carole\n1991-04-12\n180.0\nDefender\nFrance\n33\nKayserispor Kulübü\n\n\n5\nLudovic Butelle\n1983-04-03\n188.0\nGoalkeeper\nFrance\n41\nStade de Reims\n\n\n6\nDaley Blind\n1990-03-09\n180.0\nDefender\nNetherlands\n34\nGirona Fútbol Club S. A. D.\n\n\n7\nCraig Gordon\n1982-12-31\n193.0\nGoalkeeper\nScotland\n41\nHeart of Midlothian Football Club\n\n\n8\nDimitrios Sotiriou\n1987-09-13\n185.0\nGoalkeeper\nGreece\n37\nOmilos Filathlon Irakliou FC\n\n\n9\nAlessio Cragno\n1994-06-28\n184.0\nGoalkeeper\nItaly\n30\nAssociazione Calcio Monza"
  },
  {
    "objectID": "gallery/Python/26Summer/example_project/example_project.html#cleaning-the-data",
    "href": "gallery/Python/26Summer/example_project/example_project.html#cleaning-the-data",
    "title": "Goalkeepers and their heights",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nThe data had a few issues, as the following plot shows:\n\n\nShow code\nsns.catplot(df_raw, x = \"positions\", y = \"height_cm\")\n\n\n\n\n\n\n\n\n\nIt looks like some of the players’ positions and heights were recorded incorrectly. To clean, let’s remove the “Missing” positions and ensure that heights are reasonable:\n\n\nShow code\ndf = df_raw.copy()\n\n# Remove missing position\ndf = df[df[\"positions\"] != \"Missing\"]\n\n# Ensure reasonable heights\ndf = df[df[\"height_cm\"] &gt; 100]\n\n\nTo confirm, let’s plot the outliers in a different colour\n\n\nShow code\n# Identify outliers\noutliers = pd.concat([df_raw,df]).drop_duplicates(keep = False)\n\nsns.catplot(df, x = \"positions\", y = \"height_cm\")\nsns.stripplot(outliers, x = \"positions\", y = \"height_cm\", color = \"r\")"
  },
  {
    "objectID": "gallery/Python/26Summer/example_project/example_project.html#visualising-the-players-heights",
    "href": "gallery/Python/26Summer/example_project/example_project.html#visualising-the-players-heights",
    "title": "Goalkeepers and their heights",
    "section": "Visualising the players’ heights",
    "text": "Visualising the players’ heights\nAfter cleaning the data we can now analyse the players’ heights to see if there’s differences between positions. A box plot can show the distribution of heights:\n\n\nShow code\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"box\", order = [\"Goalkeeper\", \"Defender\", \"Midfield\", \"Attack\"])\nplt.xlabel(\"Position\")\nplt.ylabel(\"Height (cm)\")\nplt.savefig(\"./tb.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\nIt looks like goalkeepers are taller than the rest!\nLet’s through the age variable into the mix, to see if players’ heights allow them to compete longer.\n\n\nShow code\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\",\n           hover_data = \"nationality\", labels = {\"height_cm\": \"Height (cm)\",\n                                                 \"positions\": \"Position\"})\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nIt doesn’t look like there’s a relationship between heights and ages, but clearly it affects their position!"
  },
  {
    "objectID": "gallery/Python/26Summer/example_project/example_project.html#global-spread",
    "href": "gallery/Python/26Summer/example_project/example_project.html#global-spread",
    "title": "Goalkeepers and their heights",
    "section": "Global spread",
    "text": "Global spread\nWe haven’t looked at the nationality column yet. Let’s draw up a map using plotly to see where the players come from.\n\n\nShow code\n# Change country names to match plotly reference\ndf[\"nationality\"] = df[\"nationality\"].replace([\"England\", \"Türkiye\", \"Cote d'Ivoire\", \n                                               \"Northern Ireland\", \"Wales\"], \n                                               [\"United Kingdom\", \"Turkey\", \"Ivory Coast\",\n                                                \"United Kingdom\", \"United Kingdom\"])\n\n# Make the count\ncountries = df.value_counts(\"nationality\")\n\n# Make the plot\npx.choropleth(locations = countries.index, locationmode = \"country names\", color = countries,\n              labels = {\"locations\": \"Country\", \"color\": \"# of players\"})\n\n\n                            \n                                            \n\n\nLooks like most players are from Europe. Pan and zoom to see the finer details."
  },
  {
    "objectID": "gallery/R/25Winter/Aisha Aslam/R Intensive Report.html",
    "href": "gallery/R/25Winter/Aisha Aslam/R Intensive Report.html",
    "title": "Good Reads",
    "section": "",
    "text": "If you love books, you are at just the right place :) Wouldn’t it be interesting to find out:\nIs there a correlation between higher book ratings and the number of book reviews some popular books receive?\nLet us find out using the following dataset."
  },
  {
    "objectID": "gallery/R/25Winter/Aisha Aslam/R Intensive Report.html#introduction",
    "href": "gallery/R/25Winter/Aisha Aslam/R Intensive Report.html#introduction",
    "title": "Good Reads",
    "section": "",
    "text": "If you love books, you are at just the right place :) Wouldn’t it be interesting to find out:\nIs there a correlation between higher book ratings and the number of book reviews some popular books receive?\nLet us find out using the following dataset."
  },
  {
    "objectID": "gallery/R/25Winter/Aisha Aslam/R Intensive Report.html#the-dataset",
    "href": "gallery/R/25Winter/Aisha Aslam/R Intensive Report.html#the-dataset",
    "title": "Good Reads",
    "section": "The Dataset",
    "text": "The Dataset\nWe will be using the publicly accessible dataset ‘Good reads books’ . (https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks ).\n\n\nShow code\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"plotly\")\nlibrary(\"knitr\")\n\n\nA Sneak-peak into the dataset\n\n\nShow code\ngoodreadsdata &lt;- read.csv(\"../../../../data/books.csv\")\n\nkable(head(goodreadsdata))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nbookID\ntitle\nauthors\naverage_rating\nisbn\nisbn13\nlanguage_code\nnum_pages\nratings_count\ntext_reviews_count\npublication_date\npublisher\n\n\n\n\n1\n1\nHarry Potter and the Half-Blood Prince (Harry Potter #6)\nJ.K. Rowling/Mary GrandPré\n4.57\n0439785960\n9.780440e+12\neng\n652\n2095690\n27591\n2006-09-16\nScholastic Inc.\n\n\n2\n2\nHarry Potter and the Order of the Phoenix (Harry Potter #5)\nJ.K. Rowling/Mary GrandPré\n4.49\n0439358078\n9.780439e+12\neng\n870\n2153167\n29221\n2004-09-01\nScholastic Inc.\n\n\n3\n4\nHarry Potter and the Chamber of Secrets (Harry Potter #2)\nJ.K. Rowling\n4.42\n0439554896\n9.780440e+12\neng\n352\n6333\n244\n2003-11-01\nScholastic\n\n\n4\n5\nHarry Potter and the Prisoner of Azkaban (Harry Potter #3)\nJ.K. Rowling/Mary GrandPré\n4.56\n043965548X\n9.780440e+12\neng\n435\n2339585\n36325\n2004-05-01\nScholastic Inc.\n\n\n5\n8\nHarry Potter Boxed Set Books 1-5 (Harry Potter #1-5)\nJ.K. Rowling/Mary GrandPré\n4.78\n0439682584\n9.780440e+12\neng\n2690\n41428\n164\n2004-09-13\nScholastic\n\n\n6\n9\nUnauthorized Harry Potter Book Seven News: Half-Blood Prince Analysis and Speculation\nW. Frederick Zimmerman\n3.74\n0976540606\n9.780977e+12\nen-US\n152\n19\n1\n2005-04-26\nNimble Books\n\n\n\n\n\nLet’s visualize the book reviews and book ratings\n\n\nShow code\n#View(goodreadsdata)\n\nggplot(goodreadsdata, aes(x = average_rating, y = text_reviews_count)) +\n  geom_point( colour = \"blue\") \n\n\n\n\n\n\n\n\n\nMore ratings = more reviews :)"
  },
  {
    "objectID": "gallery/R/25Winter/Casey & Jess Project/Project Hospital Report.html",
    "href": "gallery/R/25Winter/Casey & Jess Project/Project Hospital Report.html",
    "title": "Project Hospital Report",
    "section": "",
    "text": "Initially we selected our dataset to study. We selected the QLD Hospital data.\n\n\n\nGoal: identify which variables are discrete (categorical) and which are continuous.\nTo do this we: First: loaded our data\n\ndataset &lt;- read.csv(\"../../../../data/hospital_data.csv\")\n\nSecond: viewed the column names of our data\n\nnames(dataset)\n\n [1] \"X.1\"                                                  \n [2] \"X\"                                                    \n [3] \"Facility.HHS.Code\"                                    \n [4] \"Facility.HHS.Desc\"                                    \n [5] \"Last.Month.in.QTR\"                                    \n [6] \"Triage.Category\"                                      \n [7] \"Number.of.Attendances\"                                \n [8] \"Variation.in.the.number.of.attendances....\"           \n [9] \"Patients.Seen.within.clinically.recommended.times....\"\n[10] \"Median.Waiting.time.to.treatment..minutes.\"           \n[11] \"Patients.who.did.not.wait.for.treatment....\"          \n[12] \"Patients.admitted.from.the.Emergency.Department....\"  \n[13] \"Admissions.to.hospital.within.4.hours....\"            \n\n\nThird: looked at the structure to see type of data in each column\n\nstr(dataset)\n\n'data.frame':   9442 obs. of  13 variables:\n $ X.1                                                  : int  1 2 3 4 5 6 7 8 9 10 ...\n $ X                                                    : int  0 1 2 3 4 5 6 7 8 9 ...\n $ Facility.HHS.Code                                    : int  1 1 1 1 1 1 4 4 4 4 ...\n $ Facility.HHS.Desc                                    : chr  \"Mater Adult\" \"Mater Adult\" \"Mater Adult\" \"Mater Adult\" ...\n $ Last.Month.in.QTR                                    : chr  \"Jun-24\" \"Jun-24\" \"Jun-24\" \"Jun-24\" ...\n $ Triage.Category                                      : chr  \"1\" \"2\" \"3\" \"4\" ...\n $ Number.of.Attendances                                : int  58 2998 6035 3767 513 13371 215 4986 13663 9169 ...\n $ Variation.in.the.number.of.attendances....           : num  -17.1 17.4 -4.4 -8 -20.8 -2.3 -0.5 -12.9 0.7 -8.1 ...\n $ Patients.Seen.within.clinically.recommended.times....: num  100 37.6 54.2 78.9 94.8 58.7 100 73.2 61.1 73.9 ...\n $ Median.Waiting.time.to.treatment..minutes.           : num  0 16 27 28 29 25 0 7 22 28 ...\n $ Patients.who.did.not.wait.for.treatment....          : num  0 1.2 3.1 6.4 15.8 4.1 0 0.2 2.5 4.5 ...\n $ Patients.admitted.from.the.Emergency.Department....  : num  72.4 44.9 40.8 20.8 6 34.9 71.2 59.5 41.5 13.8 ...\n $ Admissions.to.hospital.within.4.hours....            : num  31 22.2 26.1 39.4 41.9 27.4 43.1 44.9 34.1 40.3 ...\n\n\nFourth: crated a summary of the dataset\n\nsummary(dataset)\n\n      X.1             X         Facility.HHS.Code Facility.HHS.Desc \n Min.   :   1   Min.   :  0.0   Min.   :    1     Length:9442       \n 1st Qu.:2361   1st Qu.:157.0   1st Qu.:   68     Class :character  \n Median :4722   Median :314.0   Median :  117     Mode  :character  \n Mean   :4722   Mean   :314.2   Mean   : 1091                       \n 3rd Qu.:7082   3rd Qu.:472.0   3rd Qu.:  192                       \n Max.   :9442   Max.   :629.0   Max.   :99999                       \n                                                                    \n Last.Month.in.QTR  Triage.Category    Number.of.Attendances\n Length:9442        Length:9442        Min.   :     0       \n Class :character   Class :character   1st Qu.:    84       \n Mode  :character   Mode  :character   Median :   375       \n                                       Mean   :  3754       \n                                       3rd Qu.:  1501       \n                                       Max.   :640258       \n                                                            \n Variation.in.the.number.of.attendances....\n Min.   :-100.000                          \n 1st Qu.:  -6.313                          \n Median :   5.000                          \n Mean   :  13.734                          \n 3rd Qu.:  22.095                          \n Max.   :1000.000                          \n NA's   :724                               \n Patients.Seen.within.clinically.recommended.times....\n Min.   :  0.00                                       \n 1st Qu.:  0.00                                       \n Median : 19.00                                       \n Mean   : 40.49                                       \n 3rd Qu.: 92.00                                       \n Max.   :100.00                                       \n NA's   :235                                          \n Median.Waiting.time.to.treatment..minutes.\n Min.   :  0.00                            \n 1st Qu.:  6.00                            \n Median : 74.00                            \n Mean   : 56.76                            \n 3rd Qu.: 98.28                            \n Max.   :100.00                            \n NA's   :168                               \n Patients.who.did.not.wait.for.treatment....\n Min.   :  0.00                             \n 1st Qu.:  2.00                             \n Median :  7.00                             \n Mean   : 17.36                             \n 3rd Qu.: 26.59                             \n Max.   :100.00                             \n NA's   :1000                               \n Patients.admitted.from.the.Emergency.Department....\n Min.   :  0.00                                     \n 1st Qu.: 21.15                                     \n Median : 50.00                                     \n Mean   : 52.34                                     \n 3rd Qu.: 87.50                                     \n Max.   :100.00                                     \n NA's   :669                                        \n Admissions.to.hospital.within.4.hours....\n Min.   :  0.00                           \n 1st Qu.: 59.00                           \n Median : 86.00                           \n Mean   : 76.48                           \n 3rd Qu.: 96.97                           \n Max.   :100.00                           \n NA's   :468                              \n\n\nFifth: Created a summary of a specific columnn, in this case the Median wait time to gain treatment (mins).\n\nsummary(dataset$Median.Waiting.time.to.treatment..minutes.)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   74.00   56.76   98.28  100.00     168 \n\n\n\n\n\nGoal: filter by a condition or group by and aggregate over a particular variable The condition we chose to filter by was Hospital Facility Name - Mater Adult. We did this by loading dplyr, created another copy of the filtered data called “subset”. It was filtered by Mater Adult to see only information from this facility.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nsubset=dataset %&gt;% filter(Facility.HHS.Desc==\"Mater Adult\")\n\nTo group we created a new dataset and then grouped by Facility code number\n\naggregated=dataset\naggregated %&gt;% group_by(Facility.HHS.Code)\n\n# A tibble: 9,442 × 13\n# Groups:   Facility.HHS.Code [105]\n     X.1     X Facility.HHS.Code Facility.HHS.Desc Last.Month.in.QTR\n   &lt;int&gt; &lt;int&gt;             &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;            \n 1     1     0                 1 Mater Adult       Jun-24           \n 2     2     1                 1 Mater Adult       Jun-24           \n 3     3     2                 1 Mater Adult       Jun-24           \n 4     4     3                 1 Mater Adult       Jun-24           \n 5     5     4                 1 Mater Adult       Jun-24           \n 6     6     5                 1 Mater Adult       Jun-24           \n 7     7     6                 4 Prince Charles    Jun-24           \n 8     8     7                 4 Prince Charles    Jun-24           \n 9     9     8                 4 Prince Charles    Jun-24           \n10    10     9                 4 Prince Charles    Jun-24           \n# ℹ 9,432 more rows\n# ℹ 8 more variables: Triage.Category &lt;chr&gt;, Number.of.Attendances &lt;int&gt;,\n#   Variation.in.the.number.of.attendances.... &lt;dbl&gt;,\n#   Patients.Seen.within.clinically.recommended.times.... &lt;dbl&gt;,\n#   Median.Waiting.time.to.treatment..minutes. &lt;dbl&gt;,\n#   Patients.who.did.not.wait.for.treatment.... &lt;dbl&gt;,\n#   Patients.admitted.from.the.Emergency.Department.... &lt;dbl&gt;, …\n\n\nWe then had to rename a column due to some errors (removed for reruns -\n\naggregated &lt;- rename(aggregated, \"Median_wait\" = \"Median.Waiting.time.to.treatment..minutes.\")\n\nThen Grouped by facility and summarised mean average attendance, median wait time and Patients that didn’t wait for treatment for each facility. We also had to remove missing data from the ptients not waititng for treatment column.\n\nHosp_wait_time &lt;- aggregated %&gt;%  \n  group_by(Facility.HHS.Code) %&gt;%  \n  summarise(avg_attendance = mean(Number.of.Attendances),\n            median_wait_time = median(Median_wait),\n            No_non_wait = mean(Patients.who.did.not.wait.for.treatment....,na.rm=TRUE))\n\n\n\n\nGoal: create a visualisation of one to three variables in your summary data. To visualise this data we: load ggplot2\n\nlibrary(ggplot2)\n\nCreate a scatter plot of avg attendance vs med wait time\n\nggplot(data = Hosp_wait_time, \n       mapping= aes(x = avg_attendance,\n       y = median_wait_time)) +\n  geom_point()\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis showed us a large outlier so we removed this using the code below:\n\nfilter(Hosp_wait_time, Facility.HHS.Code != \"99999\")\n\n# A tibble: 104 × 4\n   Facility.HHS.Code avg_attendance median_wait_time No_non_wait\n               &lt;int&gt;          &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;\n 1                 1          4761.             40.2        22.6\n 2                 4         10404              50.8        25.1\n 3                11          5747.             55.2        34.8\n 4                15          6389.             46.5        27.1\n 5                16          6463.             52.5        26.1\n 6                22          5290.             66.2        27.5\n 7                28          4911.             66.6        22.6\n 8                29          8901              51.4        28.6\n 9                30          5328.             63          24.8\n10                32          7682.             68.1        26.7\n# ℹ 94 more rows\n\nsubset &lt;- Hosp_wait_time %&gt;% filter(Facility.HHS.Code !=\"99999\")\n\nWe Then reran the graph without the outlier and added lables and a trend line.\n\nggplot(data = subset, \n       mapping= aes(x = avg_attendance,\n                    y = median_wait_time)) +\n  geom_point()+\n  labs(title = \"Does Average Attendance Number Effect Median Wait Time?\",\n       x=\"Average Attendance\",\n       y=\"Median Wait Time\") +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWith the adjusted data we then also ran 2 more scatters with trend lines looking at other factors contributing to wait time and patients leaving without treatment.\n\nggplot(data = subset, \n       mapping= aes(x = median_wait_time,\n                    y = No_non_wait)) +\n  geom_point()+\n  labs(title = \"Does wait time influence Number of People Leaving without Treatment?\",\n       x=\"Median Wait Time\",\n       y=\"Number leaving without Treatment\") +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nggplot(data = subset, \n       mapping= aes(x = No_non_wait,\n                    y = avg_attendance)) +\n  geom_point()+\n  labs(title = \"Does Number Attending Hospital Influence Number of People Leaving without Treatment?\",\n       x=\"Number leaving without Treatment\",\n       y=\"Average Hospital Attendance Numbers\") +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nlooking at number of people that leave based on attendance numbers\nfirst filter out missing median_wait_time data, then created a linear model\n\nsubset &lt;- subset %&gt;%   \n  filter(median_wait_time !=\"Missing\")\nmain_model &lt;- lm(\"No_non_wait~avg_attendance\", subset)\n\nTook the coefficients of the intercept and slope\n\nb0 &lt;- main_model$coefficients[1] #intercept\nb1 &lt;- main_model$coefficients[2] #slope\n\nThen made linear regression line on scatter with labels.\n\nlibrary(ggplot2)\nggplot(subset,\n       aes(x=avg_attendance,\n           y=No_non_wait))+\n  geom_point()+\n  labs(title = \"Does Number Attending Hospital Influence Number of People Leaving without Treatment?\",\n       x=\"Average Hospital Attendance Numbers\",\n       y=\"Number leaving without Treatment\") +\n  geom_abline(intercept = b0, slope = b1)\n\n\n\n\n\n\n\n\nThen compared to Wait time to number of people leaving.\n\nmodel3 &lt;- lm(\"median_wait_time ~No_non_wait\", subset)\nb00 &lt;- model3$coefficients[1] #intercept\nb11 &lt;- model3$coefficients[2] #slope\nggplot(subset,\n       aes(x=No_non_wait,\n           y=median_wait_time))+\n  geom_point()+\n  labs(title = \"Does Number of People Leaving without Treatment Influence Median Wait Time?\",\n       x=\"Number leaving without Treatment\",\n       y=\"Median Wait Time\") +\n  geom_abline(intercept = b00, slope = b11)"
  },
  {
    "objectID": "gallery/R/25Winter/Casey & Jess Project/Project Hospital Report.html#hospital-wait-time-report",
    "href": "gallery/R/25Winter/Casey & Jess Project/Project Hospital Report.html#hospital-wait-time-report",
    "title": "Project Hospital Report",
    "section": "",
    "text": "Initially we selected our dataset to study. We selected the QLD Hospital data.\n\n\n\nGoal: identify which variables are discrete (categorical) and which are continuous.\nTo do this we: First: loaded our data\n\ndataset &lt;- read.csv(\"../../../../data/hospital_data.csv\")\n\nSecond: viewed the column names of our data\n\nnames(dataset)\n\n [1] \"X.1\"                                                  \n [2] \"X\"                                                    \n [3] \"Facility.HHS.Code\"                                    \n [4] \"Facility.HHS.Desc\"                                    \n [5] \"Last.Month.in.QTR\"                                    \n [6] \"Triage.Category\"                                      \n [7] \"Number.of.Attendances\"                                \n [8] \"Variation.in.the.number.of.attendances....\"           \n [9] \"Patients.Seen.within.clinically.recommended.times....\"\n[10] \"Median.Waiting.time.to.treatment..minutes.\"           \n[11] \"Patients.who.did.not.wait.for.treatment....\"          \n[12] \"Patients.admitted.from.the.Emergency.Department....\"  \n[13] \"Admissions.to.hospital.within.4.hours....\"            \n\n\nThird: looked at the structure to see type of data in each column\n\nstr(dataset)\n\n'data.frame':   9442 obs. of  13 variables:\n $ X.1                                                  : int  1 2 3 4 5 6 7 8 9 10 ...\n $ X                                                    : int  0 1 2 3 4 5 6 7 8 9 ...\n $ Facility.HHS.Code                                    : int  1 1 1 1 1 1 4 4 4 4 ...\n $ Facility.HHS.Desc                                    : chr  \"Mater Adult\" \"Mater Adult\" \"Mater Adult\" \"Mater Adult\" ...\n $ Last.Month.in.QTR                                    : chr  \"Jun-24\" \"Jun-24\" \"Jun-24\" \"Jun-24\" ...\n $ Triage.Category                                      : chr  \"1\" \"2\" \"3\" \"4\" ...\n $ Number.of.Attendances                                : int  58 2998 6035 3767 513 13371 215 4986 13663 9169 ...\n $ Variation.in.the.number.of.attendances....           : num  -17.1 17.4 -4.4 -8 -20.8 -2.3 -0.5 -12.9 0.7 -8.1 ...\n $ Patients.Seen.within.clinically.recommended.times....: num  100 37.6 54.2 78.9 94.8 58.7 100 73.2 61.1 73.9 ...\n $ Median.Waiting.time.to.treatment..minutes.           : num  0 16 27 28 29 25 0 7 22 28 ...\n $ Patients.who.did.not.wait.for.treatment....          : num  0 1.2 3.1 6.4 15.8 4.1 0 0.2 2.5 4.5 ...\n $ Patients.admitted.from.the.Emergency.Department....  : num  72.4 44.9 40.8 20.8 6 34.9 71.2 59.5 41.5 13.8 ...\n $ Admissions.to.hospital.within.4.hours....            : num  31 22.2 26.1 39.4 41.9 27.4 43.1 44.9 34.1 40.3 ...\n\n\nFourth: crated a summary of the dataset\n\nsummary(dataset)\n\n      X.1             X         Facility.HHS.Code Facility.HHS.Desc \n Min.   :   1   Min.   :  0.0   Min.   :    1     Length:9442       \n 1st Qu.:2361   1st Qu.:157.0   1st Qu.:   68     Class :character  \n Median :4722   Median :314.0   Median :  117     Mode  :character  \n Mean   :4722   Mean   :314.2   Mean   : 1091                       \n 3rd Qu.:7082   3rd Qu.:472.0   3rd Qu.:  192                       \n Max.   :9442   Max.   :629.0   Max.   :99999                       \n                                                                    \n Last.Month.in.QTR  Triage.Category    Number.of.Attendances\n Length:9442        Length:9442        Min.   :     0       \n Class :character   Class :character   1st Qu.:    84       \n Mode  :character   Mode  :character   Median :   375       \n                                       Mean   :  3754       \n                                       3rd Qu.:  1501       \n                                       Max.   :640258       \n                                                            \n Variation.in.the.number.of.attendances....\n Min.   :-100.000                          \n 1st Qu.:  -6.313                          \n Median :   5.000                          \n Mean   :  13.734                          \n 3rd Qu.:  22.095                          \n Max.   :1000.000                          \n NA's   :724                               \n Patients.Seen.within.clinically.recommended.times....\n Min.   :  0.00                                       \n 1st Qu.:  0.00                                       \n Median : 19.00                                       \n Mean   : 40.49                                       \n 3rd Qu.: 92.00                                       \n Max.   :100.00                                       \n NA's   :235                                          \n Median.Waiting.time.to.treatment..minutes.\n Min.   :  0.00                            \n 1st Qu.:  6.00                            \n Median : 74.00                            \n Mean   : 56.76                            \n 3rd Qu.: 98.28                            \n Max.   :100.00                            \n NA's   :168                               \n Patients.who.did.not.wait.for.treatment....\n Min.   :  0.00                             \n 1st Qu.:  2.00                             \n Median :  7.00                             \n Mean   : 17.36                             \n 3rd Qu.: 26.59                             \n Max.   :100.00                             \n NA's   :1000                               \n Patients.admitted.from.the.Emergency.Department....\n Min.   :  0.00                                     \n 1st Qu.: 21.15                                     \n Median : 50.00                                     \n Mean   : 52.34                                     \n 3rd Qu.: 87.50                                     \n Max.   :100.00                                     \n NA's   :669                                        \n Admissions.to.hospital.within.4.hours....\n Min.   :  0.00                           \n 1st Qu.: 59.00                           \n Median : 86.00                           \n Mean   : 76.48                           \n 3rd Qu.: 96.97                           \n Max.   :100.00                           \n NA's   :468                              \n\n\nFifth: Created a summary of a specific columnn, in this case the Median wait time to gain treatment (mins).\n\nsummary(dataset$Median.Waiting.time.to.treatment..minutes.)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   74.00   56.76   98.28  100.00     168 \n\n\n\n\n\nGoal: filter by a condition or group by and aggregate over a particular variable The condition we chose to filter by was Hospital Facility Name - Mater Adult. We did this by loading dplyr, created another copy of the filtered data called “subset”. It was filtered by Mater Adult to see only information from this facility.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nsubset=dataset %&gt;% filter(Facility.HHS.Desc==\"Mater Adult\")\n\nTo group we created a new dataset and then grouped by Facility code number\n\naggregated=dataset\naggregated %&gt;% group_by(Facility.HHS.Code)\n\n# A tibble: 9,442 × 13\n# Groups:   Facility.HHS.Code [105]\n     X.1     X Facility.HHS.Code Facility.HHS.Desc Last.Month.in.QTR\n   &lt;int&gt; &lt;int&gt;             &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;            \n 1     1     0                 1 Mater Adult       Jun-24           \n 2     2     1                 1 Mater Adult       Jun-24           \n 3     3     2                 1 Mater Adult       Jun-24           \n 4     4     3                 1 Mater Adult       Jun-24           \n 5     5     4                 1 Mater Adult       Jun-24           \n 6     6     5                 1 Mater Adult       Jun-24           \n 7     7     6                 4 Prince Charles    Jun-24           \n 8     8     7                 4 Prince Charles    Jun-24           \n 9     9     8                 4 Prince Charles    Jun-24           \n10    10     9                 4 Prince Charles    Jun-24           \n# ℹ 9,432 more rows\n# ℹ 8 more variables: Triage.Category &lt;chr&gt;, Number.of.Attendances &lt;int&gt;,\n#   Variation.in.the.number.of.attendances.... &lt;dbl&gt;,\n#   Patients.Seen.within.clinically.recommended.times.... &lt;dbl&gt;,\n#   Median.Waiting.time.to.treatment..minutes. &lt;dbl&gt;,\n#   Patients.who.did.not.wait.for.treatment.... &lt;dbl&gt;,\n#   Patients.admitted.from.the.Emergency.Department.... &lt;dbl&gt;, …\n\n\nWe then had to rename a column due to some errors (removed for reruns -\n\naggregated &lt;- rename(aggregated, \"Median_wait\" = \"Median.Waiting.time.to.treatment..minutes.\")\n\nThen Grouped by facility and summarised mean average attendance, median wait time and Patients that didn’t wait for treatment for each facility. We also had to remove missing data from the ptients not waititng for treatment column.\n\nHosp_wait_time &lt;- aggregated %&gt;%  \n  group_by(Facility.HHS.Code) %&gt;%  \n  summarise(avg_attendance = mean(Number.of.Attendances),\n            median_wait_time = median(Median_wait),\n            No_non_wait = mean(Patients.who.did.not.wait.for.treatment....,na.rm=TRUE))\n\n\n\n\nGoal: create a visualisation of one to three variables in your summary data. To visualise this data we: load ggplot2\n\nlibrary(ggplot2)\n\nCreate a scatter plot of avg attendance vs med wait time\n\nggplot(data = Hosp_wait_time, \n       mapping= aes(x = avg_attendance,\n       y = median_wait_time)) +\n  geom_point()\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis showed us a large outlier so we removed this using the code below:\n\nfilter(Hosp_wait_time, Facility.HHS.Code != \"99999\")\n\n# A tibble: 104 × 4\n   Facility.HHS.Code avg_attendance median_wait_time No_non_wait\n               &lt;int&gt;          &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;\n 1                 1          4761.             40.2        22.6\n 2                 4         10404              50.8        25.1\n 3                11          5747.             55.2        34.8\n 4                15          6389.             46.5        27.1\n 5                16          6463.             52.5        26.1\n 6                22          5290.             66.2        27.5\n 7                28          4911.             66.6        22.6\n 8                29          8901              51.4        28.6\n 9                30          5328.             63          24.8\n10                32          7682.             68.1        26.7\n# ℹ 94 more rows\n\nsubset &lt;- Hosp_wait_time %&gt;% filter(Facility.HHS.Code !=\"99999\")\n\nWe Then reran the graph without the outlier and added lables and a trend line.\n\nggplot(data = subset, \n       mapping= aes(x = avg_attendance,\n                    y = median_wait_time)) +\n  geom_point()+\n  labs(title = \"Does Average Attendance Number Effect Median Wait Time?\",\n       x=\"Average Attendance\",\n       y=\"Median Wait Time\") +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWith the adjusted data we then also ran 2 more scatters with trend lines looking at other factors contributing to wait time and patients leaving without treatment.\n\nggplot(data = subset, \n       mapping= aes(x = median_wait_time,\n                    y = No_non_wait)) +\n  geom_point()+\n  labs(title = \"Does wait time influence Number of People Leaving without Treatment?\",\n       x=\"Median Wait Time\",\n       y=\"Number leaving without Treatment\") +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nggplot(data = subset, \n       mapping= aes(x = No_non_wait,\n                    y = avg_attendance)) +\n  geom_point()+\n  labs(title = \"Does Number Attending Hospital Influence Number of People Leaving without Treatment?\",\n       x=\"Number leaving without Treatment\",\n       y=\"Average Hospital Attendance Numbers\") +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nlooking at number of people that leave based on attendance numbers\nfirst filter out missing median_wait_time data, then created a linear model\n\nsubset &lt;- subset %&gt;%   \n  filter(median_wait_time !=\"Missing\")\nmain_model &lt;- lm(\"No_non_wait~avg_attendance\", subset)\n\nTook the coefficients of the intercept and slope\n\nb0 &lt;- main_model$coefficients[1] #intercept\nb1 &lt;- main_model$coefficients[2] #slope\n\nThen made linear regression line on scatter with labels.\n\nlibrary(ggplot2)\nggplot(subset,\n       aes(x=avg_attendance,\n           y=No_non_wait))+\n  geom_point()+\n  labs(title = \"Does Number Attending Hospital Influence Number of People Leaving without Treatment?\",\n       x=\"Average Hospital Attendance Numbers\",\n       y=\"Number leaving without Treatment\") +\n  geom_abline(intercept = b0, slope = b1)\n\n\n\n\n\n\n\n\nThen compared to Wait time to number of people leaving.\n\nmodel3 &lt;- lm(\"median_wait_time ~No_non_wait\", subset)\nb00 &lt;- model3$coefficients[1] #intercept\nb11 &lt;- model3$coefficients[2] #slope\nggplot(subset,\n       aes(x=No_non_wait,\n           y=median_wait_time))+\n  geom_point()+\n  labs(title = \"Does Number of People Leaving without Treatment Influence Median Wait Time?\",\n       x=\"Number leaving without Treatment\",\n       y=\"Median Wait Time\") +\n  geom_abline(intercept = b00, slope = b11)"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/Fuel sites.html",
    "href": "gallery/R/25Winter/Claudine & Emman/Fuel sites.html",
    "title": "QLD fuel",
    "section": "",
    "text": "fuel &lt;- read.csv(\"../../../../data/qld_fuel.csv\")\n\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/Fuel sites.html#import-data",
    "href": "gallery/R/25Winter/Claudine & Emman/Fuel sites.html#import-data",
    "title": "QLD fuel",
    "section": "",
    "text": "fuel &lt;- read.csv(\"../../../../data/qld_fuel.csv\")\n\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)"
  },
  {
    "objectID": "gallery/R/25Winter/Claudine & Emman/Fuel sites.html#fuel-sites",
    "href": "gallery/R/25Winter/Claudine & Emman/Fuel sites.html#fuel-sites",
    "title": "QLD fuel",
    "section": "Fuel Sites",
    "text": "Fuel Sites\nSee @weschke_nighttime_2024 for more details\n\nfuel %&gt;%  ggplot(aes(x = Site_Latitude, y = Site_Longitude)) + geom_jitter(aes(colour = Fuel_Type))\n\n\n\n\n\n\n\n\n@ferretti_ecological_2024"
  },
  {
    "objectID": "gallery/R/25Winter/Sandya & Buddhika/melb property.html",
    "href": "gallery/R/25Winter/Sandya & Buddhika/melb property.html",
    "title": "Mel Property",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "gallery/R/25Winter/Sandya & Buddhika/melb property.html#melbourne-housing-snapshot",
    "href": "gallery/R/25Winter/Sandya & Buddhika/melb property.html#melbourne-housing-snapshot",
    "title": "Mel Property",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "gallery/R/25Winter/Sandya & Buddhika/melb property.html#running-code",
    "href": "gallery/R/25Winter/Sandya & Buddhika/melb property.html#running-code",
    "title": "Mel Property",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\nmelb_data &lt;- read.csv(\"../../../../data/melb_data.csv\")\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\n\nhead(melb_data)\n\n  X     Suburb          Address Rooms Type   Price Method SellerG       Date\n1 1 Abbotsford     85 Turner St     2    h 1480000      S  Biggin 2016-12-03\n2 2 Abbotsford  25 Bloomburg St     2    h 1035000      S  Biggin 2016-02-04\n3 3 Abbotsford     5 Charles St     3    h 1465000     SP  Biggin 2017-03-04\n4 4 Abbotsford 40 Federation La     3    h  850000     PI  Biggin 2017-03-04\n5 5 Abbotsford      55a Park St     4    h 1600000     VB  Nelson 2016-06-04\n6 6 Abbotsford   129 Charles St     2    h  941000      S  Jellis 2016-05-07\n  Distance Postcode Bedroom2 Bathroom Car Landsize BuildingArea YearBuilt\n1      2.5     3067        2        1   1      202           NA        NA\n2      2.5     3067        2        1   0      156           79      1900\n3      2.5     3067        3        2   0      134          150      1900\n4      2.5     3067        3        2   1       94           NA        NA\n5      2.5     3067        3        1   2      120          142      2014\n6      2.5     3067        2        1   0      181           NA        NA\n  CouncilArea Lattitude Longtitude            Regionname Propertycount\n1       Yarra  -37.7996   144.9984 Northern Metropolitan          4019\n2       Yarra  -37.8079   144.9934 Northern Metropolitan          4019\n3       Yarra  -37.8093   144.9944 Northern Metropolitan          4019\n4       Yarra  -37.7969   144.9969 Northern Metropolitan          4019\n5       Yarra  -37.8072   144.9941 Northern Metropolitan          4019\n6       Yarra  -37.8041   144.9953 Northern Metropolitan          4019"
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html",
    "href": "gallery/R/25Winter/cathys project/report.html",
    "title": "My Report",
    "section": "",
    "text": "Investigating the books dataset within quarto"
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html#books-dataset-with-quarto",
    "href": "gallery/R/25Winter/cathys project/report.html#books-dataset-with-quarto",
    "title": "My Report",
    "section": "",
    "text": "Investigating the books dataset within quarto"
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html#loading-the-required-packages",
    "href": "gallery/R/25Winter/cathys project/report.html#loading-the-required-packages",
    "title": "My Report",
    "section": "Loading the required packages",
    "text": "Loading the required packages\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html#loading-the-packages",
    "href": "gallery/R/25Winter/cathys project/report.html#loading-the-packages",
    "title": "My Report",
    "section": "Loading the packages",
    "text": "Loading the packages\n\nbooks &lt;-  read.csv(\"../../../../data/books.csv\")"
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html#the-books-dataset-includes-the-following-fields",
    "href": "gallery/R/25Winter/cathys project/report.html#the-books-dataset-includes-the-following-fields",
    "title": "My Report",
    "section": "The books dataset includes the following fields",
    "text": "The books dataset includes the following fields\n\nnames(books)\n\n [1] \"X\"                  \"bookID\"             \"title\"             \n [4] \"authors\"            \"average_rating\"     \"isbn\"              \n [7] \"isbn13\"             \"language_code\"      \"num_pages\"         \n[10] \"ratings_count\"      \"text_reviews_count\" \"publication_date\"  \n[13] \"publisher\""
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html#this-graph-shows-the-the-volume-of-publications-by-language-code",
    "href": "gallery/R/25Winter/cathys project/report.html#this-graph-shows-the-the-volume-of-publications-by-language-code",
    "title": "My Report",
    "section": "This graph shows the the volume of publications by language code",
    "text": "This graph shows the the volume of publications by language code\n\nbooks |&gt; \n  ggplot(mapping = aes(x = language_code)) +\n  geom_bar()"
  },
  {
    "objectID": "gallery/R/25Winter/cathys project/report.html#due-to-the-large-number-of-english-language-books-we-will-create-a-data-subset-without-the-codes-eng-and-en-us.",
    "href": "gallery/R/25Winter/cathys project/report.html#due-to-the-large-number-of-english-language-books-we-will-create-a-data-subset-without-the-codes-eng-and-en-us.",
    "title": "My Report",
    "section": "Due to the large number of english language books, We will create a data subset without the codes ‘eng’ and ‘en-US’.",
    "text": "Due to the large number of english language books, We will create a data subset without the codes ‘eng’ and ‘en-US’.\n\nnon_english_books &lt;- filter(books,!language_code %in% c(\"en-US\",\"eng\"))\nnon_english_books |&gt; \n  ggplot(mapping = aes(x = language_code)) +\n  geom_bar()\n\n\n\n\n\n\n\n#| fig-cap: \"Number of Non-English Books Published\"\n\n\nggplot(data = non_english_books,\n       mapping = aes(x = num_pages,\n                     y = publisher)) +\n  geom_point()"
  },
  {
    "objectID": "gallery/R/26Summer/example_project/example_project.html",
    "href": "gallery/R/26Summer/example_project/example_project.html",
    "title": "Goalkeepers and their heights",
    "section": "",
    "text": "Set up code\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(plotly)\nlibrary(knitr)\n\nplayers_raw &lt;- read.csv(\"../../../../data/Players2024.csv\")"
  },
  {
    "objectID": "gallery/R/26Summer/example_project/example_project.html#a-glimpse-at-the-dataset",
    "href": "gallery/R/26Summer/example_project/example_project.html#a-glimpse-at-the-dataset",
    "title": "Goalkeepers and their heights",
    "section": "A glimpse at the dataset",
    "text": "A glimpse at the dataset\nWe’ll begin just by taking a glimpse at the dataset:\n\n\nShow code\nkable(head(players_raw))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\nJames Milner\n1986-01-04\n175\nMidfield\nEngland\n38\nBrighton and Hove Albion Football Club\n\n\nAnastasios Tsokanis\n1991-05-02\n176\nMidfield\nGreece\n33\nVolou Neos Podosferikos Syllogos\n\n\nJonas Hofmann\n1992-07-14\n176\nMidfield\nGermany\n32\nBayer 04 Leverkusen Fußball\n\n\nPepe Reina\n1982-08-31\n188\nGoalkeeper\nSpain\n42\nCalcio Como\n\n\nLionel Carole\n1991-04-12\n180\nDefender\nFrance\n33\nKayserispor Kulübü\n\n\nLudovic Butelle\n1983-04-03\n188\nGoalkeeper\nFrance\n41\nStade de Reims"
  },
  {
    "objectID": "gallery/R/26Summer/example_project/example_project.html#cleaning-the-data",
    "href": "gallery/R/26Summer/example_project/example_project.html#cleaning-the-data",
    "title": "Goalkeepers and their heights",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nThe data has a few issues, as the following plot shows:\n\n\nShow code\nggplot(players_raw, aes(x = positions, y = height_cm)) +\n  geom_boxplot() \n\n\n\n\n\n\n\n\n\nShow code\n#sns.catplot(df_raw, x = \"positions\", y = \"height_cm\")\n\n\nIt looks like some of the players’ positions and heights were recorded incorrectly. To clean, let’s remove the “Missing” positions and ensure that heights are reasonable:\n\n\nShow code\n# Remove missing position and ensure reasonable heights\nplayers &lt;- players_raw %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n\n\nTo confirm, let’s plot the outliers in a different colour\n\n\nShow code\n# Identify outliers\noutliers &lt;- anti_join(players_raw, players)\n\n# Plot\nggplot(players, aes(x = positions, y = height_cm)) +\n  geom_boxplot() + \n  geom_point(data = outliers, colour = \"red\")"
  },
  {
    "objectID": "gallery/R/26Summer/example_project/example_project.html#visualising-the-players-heights",
    "href": "gallery/R/26Summer/example_project/example_project.html#visualising-the-players-heights",
    "title": "Goalkeepers and their heights",
    "section": "Visualising the players’ heights",
    "text": "Visualising the players’ heights\nAfter cleaning the data we can now analyse the players’ heights to see if there’s differences between positions. Let’s make the boxplot without the outliers\n\n\nShow code\nggplot(players, aes(x = positions, y = height_cm)) +\n  geom_boxplot() +\n  labs(x = \"Position\", y = \"Height (cm)\") \n\n\n\n\n\n\n\n\n\nShow code\nggsave(\"tb.png\")\n\n\nIt looks like goalkeepers are taller than the rest!\nLet’s through the age variable into the mix, to see if players’ heights allow them to compete longer.\n\n\nShow code\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\n\nggplotly(p)\n\n\n\n\n\n\nIt doesn’t look like there’s a relationship between heights and ages, but clearly it affects their position!"
  },
  {
    "objectID": "gallery/R/26Summer/example_project/example_project.html#global-spread",
    "href": "gallery/R/26Summer/example_project/example_project.html#global-spread",
    "title": "Goalkeepers and their heights",
    "section": "Global spread",
    "text": "Global spread\nWe haven’t looked at the nationality column yet. Let’s draw up a map using plotly to see where the players come from.\n\n\nShow code\n# Change country names to match plotly reference\nplayers &lt;- players %&gt;% \n  mutate(nationality = case_match(nationality,\n                                  \"England\" ~ \"United Kingdom\",\n                                  \"Türkiye\" ~ \"Turkey\",\n                                  \"Cote d'Ivoire\" ~ \"Ivory Coast\",\n                                  \"Northern Ireland\" ~ \"United Kingdom\",\n                                  \"Wales\" ~ \"United Kingdom\",\n                                  .default = nationality))\n    \n# Make the country count\ncountries &lt;- players %&gt;%\n  group_by(nationality) %&gt;%\n  summarise(n = n())\n\n# Make the plot\ncountries %&gt;% \n  plot_ly(type = \"choropleth\", \n          locations = countries$nationality, \n          locationmode = \"country names\", \n          z = countries$n) %&gt;%\n  colorbar(title = \"# of Players\")"
  },
  {
    "objectID": "project/scaffold.html",
    "href": "project/scaffold.html",
    "title": "Getting started",
    "section": "",
    "text": "You’re welcome to dive in and work as you please, but if you’re feeling at a loss where to begin, follow the scaffold below. Don’t forget to start from our template and look at the examples:",
    "crumbs": [
      "The Project",
      "Getting started"
    ]
  },
  {
    "objectID": "project/scaffold.html#project-scaffold",
    "href": "project/scaffold.html#project-scaffold",
    "title": "Getting started",
    "section": "Project scaffold",
    "text": "Project scaffold\n\nStep 0: Pick a dataset\nWe have nine datasets for you to choose from. We recommend saving your data inside your project.\n\n\n\nDataset\nDescription\nSource\n\n\n\n\nWorld populations\nA summary of world populations and corresponding statistics\nData from a Tidy Tuesday post on 2014 CIA World Factbook data\n\n\nSoccer players\nA summary of approx. 6000 soccer players from 2024\nData from a Kaggle submission.\n\n\nCoffee survey\nA survey of blind coffee tasting results\nData from a Kaggle submission\n\n\nGapminder\nGDP and life expectancy data by country\nData from the Research Bazaar’s R novice tutorial, sourced from Gapminder.\n\n\nMelbourne housing data\nA collection of houses for sale in Melbourne.\nData from a Kaggle submission\n\n\nGoodreads books\nA summary of books on Goodreads.\nData from a Kaggle submission\n\n\nQueensland hospitals\nQueensland emergency department statistics.\nData from the Queensland Government’s Open Data Portal.\n\n\nQueensland fuel prices\nFuel prices by the pump in Queensland\nData from the Queensland Government’s Open Data Portal\n\n\nAeroplane bird strikes\nAeroplane bird strike incidents fron the 90s\nData from a Tidy Tuesday post sourced from an FAA database\n\n\n\nRemember, to work with data, we should import our useful packages and load the data in.\n\nRPython\n\n\nlibrary(dplyr)\ndataset &lt;- read.csv(\"path_to_data\")\n\n\nimport pandas as pd\ndf = pd.read_csv(\"data/...\")\n\n\n\n\n\nStep 1: Understand the data\nThe datasets are varied with respect to variable types and content. The first exercise you should complete is a overview of the data. Use the following techniques to do so.\nYour goal: identify which variables are discrete (categorical) and which are continuous.\n\nViewing the data structure\nUse the following functions to view your data and the underlying data types.\n\nRPython\n\n\nnames(dataset)\nstr(dataset)\nsummary(dataset)\n\n\ndf.columns\ndf.info()\ndf.describe()\n\n\n\n\n\nPicking out individual columns\nTo view the contents of particular columns, you can select them via indexing\n\nRPython\n\n\ndataset$column_name\nunique(dataset$column_name)\nsummary(dataset$column_name)\nYou can also apply other statistics to the column, like max(dataset$column_name).\n\n\ndf[\"column_name\"]\ndf[\"column_name\"].unique()\ndf[\"column_name\"].describe()\nYou can also apply other statistics to the column, like dataset[\"column_name\"].max().\n\n\n\n\n\n\nStep 2: Taking a subset\nThe datasets have lots of observations for lots of variables. To draw meaningful results, it’s often useful to take a subset of those.\nYour goal: filter by a condition or group by and aggregate over a particular variable\n\nFiltering\nRecall that filtering looks like indexing. If you only want to examine a certain subset of a variable, the following code will isolate that subset\n\nRPython\n\n\nsubset = dataset %&gt;% filter(condition)\nwhere condition depends on the columns. For example, country == \"Australia\".\n\n\n\n\n\n\nTipThe pipe\n\n\n\nWe’ve used the pipe operator %&gt;% here, which is equivalent to filter(datatset, condition).\n\n\n\n\nsubset = df[condition]\nwhere condition depends on the columns. For example, df[\"country\"] == \"Australia\".\n\n\n\n\n\nGrouping\nIf you want to aggregate over a particular variable you need to group by it. This answers questions like, what is the average \\(x\\) for every \\(y\\).\nIf you want to group by a column and, for each of its values, apply a statistic to all the others,\n\nRPython\n\n\n\naggregated &lt;- dataset %&gt;%\n  group_by(\"variable_to_group_by\") %&gt;%\n  summarise(summary_1 = ..., summary_2 = ..., ...)\nThe summarise function aggregates by applying some statistic to a particular column for every unique value in the grouping variable. For example, summarise(avg_pop = mean(population)) makes a column in the summary table for the average population of each unique value in \"variable_to_group_by\".\n\n\naggregated = df.groupby(\"column_to_group_by\").agg(\"statistic\")\nFor example, df.groupby(\"age\").agg(\"max\") will calculate the maximum value of every column for every unique age. If you only want to apply aggregation to some columns, we can pick them out,\naggregated = df.groupby(\"column_to_group_by\")[\"column_to_aggregate\"].agg(\"statistic\")\n\n\n\n\n\n\nTipKeeping the grouped variable\n\n\n\nBy default, df.groupby() makes the grouped column the row names (index). If you want to keep it as a normal column (e.g. for visualisations), you might want to use df.groupby(\"column\", as_index = False)....\n\n\n\n\n\n\n\n\nStep 3: Visualise the relationship between variables\nWith your summary dataset, you can now try to visualise your variables.\nYour goal: create a visualisation of one to three variables in your summary data.\nFirst, you need to import the appropriate visualisation module\n\nRPython\n\n\nlibrary(ggplot2)\n\n\nWe use\nimport seaborn as sns\nfor our simple plots and the examples below. You could also use\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n\n\nNext, you’ll need to identify the variables to visualise. If they’re both continuous, you could use a scatter or line plot\n\nRPython\n\n\nUsing ggplot, we then specify the data, the mappings and the graphical elements.\nggplot(data = ...,\n       mapping = aes(x = ..., y = ..., ...)) +\n  geom_...()\nUse different graphical elements for different type of variables. Below are a few (non-exhaustive!) options.\nIf they’re both continuous\n\ngeom_line()\ngeom_point() (scatter plot)\n\nIf one is categorical\n\ngeom_box()\ngeom_bar() (displays the count of each variable)\ngeom_col() (plots \\(x\\) against \\(y\\); only have one “number” for each categorical variable - it does not aggregate).\n\nFor distributions\n\ngeom_hist()\n\n\n\nUse different functions and kinds for different variable types. Below are a few (non-exhaustive!) options.\nIf they’re both continuous\nsns.relplot(data = ..., x = ..., y = ..., kind = ..., ...)\n\nkind = \"scatter\"\nkind = \"line\"\n\nIf one is categorical\nsns.catplot(data = ..., x = ..., y = ..., kind = ..., ...)\n\nkind = \"box\"\nkind = \"bar\"\n\nFor distributions\nsns.displot(data = ..., x = ..., kind = ..., ...)\n\nkind = \"hist\"\n\n\n\n\n\n\nStep 4: Looking ahead\nNow that you’ve performed your first analysis and visualisation of the dataset, use these results to inform your next analysis!\nBelow you’ll find some general tips which can help. They have dataset-specific tips too, so check them out. Otherwise, feel free to ask if you have any other questions.",
    "crumbs": [
      "The Project",
      "Getting started"
    ]
  },
  {
    "objectID": "project/tips.html",
    "href": "project/tips.html",
    "title": "Tips",
    "section": "",
    "text": "Here’s a few general tips. In addition, we strongly recommend using the pandas cheatsheets, which give a quick and easy reference for common packages and functions, and from Data to Viz, which guides you through choosing a visualisation.",
    "crumbs": [
      "The Project",
      "Tips"
    ]
  },
  {
    "objectID": "project/tips.html#hotkeys",
    "href": "project/tips.html#hotkeys",
    "title": "Tips",
    "section": "Hotkeys",
    "text": "Hotkeys\n\nRPython\n\n\n\n\n\n\n\n\n\n\nCode\nHotkey\nDescription\n\n\n\n\n\nCtrl+Enter\nRun current line (when in Script)\n\n\n&lt;-\nAlt+Enter\nAssignment\n\n\n%&gt;%\nCtrl+Shift+M\nPipe\n\n\n\nEsc\nCancel current operation (when in Console)\n\n\n\nF1\nHelp documentation for selected function\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nHotkey\nDescription\n\n\n\n\n\nF9 (or Fn + F9)\nRun current line\n\n\n# %%\nCtrl + 2\nNew cell (only in Spyder)\n\n\n\nCtrl+Enter\nRun current cell (when in Script)\n\n\n\nCtrl+C\nCancel current operation (when in Console)",
    "crumbs": [
      "The Project",
      "Tips"
    ]
  },
  {
    "objectID": "project/tips.html#data-manipulation",
    "href": "project/tips.html#data-manipulation",
    "title": "Tips",
    "section": "Data manipulation",
    "text": "Data manipulation\nImport packages to make data manipulation easier\n\nRPython\n\n\nlibrary(dplyr)\n\n\nimport pandas as pd\n\n\n\n\nImporting and exporting data\nRead your data with an I/O (input/output) function.\n\nRPython\n\n\ndataset &lt;- read.csv(\"data/dataset.csv\")\n\n\ndf = pd.read_csv(\"data/dataset.csv\")\n\n\n\nYou can also export your data to a csv file.\n\nRPython\n\n\nwrite.csv(dataset, \"data/output_name.csv\")\n\n\ndf.to_csv(\"data/output_name.csv\")\n\n\n\n\n\nInitial exploration\nYou’ll want to explore the data to start with - below are a few functions to get started.\n\nRPython\n\n\n\n\n\n\n\n\n\n\nFunction\nExample\nDescription\n\n\n\n\nnames()\nnames(dataset)\nReturns the variable names\n\n\nstr()\nstr(dataset)\nReturns the structure of the dataset (variable names, types and first entries)\n\n\n$\ndataset$variable\nReturns a specific variable\n\n\nunique()\nunique(dataset$variable)\nReturns the unique values of a variable\n\n\nsummary()\nsummary(dataset$variable)\nReturns a statistical summary of a variable\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nExample\nDescription\n\n\n\n\ndf.columns\n\nReturns the variable names\n\n\ndf.info()\n\nReturns the structure of the dataset (variable names, counts and types)\n\n\ndf[\"variable\"]\n\nReturns a specific column\n\n\ndf[\"variable\"].unique()\n\nReturns the unique values of a variable\n\n\ndf.describe() or df[\"variable\"].describe()\nReturns a statistical summary of the dataset or a variable\n\n\n\n\n\n\n\n\n\nRemoving nans\nWe can remove nans by filtering\n\nRPython\n\n\ndataset &lt;- dataset %&gt;%\n  filter(!is.na(variable_to_check_for_NAs))\n\n\n\n\n\n\nNoteUsing ! for negation\n\n\n\nWe use the exclamation mark ! to negate the result, because is.na returns all the rows that are NA.\n\n\n\n\ndf = df[df[\"variable\"].notna()]\n\n\n\n\n\nTime series data\nIf you’ve picked a dataset with time-series data (e.g. a “date” variable), you should transform that variable so that it visualises better:\n\nRPython\n\n\ndataset$variable &lt;- as.Date(dataset$variable)\n\n\ndf[\"variable\"] = pd.to_datetime(df[\"variable\"])\n\n\n\n\n\nCategorical and ordered data\nIf you’re dealing with categorical data, you can specify this explicitly to keep track of the levels.\n\nRPython\n\n\ndataset$variable &lt;- factor(dataset$variable)\n\n\ndf[\"variable\"] = df[\"variable\"].astype(\"category\")\n\n\n\nTo manually specify the order of categories,\n\nRPython\n\n\nSpecify the order by sending in an ordered list of the levels joined with c():\ndataset$variable &lt;- factor(dataset$variable, levels = c(\"first_val\", \"second_val\", ... ))\nAlternatively, if you only need to specify the first (reference) level, use\ndataset$variable &lt;- relevel(factor(dataset$variable), ref = \"reference_level\")\n\n\nUse the df[\"variable\"].cat.reorder_categories() function and use the ordered = True parameter,\ndf[\"variable\"] = df[\"variable\"].cat.reorder_categories([\"cat1\", \"cat2\", ...], ordered = True)\nIf you’re dealing with categorical data, look at the pandas guide for inspiration and help.\n\n\n\n\n\n\n\n\n\nTipCoffee survey\n\n\n\nThis is particularly useful for the Coffee survey dataset.\n\n\n\n\nRenaming variables\nSome datasets have cumbersome names for their variables which we can rename.\n\nRPython\n\n\ndf &lt;- df %&gt;% \n  rename(new_name = old_name)\n\n\nUse df.rename(), sending a dictionary to the columns = parameter:\ndf = df.rename(columns = {\"old_name\": \"new_name\"})\n\n\n\n\n\n\nNoteDictionaries\n\n\n\nA dictionary is a Python variable with key-value pairs. The structure is key: value, so above we have a dictionary with one key, \"old_name\" and corresponding value \"new_name\". They are created as follows:\n\nexample_dictionary = {\"key1\": \"value1\",\n                      \"key2\": \"value2\",\n                      \"key3\": \"value3\",\n                      ...}\n\nNote that multiple lines are used purely for readability, you could just as well do this on one line.\n\n\n\n\n\n\n\n\n\n\n\nTipWorld population\n\n\n\nThis is particularly useful for the World population dataset.",
    "crumbs": [
      "The Project",
      "Tips"
    ]
  },
  {
    "objectID": "project/tips.html#visualisation",
    "href": "project/tips.html#visualisation",
    "title": "Tips",
    "section": "Visualisation",
    "text": "Visualisation\nWe can make simple visualisations of our data.\n\nRPython\n\n\nUse ggplot2’s ggplot() function, with\n\ndata = the dataset\nmapping = the variables, provideed as an aes(...) object\ngeom_... the geometries, e.g. geom_line(), geom_point() etc.\n\nlibrary(ggplot2)\n\nggplot(data = dataset,\n       mapping = aes(x = ..., y = ..., colour = ..., ...)) +\n  geom_first_layer() + \n  geom_second_layer() + \n  ...\nTake a look at the ggplot2 documentation for more information.\nPlotly workaround\nIf you’re having issues using ggplotly (it’s producing a blank plot), you can use this workaround to view it in your browser.\nplot &lt;- ggplotly(saved_ggplot_image)\nhtmlwidgets::saveWidget(as_widget(plot), \"plots/name_of_plot.html\")\nOpening that file will show you the image.\n\n\nUse seaborn’s relplot(), catplot() and displot() functions. For example,\nimport seaborn as sns\n\nsns.relplot(data = df, x = \"variable_x\", y = \"variable_y\", hue = \"variable_colour\", ...)\n\n\n\nWe can add additional customisations to our plots, such as axis labels.\n\nRPython\n\n\nGenerally, ggplot2 lets you do this with additional elements added to the plot. For example, to add axis labels,\nggplot(data = dataset,\n       mapping = aes(x = ..., y = ..., colour = ..., ...)) +\n  geom_first_layer() + \n  geom_second_layer() + \n  labs(title = ..., var1 = ...)\n\n\nThe simplest way to do this in Python is to use the matplotlib.pyplot module’s functions. Generally, this has the format plt.&lt;some_customisation&gt;. For example, to add axis labels,\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.relplot(data = df, x = \"variable_x\", y = \"variable_y\", hue = \"variable_colour\", ...)\nplt.xlabel(\"x axis label\")\nplt.ylabel(\"y axis label\")",
    "crumbs": [
      "The Project",
      "Tips"
    ]
  },
  {
    "objectID": "python/Advanced topics/6 - Programming.html",
    "href": "python/Advanced topics/6 - Programming.html",
    "title": "Programming Essentials",
    "section": "",
    "text": "In this workshop we cover the building blocks for developing more complex code, looking at",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "python/Advanced topics/6 - Programming.html#looking-under-the-hood-what-makes-ints-ints",
    "href": "python/Advanced topics/6 - Programming.html#looking-under-the-hood-what-makes-ints-ints",
    "title": "Programming Essentials",
    "section": "Looking under the hood: what makes ints ints?",
    "text": "Looking under the hood: what makes ints ints?\nPython is a high level programming language. Its features are often inspired by C and C++, and is itself built in C/C++.\nOne of the major innovations of C++, and object-oriented programming in general, are classes. We won’t go over how to write your own - it’s beyond the scope of this workshop - but they’re worth a conceptual understanding.\nEssentially, all Python variables follow a specific template, known as its class or type. It’s safe to use these interchangebly here. The class is a general template for the variable and it defines what methods (functions) and attributes (variables) live inside the variable.\nInside the variable? Where? Well, a variables contain more than just their value. We use the . operator to access anything besides the value that lives in the variable. For example, all strings have a function called .upper() that makes them uppercase:\n\nrandom_string = \"Hello, this is a sentence.\"\nprint(random_string.upper())\n\nHELLO, THIS IS A SENTENCE.\n\n\nLet me emphasise that all strings have .upper(). That makes upper() a method of strings.\nIn other words, a class is like an empty form that needs filling. The form string has a field called upper() that is filled with the function as defined above.",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "python/Advanced topics/6 - Programming.html#directing-traffic-with-conditionals",
    "href": "python/Advanced topics/6 - Programming.html#directing-traffic-with-conditionals",
    "title": "Programming Essentials",
    "section": "Directing traffic with conditionals",
    "text": "Directing traffic with conditionals\nIn the first half of this session we’ll look at two types of control flows: conditionals and loops.\nConditionals allow you to put “gates” in your code, only running sections if a certain condition is true. They are common to most programming languages.\nIn Python, they are called if statements, because you use the if command. For example,\n\nif 5 &gt; 0:\n    print(\"We're inside the if statement\")\n\nWe're inside the if statement\n\n\nThe line print(\"We're inside the if statement\") will only run if 5 &gt; 0 is true. If not, it’ll get skipped.\nIndents are essential. Only indented code will be governed by conditional\n\nif 5 &gt; 0:\n    print(\"We're inside the if statement\")\n\nprint(\"This code always runs\")\n\nWe're inside the if statement\nThis code always runs\n\n\nWatch what happens if we change the condition\n\nif 5 &gt; 10:\n    print(\"We're inside the if statement\")\n\nprint(\"This code always runs\")\n\nThis code always runs\n\n\nNow, the first line doesn’t run. That’s the essence of a conditional.\nThere’s not much point to using a condition that will always be true. Typically, you’d use a variable in the condition, for example.\n\npet_age = 10\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\n\n\nLogical operators\nHere is a table of the different operators you can make conditions with. When you run them, they always return either True or False.\n\n\n\n\n\n\n\n\nOperator\nTrue example\nDescription\n\n\n\n\n==\n10 == 10\nSame value and type\n\n\n!=\n\"10\" != 10\nDifferent value or type\n\n\n&gt;\n10 &gt; 5\nGreater than\n\n\n&gt;=\n10 &gt;= 10\nGreater than or equal to\n\n\n&lt;\n5 &lt; 10\nLess than\n\n\n&lt;=\n5 &lt;= 10\nLess than or equal to\n\n\nin\n\"a\" in \"apple\"\nFirst object exists in the second\n\n\nnot in\n\"b\" not in \"apple\"\nFirst object does not exist in the second\n\n\nand\n10 == 10 and \"a\" in \"apple\"\nOnly true if both conditions are true. Same as &\n\n\nor\n10 == 10 or \"b\" in \"apple\"\nAlways true if one condition is true. Same as \\|\n\n\n\n\n\nelif and else\nif statements only run if the condition is True. What happens if its False? That’s what the else command is for, it’s like a net that catches anything that slipped past if:\n\npet_age = 5\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\nelse:\n    print(\"My pet is 10 or younger\")\n\nMy pet is 10 or younger\n\n\n\nDon’t forget the colon :!\n\nCheck what happens when you change the age from 5 to 15.\nFinally, what if you wanted to check another condition only if the first one fails? That’s what elif (else-if) is for. It’s another if statement but it only runs if the first fails.\n\npet_age = 5\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\nelif pet_age &lt; 5:\n    print(\"My pet is younger than 5\")\nelse:\n    print(\"My pet is between 5 and 10\")\n\nMy pet is between 5 and 10\n\n\nYou can include as many as you’d like\n\npet_age = 5\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\nelif pet_age &lt; 5:\n    print(\"My pet is younger than 5\")\nelif pet_age &lt; 1:\n    print(\"My pet is freshly born\")\nelse:\n    print(\"My pet is between 5 and 10\")\n\nMy pet is between 5 and 10",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "python/Advanced topics/6 - Programming.html#repeat-after-me",
    "href": "python/Advanced topics/6 - Programming.html#repeat-after-me",
    "title": "Programming Essentials",
    "section": "Repeat after me",
    "text": "Repeat after me\nSometimes you need to repeat a task multiple times. Sometimes hundreds. Maybe you need to loop through 1 million pieces of data. Not fun.\nPython’s loops offer us a way to run a section of code multiple times. There are two types: for loops, which run the code once for each element in a sequence (like a list or string), and while loops, which run until some condition is false.\n\nwhile loops\nThese are almost the same as if statements, except for the fact that they run the code multiple times. Let’s begin with a basic conditional\n\nnumber = 5\n\nif number &lt; 10:\n    print(str(number) + \" is less than 10.\")\n\n5 is less than 10.\n\n\n\nUsing str(number) turns the number into a string, which lets us combine it with ” is less than 10.”\n\nThe print statement runs once if the condition is true.\nWhat if we wanted to check all the numbers between 5 and 10? We can use a while loop.\n\nnumber = 5\n\nwhile number &lt; 10:\n    print(str(number) + \" is less than 10.\")\n    number = number + 1\n\n5 is less than 10.\n6 is less than 10.\n7 is less than 10.\n8 is less than 10.\n9 is less than 10.\n\n\nWe’ve done two things\n\nReplace if with while\nIntroduce number = number + 1 to increase the number each time.\n\n\nWithout step 2, we’d have an infinite loop – one that never stops, because the condition would always be true!\n\nWhile loops are useful for repeating code an indeterminate number of times.\n\n\nfor loops\nRealistically, you’re most likely to use a for loop. They’re inherently safer (you can’t have an infinite loop) and often handier.\nIn Python, for loops iterate through a sequence, like the objects in a list. This is more like other languages’ foreach, than most’s for.\nLet’s say you have a list of different fruit\n\nlist_of_fruits = [\"apple\", \"banana\", \"cherry\"]\n\nand you want to run a section of code on \"apple\", then \"banana\", then \"cherry\". Maybe you want to know which ones have the letter “a”. We can start with a for loop\n\nlist_of_fruits = [\"apple\", \"banana\", \"cherry\"]\n\nfor fruit in list_of_fruits:\n    print(fruit)\n\napple\nbanana\ncherry\n\n\nThis loop’s job is to print out the variable fruit. But where is fruit defined? Well, the for loop runs print(fruit) for every element of list_of_fruits, storing the current element in the variable fruit. If we were to write it out explicitly, it would look like\n\nfruit = list_of_fruits[0]\nprint(fruit)\n\nfruit = list_of_fruits[1]\nprint(fruit)\n\nfruit = list_of_fruits[2]\nprint(fruit)\n\napple\nbanana\ncherry\n\n\nLet’s return to our goal: working out which ones have an “a”. We need to put a conditional inside the loop:\n\nlist_of_fruits = [\"apple\", \"banana\", \"cherry\"]\n\nfor fruit in list_of_fruits:\n    if \"a\" in fruit:\n        print(\"a is in \" + fruit)\n    else:\n        print(\"a is not in \" + fruit)\n\na is in apple\na is in banana\na is not in cherry\n\n\n\n\nUsing range\nThere’s a special Python object which is useful for loops, the range. This object ‘contains’ all the numbers between a certain range. For example,\n\nrange(0,5)\n\nrange(0, 5)\n\n\ncover the numbers \\(0-4\\), and is somewhat equivalent to [0,1,2,3,4] (for looping purposes). Of course, we can choose a much bigger number:\n\nfor i in range(0,1000):\n    print(i)\n\nwill print every number between \\(0\\) and \\(1000\\). This can be useful if you need to loop through multiple objects by indexing.",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "python/Advanced topics/6 - Programming.html#building-your-own-machines",
    "href": "python/Advanced topics/6 - Programming.html#building-your-own-machines",
    "title": "Programming Essentials",
    "section": "Building your own machines",
    "text": "Building your own machines\nWe’ll wrap this session up by looking at custom functions and modules. So far, we’ve only used built-in functions or those from other people’s modules. But we can make our own!\nWe’ve only ever called functions - this is what we do when we use them. All functions need a definition, this is the code that gets run when they’re called.\n\nThe function definition\nFunctions are machines. They take some inputs, run some code with those inputs, and spit out one output. We need to define how they work before we use them. We should specify\n\nA name\nSome inputs\nThe code to run (the machine itself)\nAn output\n\nWe include these in three steps\n\nThe first line of the function definition (the function signature) specifies the name and inputs\nWe then indent all the code we want to run with our inputs\nWe end with a return statement, specifying the output\n\n\ndef insert_function_name_here(input_1_name, input_2_name, ...):\n    # Code code code\n    return output\n\nFor example, let’s create a function that converts centimetres to metres.\n\ndef cm_to_m(value_in_cm):\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\nTaking it apart, we have\n\nName: cm_to_m\nInputs (just one): value_in_cm\nCode (just one line): value_in_m = value_in_cm / 100\nOutput: value_in_m\n\nImportantly, nothing happens when you run this code. Why? Because you’ve only defined the function, you haven’t used it yet.\nTo use this function, we need to call it. Let’s convert \\(10\\text{ cm}\\) to \\(\\text{m}\\).\n\ndef cm_to_m(value_in_cm):\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\ncm_to_m(10)\n\n0.1\n\n\nWhen we call the function, it runs with value_in_cm = 10.\nThat’s it! Every function that you use, built-in or imported, looks like this.\nBecause functions must be defined before called, and defining them produces no output, best practice is to place functions at the top of your script, below the import statements.\n\n\nDocstrings\nSomething you’ll spot on all professional functions are docstrings. This is what Python spits out with the help() function. You can make your own by writing it within triple quotes immediately after the signature ''' ''':\n\ndef cm_to_m(value_in_cm):\n    \"\"\"Converts centimetres to metres\"\"\"\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\ncm_to_m(10)\n\n0.1\n\n\nThat said, the best way to ensure clarity is to use a clear name.\n\n\nCreating modules\nWhat if you need to write lots of functions? We could write unit converters like above for hundreds of possibilities.\nIt’s useful to tuck these away in their own file, so they don’t clog up your main.py.\nLet’s make a new file called conversions.py, and move your function into it. Delete it from your current file.\nThen, to make sure it works, let’s make a new converter too, from centimetres to inches. Your conversions.py file should look like:\n\ndef cm_to_m(value_in_cm):\n    \"\"\"Converts centimetres to metres\"\"\"\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\ndef cm_to_in(value_in_cm):\n    \"\"\"Converts centimetres to inches\"\"\"\n    value_in_inches = value_in_cm / 2.54\n    return value_in_inches\n\nLet’s make another script now called main.py. We’ll run our conversions here by pulling in the functions from conversions.py.\nInside main.py, you’ll need to import conversions.py. To access the functions, you’ll need to use . to look inside the module as usual:\n\nimport conversions\nmetres = conversions.cm_to_m(10)\ninches = conversions.cm_to_in(10)\n\nprint(\"10cm is \" + metres + \"m\")\nprint(\"10cm is \" + inches + \"\\\"\")\n\n\nTo include a double quote ” inside a string made of double quotes, escape it with a backslash: \\\".\n\nCongratulations, you’ve made your first module!",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "python/Essentials/4 - Sharing and Publishing.html",
    "href": "python/Essentials/4 - Sharing and Publishing.html",
    "title": "Sharing and Publishing",
    "section": "",
    "text": "In this workshop we cover using GitHub for sharing your source code, Git for version control, and Quarto for publishing outputs. Specifically, we look at:",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "python/Essentials/4 - Sharing and Publishing.html#quarto",
    "href": "python/Essentials/4 - Sharing and Publishing.html#quarto",
    "title": "Sharing and Publishing",
    "section": "Quarto",
    "text": "Quarto\nQuarto is a publishing system that allows creating documents, presentations, websites and dashboards that contain prose, code and code outputs. This means that such outputs can detail exactly what happened to the data, and outputs can be re-generated very quickly if, for example, the underlying dataset was updated, or if the analysis needs to change.\n\nInstalling Quarto\nThe simplest way to install Quarto is with Anaconda.\n\nOpen an “Anaconda prompt” from the navigator\nRun conda install conda-forge::quarto\nWhen prompted with Continue? ([y]/n), type y and press enter\nRestart the Spyder kernel and type\n\n!quarto version\nIf you get a number, then it’s worked!\nAlternatively, follow the instructions to install Quarto on your computer. Quarto is a command line tool available for all major operating systems.\n\n\n\n\n\n\nNote\n\n\n\nWe can write Quarto files in Spyder, but there is (at the time of writing) no integration of it into the Spyder interface. Other IDEs make it easier to interact with Quarto functions and write Quarto files, like R Studio.\n\n\nIf the IPython console can’t find Quarto, try to run quarto version (without the !) in a command line interface outside Spyder (bash, macOS’s Terminal, PowerShell…). You will have to use the tool that finds Quarto to run Quarto commands later.\n\n\nCreate a Quarto file\nLet’s try to create a document based on the visualisations we created earlier. First, create a new script. Then, save it as “document.qmd” - be sure to change the extension!\n\n\n\n\n\n\nWarning\n\n\n\nWhen rendering individual Quarto files, paths to files (like the one you use to import some data) will be understood as relative to the file itself. This means that, to avoid confusion, it is best to save your Quarto file at the top of your project directory, so you can use the same relative paths as in the rest of your scripts.\n\n\nThis new .qmd script is a Quarto Markdown file. Markdown is a formatting language which we’ll go through shortly.\nAt the top of our script, we need to include a header which contains the document settings\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\n---\n\nThe language used for the header is actually YAML (yet another markup language).\n\nThe remainder of the document uses the Markdown language, interspersed by Python chunks. Markdown works by using symbols to indicate formatting. For example, headings use hashtags # and bold text uses asterisks * *:\n# Markdown example\n\nThis contains **bold** and *italicised* text. You can also ~~strikethrough~~, create\n\n## Subheading\n\n- unordered \n- lists\n\nand \n\n1. ordered\n2. lists\n    1. with\n    2. levels\n\n\n\n\n\n\nNoteMarkdown example\n\n\n\n\n\nThis contains bold and italicised text. You can also strikethrough, create\n\nSubheading\n\nunordered\nlists\n\nand\n\nordered\nlists\n\nwith\nlevels\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nSee more Markdown hints in the Quarto documentation.\n\n\nLet’s make a simple markdown file and render it with quarto. In your file, write a simple document like the following:\n# Quarto document workshop\n\nThis is a simple Quarto markdown file, which will render **formatted text**!\nThen, then in your Spyder terminal, render the document to produce an HTML output:\n!quarto render document.qmd\n\nTroubleshooting\nYou may encounter a few issues which can be fixed:\n\n\n\n\n\n\nWarningERROR: No valid input files passed to render\n\n\n\n\n\nEither you’ve misspelt the filename, you’ve put he file in a folder, or the working directory is wrong. Once you’ve checked the spelling,\nIf document.qmd is in a folder\nSpecify the filepath, not just the filename:\n!quarto render folder_name/document.qmd\nIf the working directory is wrong\nMake sure you’re in the Spyder project for intensives. You can check this by opening Spyder’s “files” pane (above the console) to see where your working directory is.\nIf you need to change it, the easiest way is to open the Spyder project you created in a previous workshop.\nIf this doesn’t work, or you want to be somewhere else, you can either create a new project or change your working directory manually with the file button in the top right.\n\n\n\n\n\n\n\n\n\nWarningModuleNotFoundError: No module named '...'\n\n\n\n\n\nYou’re trying to import a module that Python can’t find. This is a Python problem, not a Quarto problem. Check the erroneous line, which will start with\nimport some_module\nand check that you’ve spelt the module correctly. If it’s still broken, then you need to install the package (you don’t have it on your computer).\nInstalling modules for Anaconda users\nIf you installed the Anaconda distribution to set up Spyder (and you haven’t manually changed environments - you’d know if you did), then use the following command to install the module\nconda install some_module\nInstalling modules with pip\nIf you aren’t using Anaconda then you can use the pip package to install the module. You can do so with\npip install some_module\n\n\n\n\n\n\n\n\n\nWarningNameError: name 'quarto' is not defined\n\n\n\n\n\nYou’ve probably forgotten the exclamation mark: make sure to use it if you’re in Spyder\n!quarto render document.qmd\n\n\n\n\n\n\n\n\n\nWarning`error: incomplete escape t position 28\n\n\n\n\n\nYou’ve probably forgotten the exclamation mark: make sure to use it if you’re in Spyder\n!quarto render document.qmd\n\n\n\n\n\n\n\n\n\nWarningSyntaxError: invalid syntax\n\n\n\n\n\nTry running\n!quarto help\nIf this returns a list of commands\nThen something’s wrong with your render command. Double check it’s the same as here, and make sure nothing else is on the line.\nIf this returns the same error\nThen you won’t be able to use Spyder, and will need to use a command prompt instead. See the note Not using Spyder below.\n\n\n\n\n\n\n\n\n\nWarning'quarto' is not recognized as an internal or external command... or quarto: command not found etc.\n\n\n\n\n\nSomething’s wrong with your Quarto installation. Check that you’ve installed it correctly and ask for help from a trainer.\n\n\n\n\n\n\n\n\n\nWarningMissing Python kernel\n\n\n\n\n\nYou might have to install jupyter. See options for different package managers in the Quarto documentation about Python. If you’re running into this issue and using Anaconda, please ask for assistance.\n\n\n\n\n\n\n\n\n\nWarningNothing is happening\n\n\n\n\n\nSometimes Quarto is a bit slow, particularly if you’ve got a lot to render. If you’ve waited for over one minute, and there’s a red square in the console’s top right, then ask a trainer for help. To troubleshoot, you can try the following steps:\n\nCancel the operation (press the red square)\nRun !quarto help. This should be quick - if it’s not, then you might need to use a terminal, see the Not using Spyder note below.\n\n\n\n\n\n\n\n\n\n\nNoteNot using Spyder\n\n\n\n\n\nIf you’re using a different IDE, you might not be able to use !quarto ....\nIf you’re using Jupyter notebooks\nThen you probably can. Try running\n!quarto render document.qmd\nand seeing if an error arises.\nIf you’re using an alternative or have encountered issues within Spyder\nYou’ll need to use a command prompt to run the Quarto commands. Give it a go yourself, and then ask a trainer for assistance if you’re having trouble.\n\nOpen a command prompt / shell on your device.\nNavigate to your project folder with the command cd to change directories:\n\ncd path/to/your/project/\nYou can find the path inside Spyder - it’s the address in the top right.\n\nUse the render command without the exclamation mark:\n\nquarto render document.qmd\n\n\n\nOnce it’s finished, you should see a new file in your project folder: “document.html”. Open it in your browser.\n\n\n\n\n\n\nTip\n\n\n\nRight click on the file and press “Open externally” within Spyder.\n\n\n\n\n\nIncluding Python\nWe can include Python chunks for quarto to execute before rendering our file. Returning to the .qmd file, we fence code chunks with backticks\n```{python}\nprint(\"This code will be executed\")\n```\nPlacing this chunk into our file and then rendering again with !quarto render document.qmd, you should see the code block and its output in the document, like this\n\nprint(\"This code will be executed\")\n\nThis code will be executed\n\n\n\n\nBuilding an example report\nWe’ll now look to using Python and markdown to develop a report with Quarto. Let’s start by bringing in some of the work we did yesterday.\nWe’ll start with set up message and import the packages and data:\n## Import the data\n\nLet's import the packages and data\n\n```{python}\nimport pandas as pd\nimport seaborn as sns\n\ndf = pd.read_csv(\"../../data/Players2024.csv\")\n```\nWe can then follow by plotting it the data\n## Plot the data\n\nLet's generate that **swarm plot** again:\n\n```{python}\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\")\n```\n\nWe now have a plot!\n\n\nCell options\nAs the default Quarto output is a HTML file, we can include interactive visualisations too.\nLet’s say we also want to let our readers know that they need to install Plotly in order to create interactive visualisations. If you want to show the corresponding code in your document but don’t want to run it, you can add the cell option #| eval: false. (And if you want to show the output but not show the underlying code, use #| echo: false.)\n## Interactive plots\n\nYou will need the plotly module:\n\n```{python}\n#| eval: false\nconda install plotly\n```\n\nAn interactive plot:\n\n```{python}\n#| echo: false\nimport plotly.express as px\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\")\n```\nAnd for adding a caption and alternative text to a figure:\n```{python}\n#| fig-cap: \"Goalkeepers tend to be taller.\"\n#| fig-alt: \"A scatterplot of the relationsip between height and position.\"\nimport seaborn as sns\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\")\n```\nMany more cell options exist, including captioning and formatting visualisations. Note that these options can be used at the cell level as well as globally (by modifying the front matter at the top of the document).\nFor example, to make sure error and warning messages are never shown:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nwarning: false\nerror: false\n---\n\n\nOutput formats\nThe default output format in Quarto is HTML, which is by far the most flexible. However, Quarto is a very versatile publishing system and can generate many different output formats, including PDF, DOCX and ODT, slide formats, Markdown suited for GitHub… and even whole blogs, books and dashboards.\nLet’s try rendering a PDF by including the format: pdf option at the top of the file:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nformat: pdf\n---\nWhen rendering PDFs, the first issue we might run into is the lack of a LaTeX distribution. If Quarto didn’t detect one, it will suggest to install tinytex (a minimal LaTeX distribution) with:\n!quarto install tinytex\nOnce that is installed, Quarto should render a PDF.\nAnother issue with our example document is that an interactive HTML visualisation won’t be renderd in the PDF. You can supress it by using the #| eval: false option:\n```{python}\n#| eval: false\nimport plotly.express as px\npx.scatter(data_frame = df, x = \"age\", y = \"height_cm\")\n```",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "python/Essentials/4 - Sharing and Publishing.html#subheading",
    "href": "python/Essentials/4 - Sharing and Publishing.html#subheading",
    "title": "Sharing and Publishing",
    "section": "Subheading",
    "text": "Subheading\n\nunordered\nlists\n\nand\n\nordered\nlists\n\nwith\nlevels",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "python/Essentials/4 - Sharing and Publishing.html#git-and-github",
    "href": "python/Essentials/4 - Sharing and Publishing.html#git-and-github",
    "title": "Sharing and Publishing",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nGit is a version control system that allows to record a clean history of your project, track precise authorship, and collaborate asynchronously with others. It can be used offline, from the command line or with integration into Integrated Desktop Environments (like RStudio, VS Code… Unfortunately, Spyder does not have Git integration).\nGitHub is one of many websites that allow you to host project that are tracked with Git. But even without using Git at all, it is possible to use GitHub to share and make your project public. Many researchers use it to make their code public alongside a published paper, to increase reproducibility and transparency. It can also be useful to build and share a portfolio of your work.\nLearning about the ins and out of Git takes time, so in this section we will mainly use GitHub as a place to upload and share your code and outputs, and as a starting point for learning more about Git in the future.\n\nGitHub\nGitHub is currently the most popular place for hosting, sharing and collaborating on code. You can create an account for free, and then create a repository for your project.\n\nCreate an account and log in\nClick on the “+” button (top right of the page)\nSelect “New repository”\nChoose a name and description for your repository\nTick “Add a README file” - this will be where you introduce your project\nClick “Create repository”\n\nFrom there, you can upload your files, and edit text-based files straight from your web browser if you need to.\nThe README file is a markdown file that can contain the most important information about your project. It’s important to populate it as it is the first document most people see. It could contain:\n\nName and description of the project\nHow to use it (installation process if any, examples…)\nWho is the author, who maintains it\nHow to contribute\n\nFor inspiration, see the pandas README file.\nTo practice managing a git repository on GitHub, try creating a personal portfolio repository where you can showcase what you have worked on and the outputs your are most proud of.",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "python/Essentials/4 - Sharing and Publishing.html#further-resources",
    "href": "python/Essentials/4 - Sharing and Publishing.html#further-resources",
    "title": "Sharing and Publishing",
    "section": "Further resources",
    "text": "Further resources\n\nSome alternatives to GitHub: Codeberg and Gitlab\nQuarto documentation\nCourse on Git from the command line\nCourse on Git with GitHub\nHow to use GitHub Pages to publish Quarto outputs",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html",
    "href": "python/Essentials/1 - Fundamentals.html",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this first workshop we will cover",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#introducing-python-and-spyder",
    "href": "python/Essentials/1 - Fundamentals.html#introducing-python-and-spyder",
    "title": "The Fundamentals",
    "section": "Introducing Python and Spyder",
    "text": "Introducing Python and Spyder\nPython is a programming language that can be used to build programs (i.e. a “general programming language”), but it can also be used to analyse data by importing a number of useful modules.\nWe are using Spyder to interact with Python more comfortably. If you have used RStudio to interact with R before, you should feel right at home: Spyder is a program designed for doing data science with Python.\nPython can be used interactively in a console, or we can build scripts and programs with it, making the most out of Spyder’s code editor.\nWe will start by using the console to work interactively. This is our direct line to the computer, and is the simplest way to run code. Don’t worry about any unfamiliar language, fonts or colours - we can ignore most of it for now - all you need to know is that\n\nIn [1]: ... is code that we’ve sent to the computer, and\nOut[1]: ... is its response.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#first-glance-arithmetic",
    "href": "python/Essentials/1 - Fundamentals.html#first-glance-arithmetic",
    "title": "The Fundamentals",
    "section": "First glance: arithmetic",
    "text": "First glance: arithmetic\nTo start with, we can use Python like a calculator. Type the following commands in the console, and press Enter to execute them:\n\n1 + 1\n\n2\n\n\n\n2 * 3\n\n6\n\n\n\n4 / 10\n\n0.4\n\n\n\n5 ** 2\n\n25\n\n\nAfter running each command, you should see the result as an output.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#variables",
    "href": "python/Essentials/1 - Fundamentals.html#variables",
    "title": "The Fundamentals",
    "section": "Variables",
    "text": "Variables\nLike language, Python has nouns and verbs. We call the nouns variables: they are the ‘things’ we manipulate with our code.\nEssentially, a variable is a named container. We access it by its name, and we get its value.\nTo create a variable, you need to choose a name and a value with name = value. For example\n\nexample_int = 42\n\nWhenever you use the variable’s name, Python will now access its value:\n\nexample_int\n\n42\n\n\nWe can use the variables in place of the values\n\nexample_float = 5.678\nproduct = example_int * example_float\nproduct\n\n238.476\n\n\n\nSpyder helps us with extra panels and features apart from the Console. To see what variables you have created, look at the “Variable explorer” tab in the top right.\n\n\nTypes\nVariables have different types. So far, we’ve just looked at storing numbers, of which there are three types:\n\nint - integers store whole numbers, e.g. 1, 5, 1000, -3.\nfloat - floating point numbers store decimals and scientific notation, e.g. 1.5, -8.97, 4e-6.\ncomplex - complex numbers express the imaginary unit with j, e.g. z = 1+2j is \\(z = 1+2i\\).\n\nLet’s look at some other types\n\nBooleans\nEven simpler than integers is the boolean type. These are either 1 or 0 (True or False), representing a single binary unit (bit). Don’t be fooled by the words, these work like numbers: True + True gives 2.\n\nexample_bool = True\n\n\nIn Python, the boolean values True and False must begin with a capital letter.\n\n\n\nStrings\nLet’s look at variable types which aren’t (necessarily) numbers. Sequences are variables which store multiple pieces of data. For example, strings store a sequence of characters and are created with quotation marks 'blah blah blah' or \"blah blah blah\":\n\nexample_string = 'This is an example of a string!'\n\n\n\nLists\nWe can also create lists, which will store several variables (not necessarily of the same type). We need to use square brackets for that:\n\nexample_numbers = [38, 3, 54, 17, 7]\nexample_diverse = [3, 'Hi!', 9.0]\n\nLists are very flexible as they can contain any number of items, and any type of data. You can even nest lists inside a list, which makes for a very flexible data type.\nOperations on sequences are a bit different to numbers. We can still use + and *, but they will concatenate (append) and duplicate, rather than perform arithmetic.\n\nexample_string + ' How are you?'\nexample_numbers + example_diverse\n3 * example_numbers\n\n[38, 3, 54, 17, 7, 38, 3, 54, 17, 7, 38, 3, 54, 17, 7]\n\n\nHowever, depending on the variable, some operations won’t work:\n\nexample_string + example_int\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 example_string + example_int\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\nThere are other data types like tuples, dictionaries and sets, but we won’t look at those in this session. Here’s a summary of the ones we’ve covered:\n\n\n\n\n\n\n\n\n\n\nCategory\nType\nShort name\nExample\nGenerator\n\n\n\n\nNumeric\nInteger\nint\n3\nint()\n\n\nNumeric\nFloating Point Number\nfloat\n4.2\nfloat()\n\n\nNumeric\nBoolean\nbool\nTrue\nbool()\n\n\nSequence\nString\nstr\n'A sentence '\n\" \" or ' ' or str()\n\n\nSequence\nList\nlist\n['apple', 'banana', 'cherry']\n[ ] or list()\n\n\n\nThe generator commands are new. We use these to manually change the variable type. For example,\n\nint(True)\n\n1\n\n\nyields 1, converting a boolean into an integer. These commands are functions, as opposed to variables - we’ll look at functions a bit later.\n\n\n\nIndexing\nWe can access part of a sequence by indexing. Sequences are ordered, starting at 0, so the first element has index 0, the second index 1, the third 2 and so on. For example, see what these commands return:\n\nexample_string[0]\nexample_string[6]\nexample_numbers[4]\n\n7\n\n\nIf you want more than one element in a sequence, you can slice. Simple slices specify a range to slice, from the first index to the last, but not including the last. For example:\n\nexample_numbers[0:4]\n\n[38, 3, 54, 17]\n\n\nThat command returns elements from position 0 up to - but not including! - position 4.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#scripts",
    "href": "python/Essentials/1 - Fundamentals.html#scripts",
    "title": "The Fundamentals",
    "section": "Scripts",
    "text": "Scripts\nSo far, we’ve been working in the console, our direct line to the computer. However, it is often more convenient to use a script. These are simple text files which store code and run when we choose. They are useful to\n\nwrite code more comfortably,\nstore clearly defined steps in chronological order,\nshare a process with peers easily, and\nmake your work reproducible\n\nLet’s create a folder system to store our script in by creating a project.\n\nPress Projects &gt; New project... and name your project, perhaps “python_training”.\nCreate a new script with ctrl+N, File &gt; New file... or the new file button.\n\nYou should now see a script on the left panel in Spyder, looking something like this:\nTry typing a line of code in your new script, such as\n\nexample_message = \"This is an example message\"\nexample_message\n\n'This is an example message'\n\n\nPress F9 to run each line, or ctrl+enter for the whole script. You should see something like the following appear in the console (depending on how you ran it):\nWe’ll work out of a script for the rest of the session. Don’t forget to save your script by pressing ctrl+S or the save button. )",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#functions",
    "href": "python/Essentials/1 - Fundamentals.html#functions",
    "title": "The Fundamentals",
    "section": "Functions",
    "text": "Functions\nFunctions are little programs that do specific jobs. These are the verbs of Python, because they do things to and with our variables. Here are a few examples of built-in functions:\n\nlen(example_numbers)\nmin(example_numbers)\nmax(example_numbers)\nsum(example_numbers)\nround(example_float)\n\n6\n\n\nFunctions always have parentheses () after their name, and they can take one or several arguments, or none at all, depending on what they can do, and how the user wants to use them.\nHere, we use two arguments to modify the default behaviour of the round() function:\n\nround(example_float, 2)\n\n5.68\n\n\n\nNotice how Spyder gives you hints about the available arguments after typing the function name?\n\n\nOperators\nOperators are a special type of function in Python with which you’re already familiar. The most important is =, which assigns values to variables. Here is a summary of some important operators, although there are many others:\n\nGeneral\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\n\n\n\n\n=\nAssignment\nAssigns values to variables\na = 7\n\n\n#\nComment\nExcludes any following text from being run\n# This text will be ignored by Python\n\n\n\n\n\nMathematical\n\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\nExample output\n\n\n\n\n+\nAddition\nAdds or concatenates values, depending on variable types\n7 + 3 or \"a\" + \"b\"\n10 or 'ab'\n\n\n-\nSubtraction\nSubtracts numerical values\n8 - 3\n5\n\n\n*\nMultiplication\nMultiplies values, depending on variable types\n7 * 2 or \"a\" * 3\n14 or 'aaa'\n\n\n**\nExponentiation\nRaises a numerical value to a power\n7 ** 2\n49\n\n\n/\nDivision\nDivides numerical values\n3 / 4\n0.75\n\n\n//\nFloor division\nDivides numerical values and then rounds down\n3 // 4\n0\n\n\n%\nRemainder\nTakes the remainder of numerical values\n13 % 7\n6\n\n\n\n\n\nComparison\n\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\nExample output\n\n\n\n\n==\nEqual to\nChecks whether two variables are the same and outputs a boolean\n1 == 1\nTrue\n\n\n!=\nNot equal to\nChecks whether two variables are different\n'1' != 1\nTrue\n\n\n&gt;\nGreater than\nChecks whether one variable is greater than the other\n1 &gt; 1\nFalse\n\n\n&gt;=\nGreater than or equal to\nChecks whether greater than (&gt;) or equal to (==) are true\n1 &gt;= 1\nTrue\n\n\n&lt;\nLess than\nChecks whether one variable is less than the other\n0 &lt; 1\nTrue\n\n\n&lt;=\nLess than or equal to\nChecks whether less than (&lt;) or equal to (==) are true\n0 &lt;= 1\nTrue",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#finding-help",
    "href": "python/Essentials/1 - Fundamentals.html#finding-help",
    "title": "The Fundamentals",
    "section": "Finding help",
    "text": "Finding help\nTo find help about a function, you can use the help() function, or a ? after a function name:\n\nhelp(max)\nprint?\n\nHelp on built-in function max in module builtins:\n\nmax(...)\n    max(iterable, *[, default=obj, key=func]) -&gt; value\n    max(arg1, arg2, *args, *[, key=func]) -&gt; value\n    \n    With a single iterable argument, return its biggest item. The\n    default keyword-only argument specifies an object to return if\n    the provided iterable is empty.\n    With two or more arguments, return the largest argument.\n\n\n\nIn Spyder, you can use the Ctrl + I keyboard shortcut to open the help in a separate pane.\nFor a comprehensive manual, go to the official online documentation. For questions and answers, typing the right question in a search engine will usually lead you to something helpful. If you can’t find an answer, StackOverflow is a great Q&A community.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#modules",
    "href": "python/Essentials/1 - Fundamentals.html#modules",
    "title": "The Fundamentals",
    "section": "Modules",
    "text": "Modules\nPython, on its own, requires a lot of manual programming for advanced tasks. What makes it versatile is the capacity to use other people’s code with modules.\nTo bring in advanced variables and functions that other’s have made, we need to import the module. For example\n\npi\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 pi\n\nNameError: name 'pi' is not defined\n\n\n\nreturns an error, because it’s undefined. But the math module contains a variable called pi:\n\nimport math\nmath.pi\n\n3.141592653589793\n\n\n\nTo access objects from within a module, we use a full stop: module.object_inside.\n\n\nNumPy for arrays\nArrays are a data type introduced by numpy, a module with many functions useful for numerical computing.\nFor example, you can convert the list we created before to then do mathematical operations on each one of its elements:\n\nimport numpy as np\nexample_array = np.array(example_numbers)\nexample_array * 2\n\narray([ 76,   6, 108,  34,  14])\n\n\n\n\nPandas for dataframes\npandas introduces dataframes, which are often used to store two-dimensional datasets with different kinds of variables in each column. If your data is stored as a spreadsheet, you probably want to import it with a pandas function.\nFirst, we’ll need to install and import the pandas module. Install it as before (either with pip or conda), and then run\n\nimport pandas as pd\n\nNow, let’s import some data to get ready for the next session.\n\nCreate a new folder in your project called data\nDownload the Players2024.csv file\nMove it into your new data folder\nUse the function pd.read_csv() to load the data:\n\n\ndf = pd.read_csv(\"../../data/Players2024.csv\")\n\nYou’ll see that it’s now in your variable explorer. You can double-click on a dataframe in the Variable explorer to explore it in a separate window.\nWe’ll look at manipulating these dataframe objects in the next session. For now, try running the df.head() function to examine the first few rows:\n\ndf.head()\n\n\n\n\n\n\n\n\nname\nbirth_date\nheight_cm\npositions\nnationality\nage\nclub\n\n\n\n\n0\nJames Milner\n1986-01-04\n175.0\nMidfield\nEngland\n38\nBrighton and Hove Albion Football Club\n\n\n1\nAnastasios Tsokanis\n1991-05-02\n176.0\nMidfield\nGreece\n33\nVolou Neos Podosferikos Syllogos\n\n\n2\nJonas Hofmann\n1992-07-14\n176.0\nMidfield\nGermany\n32\nBayer 04 Leverkusen Fußball\n\n\n3\nPepe Reina\n1982-08-31\n188.0\nGoalkeeper\nSpain\n42\nCalcio Como\n\n\n4\nLionel Carole\n1991-04-12\n180.0\nDefender\nFrance\n33\nKayserispor Kulübü\n\n\n\n\n\n\n\n\n\nMatplotlib for visualisation\nmatplotlib is a large collection of data visualisation functions, and pyplot is a submodule of matplotlib that contains essentials.\n\nimport matplotlib.pyplot as plt\nplt.plot(example_array)\n\n\n\n\n\n\n\n\nThis shows a plot in the Plots tab of Spyder.\n\n\n\n\n\n\nWarningPlots not appearing\n\n\n\n\n\nIf your plots aren’t appearing, then it might be due to a known bug. The latest versions of Spyder and matplotlib solve the problem, but we can apply a fix locally for now.\nStep 1.\nCheck that it’s not a different issue. If you see any error message, then this bug is not the problem - you should solve the error first.\nAssuming there is no error message, this bug is featuring if\n\nThe plot is not appearing, and\nThe console has this output:\n\n&lt;seaborn.axisgrid.FacetGrid at 0x1e80c2e94f0&gt;\nTo apply a quick fix (and ensure that the plots are otherwise ok), try running\nplt.show()\nThis won’t fix the problem, but it will let you manually see the plots.\nStep 2.\nBefore you try to fix the issue manually, updating Spyder to the latest version should solve the issue.\n\nSave your work and close Spyder\nOpen the Anaconda Navigator\nPress the settings button on the Spyder pane\nPress “Update Application”\n\nOnce it’s done, relaunch Spyder and give it a go.\nStep 3.\nThere are three ways which might fix the bug if you can’t update Spyder. The first is to run\nplt.ion()\nTry running the plot again. If it works, great!\nIf it doesn’t work, try\nimport matplotlib as mpl\nmpl.rcParams[\"backend\"] = \"agg\"\nIf that doesn’t work, then you should adjust your Spyder settings.\n\nGo to Tools &gt; Preferences &gt; IPython Console &gt; Graphics\nUnder “Graphics Backend” change the setting to “Automatic”\n\nTry running your plots again.\nStep 4. If they still aren’t working, then ask a trainer for assistance.\n\n\n\nThe default look is a line plot that joins all the points, but we can style a plot with only a few characters:\n\n# blue circles\nplt.plot(example_array, 'bo')\n\n# green squares, dashed line:\nplt.plot(example_array, 'gs--')\n\n\n\n\n\n\n\n\nExtra arguments can be used to style further:\n\n# red, diamonds, solid line; change width of line and size of diamonds:\nplt.plot(example_array, 'rd-', linewidth=3, markersize=10)\n\n\n\n\n\n\n\n\nTo find out about the styling shorthand and all other arguments, look at the documentation:\n\nplt.plot?\n\n\n\nInstalling modules that aren’t built in\nThe math module is built-in - the module came when I installed Python, and the numpy, pandas and matplotlib come with conda installations. Most other modules live online, so we need to download and install them first.\nInstalling modules depends on whether you have a conda environment or not. To check, run\n\nconda\n\n\n\n\n\n\n\n\nMessage\nconda Environment?\n\n\n\n\nconda is a tool for managing and deployi... or something similar\nYes\n\n\nNameError: name 'conda' is not defined\nNo\n\n\n\n\nIf you have a conda environment\nYou can install packages with\n\nconda install package_name\n\n\nYou likely have a conda environment if you installed Anaconda or you installed Spyder 6 (Since Oct 2024)\n\n\n\nIf you do not have a conda environment\nYou can install packages with\n\npip install package_name\n\n\nYou likely have a pip environment if you installed Python manually or are using an older (before Oct 2024) version of Spyder (e.g. Spyder 5)\n\n\n\n\nPlotly Express for interactive visualisations\nOne module that isn’t built-in is plotly, which we can use for interactive visualisations.\n\nimport plotly.io as pio\nimport plotly.express as px\n\n# Set renderer\npio.renderers.default='browser'\n\n# Create bar plot\npx.histogram(df, x = \"age\", color = \"positions\")",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#saving-your-work",
    "href": "python/Essentials/1 - Fundamentals.html#saving-your-work",
    "title": "The Fundamentals",
    "section": "Saving your work",
    "text": "Saving your work\nPress “Save” or Ctrl + S to save your script.\nYour project can be reopened from the “Projects” menu in Spyder.\nBy default, your variables are not saved, which is another reason why working with a script is important: you can execute the whole script in one go to get everything back. You can however save your variables as a .spydata file if you want to (for example, if it takes a lot of time to process your data).",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "python/Essentials/1 - Fundamentals.html#summary",
    "href": "python/Essentials/1 - Fundamentals.html#summary",
    "title": "The Fundamentals",
    "section": "Summary",
    "text": "Summary\nThis morning we looked at a lot of Python features, so don’t worry if they haven’t all sunk in. Programming is best learned through practice, so keep at it! Here’s a rundown of the concepts we covered\n\n\n\n\n\n\n\nConcept\nDesctiption\n\n\n\n\nThe console vs scripts\nThe console is our window into the computer, this is where we send code directly to the computer. Scripts are files which we can write, edit, store and run code, that’s where you’ll write most of your Python.\n\n\nVariables\nVariables are the nouns of programming, this is where we store information, the objects and things of our coding. They come in different types like integers, strings and lists.\n\n\nIndexing\nIn order to access elements of a sequence variable, like a list, we need to index, e.g. example_numbers[2]. Python counts from 0.\n\n\nFunctions\nFunctions are the verbs of programming, they perform actions on our variables. Call the function by name and put inputs inside parentheses, e.g. round(2.5)\n\n\nHelp\nRunning help( ... ) will reveal the help documentation about a function or type.\n\n\nPackages\nWe can bring external code into our environment with import .... This is how we use packages, an essential for Python. Don’t forget to install the package first!",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html",
    "href": "qgis/Advanced topics/6 - Field Data.html",
    "title": "Field Data Collection",
    "section": "",
    "text": "-   \"DCIM\" - this is a new one, it's for storing images from our phone!\n\n-   \"UQ_Fieldwork\" - this is also new, it's for exporting our project to QField"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#folder-setup",
    "href": "qgis/Advanced topics/6 - Field Data.html#folder-setup",
    "title": "Field Data Collection",
    "section": "",
    "text": "-   \"DCIM\" - this is a new one, it's for storing images from our phone!\n\n-   \"UQ_Fieldwork\" - this is also new, it's for exporting our project to QField"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#install-qfield",
    "href": "qgis/Advanced topics/6 - Field Data.html#install-qfield",
    "title": "Field Data Collection",
    "section": "Install QField",
    "text": "Install QField\nQField plugs directly in to QGIS, and allows you to link a QGIS project with your mobile phone for data collection.\nAndroid Download iOS Download\n\n\n\n\n\n\nNoteYou can also explore Avenza, which uses GeoPDFs\n\n\n\n\n\nFor Avenza Maps you just need to add a GeoPDF and you can collect data on it. It’s less functional than QField, but it’s a great fallback tool. Android Download iOS Download\nThere are alternatives out there, such as Input (MerginMaps)."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#dem",
    "href": "qgis/Advanced topics/6 - Field Data.html#dem",
    "title": "Field Data Collection",
    "section": "DEM",
    "text": "DEM\nA Digital Elevation Model (DEM) is a common example of raster data, i.e. grid data that contains a value in each cell (a bit like the pixels in a coloured picture).\nFor this tutorial, we are using a DEM sourced from ELVIS - Geoscience Australia’s ELeVation Information System."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#aerial-imagery",
    "href": "qgis/Advanced topics/6 - Field Data.html#aerial-imagery",
    "title": "Field Data Collection",
    "section": "Aerial Imagery",
    "text": "Aerial Imagery\nThere are a few places you can acquire aerial photography.\n\nLocal Raster Files\nAs a UQ student, you have access to very high resolution imagery from NearMap. You can activate an account here to download georeferenced aerial imagery. You can even access an array of imagery going back in time to around 2010.\nWe won’t use NearMap today, but you’re welcome to explore it.\n\n\nMapserver Raster Files\nToday we’re going to use a World Imagery XYZ Tile from ESRI.\n\nScroll down the Browser panel until your see XYZ Tiles\nRight click XYZ Tiles and select New Connection...\n\nIn Name type ESRI World Imagery\nIn URL paste:\nhttps://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\nIncrease the Max. Zoom Level to 20\n\nThis value depends on what is available from the given service in different parts of the world. Increasing that value beyond 20 for this map in Brisbane will show “Map data not yet available” when you zoom in very close.\n\nClick OK\n\nIn the Browser panel, expand XYZ Tiles and double click on ESRI World Imagery"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#lot-plans",
    "href": "qgis/Advanced topics/6 - Field Data.html#lot-plans",
    "title": "Field Data Collection",
    "section": "Lot Plans",
    "text": "Lot Plans\nYou can access a wide variety of QLD Government Data, including Spatial Data such as lot plans and vegetation maps, from QLD Spatial.\nToday we have extracted a selection from Property boundaries Queensland\nThere are three ways to access data from QSpatial.\n\nDownload all of the data from a layer\nSelect a portion of a layer for download using the My List function\nLive load it into your project using a Mapserver."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#buffer-the-lines",
    "href": "qgis/Advanced topics/6 - Field Data.html#buffer-the-lines",
    "title": "Field Data Collection",
    "section": "Buffer the Lines",
    "text": "Buffer the Lines\n\nGo to Vector &gt; Geoprocessing Tools &gt; Buffer\nChoose “Lines” as the Input Layer\nSet the Distance to 10 metres\n\nWe can also make the buffer squared if we want, but we will keep it with the rounded default\n\nTick the Dissolve result box\n\nThis will merge the polygons from our output, making for a cleaner look. The Dissolve tool also exists as a standalone tool.\n\nClick the three dots ... next to the Buffered field, navigate to the project’s processed data folder, and type in UQ_Boundary_Buffer and click Save\nClick Run"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#explore-projections",
    "href": "qgis/Advanced topics/6 - Field Data.html#explore-projections",
    "title": "Field Data Collection",
    "section": "Explore Projections",
    "text": "Explore Projections\nHopefully it’s clear why we needed to convert from a Geographic Coordinate System to a Projected Coordinate System, but why is it important that we chose the local projection EPSG:23856 - GDA94 / MGA zone 56?\nLet’s see what would happen if we did our buffer on those lines in a different projection.\n\nReproject Data\n\nGo to Vector &gt; Data Management Tools &gt; Reproject Layer...\nChoose the Lines in Input layer\nSet the Target CRS to EPSG:3857 - WGS84 / Pseudo-Mercator\n\nThis is a very common projection that Google and your phones use\n\nClick Run\n\nWe don’t need to permanently save this, so we can leave it as a temporary layer\n\n\n\n\nBuffer Reprojected Lines\n\nGo to Vector &gt; Geoprocessing Tools &gt; Buffer\nChoose “Reprojected” as the Input Layer\nSet the Distance to 10 metres\nClick Run\n\nMove the new Buffered layer order so that it draws over the UQ_Boundar_Buffer layer. Notice anything interesting?\nThe new Buffered layer is about 1m smaller!\nThis is because EPSG:3857 - WGS84 / Pseudo-Mercator is a global projection that tries to preserve shapes. Although the units are in metres, the scaling factor changes as you move away from the equator to account for the curvature of the Earth.\nIt can still be useful to use this projection to take points. But you have to be careful when you’re making measurements and calculations, for those, a local projection is usually better."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#style-the-boundary-buffer-polygon",
    "href": "qgis/Advanced topics/6 - Field Data.html#style-the-boundary-buffer-polygon",
    "title": "Field Data Collection",
    "section": "Style the Boundary buffer polygon",
    "text": "Style the Boundary buffer polygon\n\nOpen the Layer Styling panel by pressing F7 (or fn+F7)\nSelect the UQ_Boundar_Buffer layer from either the Layer Styling panel, or the Layers panel.\nUnder Fill, click Simple Fill\n\nClick the dropdown next to Fill color and select a colour that reminds us not to go there, like orange\n\nChange the Opacity to something around 30%\n\n\n\n\nSave your project\nIt’s not essential at this stage, it’s just a good reminder to save your work regularly so you don’t lose things when things go wrong."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#add-another-field",
    "href": "qgis/Advanced topics/6 - Field Data.html#add-another-field",
    "title": "Field Data Collection",
    "section": "Add Another Field",
    "text": "Add Another Field\nIt would be nice to be able to take photos when we collect our data, let’s add another field.\n\nDouble click on the new fieldwork_data layer\nClick on the Fields tab\nClick the yellow pencil button to Toggle Editing Mode\nClick the now visible yellow New field button\n\nName: Photo\nType: Text (string)\nClick OK\n\nClick the yellow pencil button to Toggle Editing Mode\nClick Save\nClick OK"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#attributes-form-preparation",
    "href": "qgis/Advanced topics/6 - Field Data.html#attributes-form-preparation",
    "title": "Field Data Collection",
    "section": "Attributes Form Preparation",
    "text": "Attributes Form Preparation\nNow that we have a layer with all the desired fields, we can now edit the layer form to customise how things are entered.\n\nDouble click on the new collected_data layer\nClick on the Attributes Form tab\nAt the very top of the window, click Autogenerate and change it to Drag and Drop Designer\n\nOn the left you will see all of our Fields, we can drag and drop these into the Form Layout section - this section lays out how our form will look when we enter new data.\n\nDrag and Drop the Photo Field to the Form Layout so that it is sitting above DateTime\nClick fid and press the red minus button - we want to keep the field, but don’t need to see this in our form\nClick ID\n\nUnder Constraints tick Not Null and Enforce not null constraint\nWe don’t need to change anything else for ID, we just want to make it mandatory\n\nClick Category\n\nUnder Widget Type click Text Edit and change it to Value Map\nAdd the following to Values and Descriptions:\n\nEX and Excellent\nGD and Good\nPR and Poor\nOT and Other\n\nIt is good practice to have an Other field if you’re using a “Not Null” constraint, as it allows the user to note when something doesn’t meet the given Categories.\n\n\nUnder Constraints tick Not Null and Enforce not null constraint\n\nClick Photo\n\nUnder Widget Type click Text Edit and change it to Attachment\nUnder Path change Default path to @project_home + ‘/DCIM’\n\nChange Absolute Path to Relative to Project Path\n\nTick **Use a hyperlink for document path (read-only)\nUnder Integrated Document Viewer change Type from No Content to Image\n\nClick DateTime\n\nUnder General untick Editable - we don’t want to edit this field\nScroll to the bottom, under Defaults change the Default value to $now\nIf this worked, there will be a date and time next to Preview\n\nClick Lat\n\nUnder General untick Editable - we don’t want to edit this field\nScroll to the bottom, under Defaults change the Default value to $y\nThe Preview will show NULL, but that’s okay, we don’t have data yet\n\nClick Long - Under General untick Editable - we don’t want to edit this field - Scroll to the bottom, under Defaults change the Default value to $x\n\nClick OK\n\nWe should now have a functional form, let’s test it in QGIS before we send it to our phones\n\nClick the yellow pencil button to Toggle Editing on\nClick the green dots (or press Ctrl + .) to Add Point Feature\nClick on the map to add a point\nThe Name should be mandatory, the Description editable, Photo have an add option, DateTime should have the current date and time, and Lat and Long should have numbers like “-27.494066205142065” and “153.0153703956312”\nClick Cancel\nClick the yellow pencil button to Toggle Editing off"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#tracks-attributes-form-preparation",
    "href": "qgis/Advanced topics/6 - Field Data.html#tracks-attributes-form-preparation",
    "title": "Field Data Collection",
    "section": "Tracks Attributes Form Preparation",
    "text": "Tracks Attributes Form Preparation\nLet’s prepare the tracks DateTime as we did with the collected_data - Double click on the new tracks layer - Click on the Attributes Form tab - At the very top of the window, click Autogenerate and change it to Drag and Drop Designer\nOn the left you will see all of our Fields, we can drag and drop these into the Form Layout section - this section lays out how our form will look when we enter new data.\n\nClick fid and press the red minus button - we want to keep the field, but don’t need to see this in our form\nClick DateTime\n\nUnder General untick Editable - we don’t want to edit this field\nScroll to the bottom, under Defaults change the Default value to $now\nIf this worked, there will be a date and time next to Preview\n\nClick OK"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#install-qfield-plugin",
    "href": "qgis/Advanced topics/6 - Field Data.html#install-qfield-plugin",
    "title": "Field Data Collection",
    "section": "Install QField Plugin",
    "text": "Install QField Plugin\n\nNavigate to Plugins &gt; Manage and Install Plugins...\nSearch for “QField”\nClick on QField Sync\nClick Install Plugin\nOnce it has installed, click Close\n\nYou can now access the QField Sync Plugin through the menu."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#prepare-data-for-qfield",
    "href": "qgis/Advanced topics/6 - Field Data.html#prepare-data-for-qfield",
    "title": "Field Data Collection",
    "section": "Prepare Data for QField",
    "text": "Prepare Data for QField\nAt this point we need to clean up our Layers. You don’t have to remove everything, but it’s worth deciding what layers you want to remove, and what scratch layers you want to make permanent.\n\nHide any layers you want to keep, but don’t want to export to QField\nMake sure your layer order makes sense, I recommend the following layers visible in this order:\n\ncollected_data\ntracks\nUQ_Boundary_Buffer\nUQ_Contours_5m\nUQ_DEM_1m\nUQ_Hillshade\nWorld Imagery Tile"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#export-to-qfield",
    "href": "qgis/Advanced topics/6 - Field Data.html#export-to-qfield",
    "title": "Field Data Collection",
    "section": "Export to QField",
    "text": "Export to QField\n\nNavigate to Plugins &gt; QFieldSync &gt; Package for QField\nIf you get a Message window popup, click Next\nGive your project an appropriate title UQ_Fieldwork\nUnder Packaged Project Filename navigate to your UQ_Fieldwork folder and click Save\nUnder Advanced untick every folder except DCIM\n\nWe want a copy of this folder for our photos to be saved to. The rest of our data will be packaged into the QField folder.\n\nAt the bottom of the window click Configure current project...\n\nClick the Cable Export tab (if we were using QFieldCloud, we would click that option now instead)\nClick the Toggle Layers eye symbol on the right\n\nIn the Action column change Copy to Remove from project for any layers you don’t want to copy to QField.\n\nScroll down and tick Geofencing\n\nSet Geofencing areas layer to UQ_Boundary_Buffer\n\nClick OK\n\nClick Create\n\nWe now need to zip the QField folder and send it to our phone!\n\nNavigate to your Project folder, right click on the UQ_Fieldwork folder and compress it to a zip file.\nSend this file to your phone via email, cloud, or using a cable."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#opening-the-qfield-project",
    "href": "qgis/Advanced topics/6 - Field Data.html#opening-the-qfield-project",
    "title": "Field Data Collection",
    "section": "Opening the QField Project",
    "text": "Opening the QField Project\nAndroid - Open QField - Skip any popups - Tap Open local file - Tap the green plus button in the bottom right - Tap Import project from ZIP - Navigate to your zip file. In my case, I had to go to the top left menu, and tap on Downloads - The file should open in QField. You may need to tap on the outer folder, and then the Project itself.\niOS - Open the zip file and extract it to: On My iPhone/QField/Imported Projects - Open QField - Skip any popups - Tap Open local file - Tap Imported projects - Open the UQ_Fieldwork folder until you reach the UQ_Fieldwork Project file. - The project should open in QField.\nYou can now access your map."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#using-qfield",
    "href": "qgis/Advanced topics/6 - Field Data.html#using-qfield",
    "title": "Field Data Collection",
    "section": "Using QField",
    "text": "Using QField\n\nTap the menu in the top right to see your layers.\nTap the eye to hide or unhide layers\nIf you tap on a layer, and then tap the pencil icon in the bottom right, you can edit a layer.\nLet’s do this for our data_collected layer\nTap on the map on the right to return to the map, your cursor will now be a cross-hair\nNavigate around and then press the green + button to add a point\nFill out the details, and then tap the tick in the top left.\nYou’ve collected data!\n\n\nTurning on Tracks\n\nTap the menu in the top right to see your layers.\nPress and hold on your Tracks layer\n\nWhen the new menu appears, tap Setup tracking\nHere you can choose the interval for when a new point will be placed for your tracks\n\nAs we’re inside and may not move much, turn on Time requirement and set a short Minimum time of 15 seconds\nTap Start tracking\n\nIf you have your phone’s GPS on, and you zoom in on yourself, your should see a tracking line appear.\n\n\n\n\nTurning off Tracks\n\nPress and hold on your Tracks layer\n\nWhen the new menu appears, tap Stop tracking\n\n\nTo export your data back to QGIS, you can either copy the whole project folder in your phones storage back to your computer, or:\n\nGo to the menu\nTap the folder with a cog on it\nTap the three dots next to your data_collected.gpkg file\nSend it to your email\n\nThere’s more to explore, such as the very very helpful QFieldCloud, and I encourage you to do so.\nIf you have any questions, reach out to the UQ Library Training Team at training@library.uq.edu.au"
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#exporting-to-avenza-maps",
    "href": "qgis/Advanced topics/6 - Field Data.html#exporting-to-avenza-maps",
    "title": "Field Data Collection",
    "section": "Exporting to Avenza Maps",
    "text": "Exporting to Avenza Maps\n\n\n\n\n\n\nNote\n\n\n\n\n\nClick on Show Layout Manager in the toolbar or use Project &gt; Layout Manager. Create a new layout called “Avenza”. We can now see the Layout window.\nNormally we would add many elements to our layout if we were exporting it for print such as the map, a legend, a scale bar, a north arrow…\nIn this case however, we are simply interested in our map. Let’s add the map to the canvas:\n\nGo to the Layout tab, scroll down to ‘Resize Layout to Content’, click ‘Resize layout’\nBefore we export, let’s turn off any layers we aren’t using in QGIS to save space\nClick the Refresh View button up the top\nNow we are ready to export.\nGo to ‘Layout &gt; Export as PDF…’ and save your map.\nThe ‘PDF Export Options’ window will open\nTick the ‘Create Geospatial PDF (GeoPDF)’ box\nClick ‘Save’\n\nYou can repeat this process with the DEM and Hillshade to export out another kind of map.\nNow you simply need to export the pdf file(s) to your phone. You can email it, send it through the cloud, or transfer it using a cable.\nWhen you first open Avenza Maps it will ask you to create an account, but you can import up to three maps without doing so, you can avoid creating an account by selecting the ‘x’ in the top right corner. * Allow Avenza Maps to access your device location * Select the orange ‘+’ in the bottom right and select ‘Download or import a map’ * Choose ‘From Storage Locations’ (if requested, give Avenza Maps the permissions to access your files) * Do the same for the other map, if you created one. * Once it has been imported, tap on the map. * You can now move the map around with your finger, and pinching to zoom. * Tapping the placemark icon in the bottom left will add a placemark in the middle of the crosshairs. * Tapping the 3 dots in the bottom right will allow you to add GPS tracking and draw and measure distances."
  },
  {
    "objectID": "qgis/Advanced topics/6 - Field Data.html#autoid",
    "href": "qgis/Advanced topics/6 - Field Data.html#autoid",
    "title": "Field Data Collection",
    "section": "AutoID",
    "text": "AutoID\nWe can use some fancy code to make the ID automated\n\nDouble click on the new collected_data layer\n\nClick on the Attributes Form tab\nClick ID\n\nUnder General untick Editable - we don’t want to edit an automated field\nUnder Defaults click the Expression Builder button\n\nPaste in this code:\n\n\n\n\nconcat(\n    \"cat\",\n    '-',\n    lpad(\n        to_string(\n            coalesce(\n                aggregate(\n                    'DataCollection',        -- layer name\n                    'max',                    -- aggregate function\n                    to_int(\n                        regexp_substr(\"ID\", '\\\\d+')\n                    ),                        -- numeric part of auto_id\n                    \"cat\" = attribute(@parent, 'cat')\n                ) + 1,\n                1\n            )\n        ),\n        3,\n        '0'\n    )\n)"
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html",
    "href": "qgis/Essentials/4 - Raster Analysis.html",
    "title": "Raster Analysis",
    "section": "",
    "text": "In this workshop, we will learn about:\n\nDEM\nTerrain Analysis\nContours\nGeoreferencing"
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#what-are-we-going-to-learn",
    "href": "qgis/Essentials/4 - Raster Analysis.html#what-are-we-going-to-learn",
    "title": "Raster Analysis",
    "section": "",
    "text": "In this workshop, we will learn about:\n\nDEM\nTerrain Analysis\nContours\nGeoreferencing"
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#what-is-raster-data",
    "href": "qgis/Essentials/4 - Raster Analysis.html#what-is-raster-data",
    "title": "Raster Analysis",
    "section": "What is Raster Data?",
    "text": "What is Raster Data?\nA Digital Elevation Model (DEM) is a common example of raster data, i.e. grid data that contains a value in each cell (a bit like the pixels in a coloured picture)."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#install-the-saga-plugin",
    "href": "qgis/Essentials/4 - Raster Analysis.html#install-the-saga-plugin",
    "title": "Raster Analysis",
    "section": "Install the SAGA Plugin",
    "text": "Install the SAGA Plugin\nWe need to install a plugin so we can access certain geoprocessing tools (the built-in SAGA provider has been removed in version 3.30). Go to Plugins &gt; Manage and Install Plugins... and Search... for “SAGA”. From the list on options choose Processing Saga NextGen Provider then in the bottom right, click Install Plugin. You might also need to install SAGA (version 9 or above) on your computer, if not already available."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#gather-some-data",
    "href": "qgis/Essentials/4 - Raster Analysis.html#gather-some-data",
    "title": "Raster Analysis",
    "section": "Gather some data",
    "text": "Gather some data\nUse the download button to download each file into your project directory. You will need a login for that, which is free but can take a bit of time. You can instead download the two raster files as an archive from our GitHub repository here."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#merge-the-two-dem-layers",
    "href": "qgis/Essentials/4 - Raster Analysis.html#merge-the-two-dem-layers",
    "title": "Raster Analysis",
    "section": "Merge the two DEM layers",
    "text": "Merge the two DEM layers\nIf you downloaded the archive, make sure you place it into the project directory so you can find it in “Project Home” and easily load the raster files: from the Browser panel, we can go into the data archive and drag and drop each .tif file into the Layers panel.\nSee the visible line between the two raster tiles? That is because the two separate raster files have different maximum and minimum values, so use different shades for different elevations. We have to merge them to make sure they use the same colour scale.\nTo do that, we use the Raster &gt; Miscellaneous &gt; Merge... tool to create one single layer from them.\n\nFirst, select both DEM layers for the “Input layers”\nMake sure the option “Place each input file into a separate band” is off, as we want to end up with one single-band layer\nWe can save the output on disk instead of only creating a temporary file (for example, name it SRTM_DEM_merged and save it inside your project directory)\nClick “Run”\n\n\nYou will need to have GDAL installed for this to work.\n\nWe can now remove the two original raster files."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#reproject-the-dem",
    "href": "qgis/Essentials/4 - Raster Analysis.html#reproject-the-dem",
    "title": "Raster Analysis",
    "section": "Reproject the DEM",
    "text": "Reproject the DEM\nIn the merged layer’s Properties (Right click &gt; Properties... &gt; Source), we can see that the Coordinate Reference System (CRS) in use is EPSG:4326 - WGS 84. It is the one that QGIS detected when opening the file. This Geographic Reference System is good for global data, but if we want to focus on a more precise area around Brisbane/Meanjin, and want our analyses to be accurate, we should reproject the data to a local Projected Reference System (PRS). We will also need a projection that uses Metres, rather than Degrees (as EPSG:4326 does). A good PRS for around Brisbane/Meanjin is “EPSG:7856 - GDA2020 / MGA zone 56”. We can’t change that here, we instead will need to use the Warp (Reproject) tool.\n\nUse the tool Raster &gt; Projections &gt; Warp (Reproject)\nuse the merged layer as an input\npick “EPSG:7856 - GDA2020 / MGA zone 56” as the Target CRS\n\nyou may need to click the Select CRS button \nuntick No CRS\nuse the filter to search for “7856”\nYou should be able to find “EPSG:7856 - GDA2020 / MGA zone 56” under Predefined Coordinate Reference Systems\n\n\n\nIf you want to learn more about the static datum GDA2020 (for “Geocentric Datum of Australia 2020”), an upgrade from the previous, less precise GDA94, head to the ICSM website."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#clip-the-dem",
    "href": "qgis/Essentials/4 - Raster Analysis.html#clip-the-dem",
    "title": "Raster Analysis",
    "section": "Clip the DEM",
    "text": "Clip the DEM\nWe now use Raster &gt; Extraction &gt; Clip Raster by Extent to focus on a smaller area of interest.\nMake sure the DEM is selected in the Input layer, and set the clip extent with ... &gt; Draw on Canvas. We want to select an area that is inland, and contains both some of the D’Aguilar National Park, and a section of the Brisbane river (you can untick the DEM in the Layers panel to reveal the basemap).\nIf you don’t save to file directly, remember two things:\n\nrename your clipped layer so it is more descriptive than the generic “Clipped (extent)”\nyou are currently using a temporary, scratch layer. It will be discarded if you exit QGIS. It is very useful for temporary intermediate files, but it can be safer to save copies of your intermediate data while you work, just in case! You can right-click on the layer and use Export &gt; Save As.."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#change-the-symbology",
    "href": "qgis/Essentials/4 - Raster Analysis.html#change-the-symbology",
    "title": "Raster Analysis",
    "section": "Change the symbology",
    "text": "Change the symbology\nWe can style our DEM with a terrain colour palette:\n\ndouble-click on the clipped DEM layer\ngo to the “Symbology” tab\nchange the Render type to “Singleband pseudocolor”\nby default, it uses the min/max values, which is what we want\nwe can change the “Color ramp” to something more suitable with the drop-down menu and Create new color ramp... &gt; Catalog: cpt-city &gt; Topography &gt; Elevation, for example."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#add-a-hillshade",
    "href": "qgis/Essentials/4 - Raster Analysis.html#add-a-hillshade",
    "title": "Raster Analysis",
    "section": "Add a hillshade",
    "text": "Add a hillshade\nAdding a hillshade makes your visualisation of elevation more readable and visually pleasing by giving an artificial lighting look to your map.\n\nRight-click on the DEM layer and “Duplicate layer”\nRename the duplicated layer “hillshade”\nOpen the Symbology menu for the hillshade layer\nChange the “Render type” to “Hillshade”\nThe defaults should work well, but you can play with the settings, like the Altitude and the Azimuth\nMake sure you apply some transparency to the pseudocolour DEM, and place the hillshade layer underneath (in Properties &gt; Symbology &gt; Transparency)\nDown the bottom of the window under Resampling change the Zoomed: in and out from “Nearest Neighbour” to “Cubic” (this will remove some of the grid-like patterns you might see in your Hillshade layer otherwise)\n\n\nAnother method is to use the hillshade tool instead of the symbology: Raster &gt; Analysis &gt; Hillshade...."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#create-a-watershed-layer",
    "href": "qgis/Essentials/4 - Raster Analysis.html#create-a-watershed-layer",
    "title": "Raster Analysis",
    "section": "Create a watershed layer",
    "text": "Create a watershed layer\nUsing the Strahler tool, we can create a watershed raster that shows where water would flow according to the DEM.\nOpen the Processing Toolbox (cog icon) and try using the SAGA Next Gen tool called “Strahler order” using the clipped DEM as an input (a temporary file is fine for now).\nLook at the result. It looks like there are few issues with our data. You may get a question mark symbol  next to your data, when hovered over it will say “There is no coordinate reference system set!”. To resolve this, issue, simply left-click on the question mark symbol and assign “EPSG:7856 - GDA2020 / MGA zone 56” as the CRS.\nHowever there is still another issue with our data. A common problem with DEMs is that they have sinks and spikes that will make further analyses more difficult. This will mean the analysis is unable to best find where the water would flow. To resolve this, we need to use another tool to smooth out our raster before using the Strahler order tool.\nWe can use the “Fill sinks (Wang & Liu)” tool to fill the sinks in our clipped DEM.\n\nWhen we do that, we might have to play with the “Minimum slope” value. A value of 0.01 degrees should work well if the layer was reprojected to a suitable Projected Reference System.\nAs an output, we only need to tick the “Filled DEM” (first one in the list), which we can also save to file. You can however keep the “Watershed Basins” output to check that your minimum slope is high enough.\n\nIf we re-run the Strahler order tool on the filled DEM, we will be able to see more useful data.\nWe can now colour the layer with “Singleband pseudocolor” to highlight the bigger streams. A palette that goes from white (for low values) to a dark colour (for high values) should work well. You can also set the smaller streams to be transparent to filter them out.\n\nAnother way to filter out the noise of the smaller streams and highlight the major streams in the network, we can use the Raster &gt; Raster Calculator tool and use a formula like: \"name_of_layer@1\" &gt;= 6 (the value will depend on how many levels exist in the Strahler layer). We need to save to file to be able to do that (name it “strahler_filtered”, for example). This will assign the value 1 to the cells matching the condition, and 0 to what is under the limit."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#channel-network-and-drainage-basin",
    "href": "qgis/Essentials/4 - Raster Analysis.html#channel-network-and-drainage-basin",
    "title": "Raster Analysis",
    "section": "Channel network and drainage basin",
    "text": "Channel network and drainage basin\nAnother analysis we can do is use the “Channel network and drainage basins” tool to calculate the flow direction, channels and drainage basins.\n\nMake sure you run this tool on the filled DEM.\nWe might have to change the threshold to a higher one if the output includes too many small basins and channels. As the threshold is related to the Strahler order number, the middle point of your previous Strahler order values is a usually a good default.\n\nYou might want to play with different threshold values depending on what you’re looking for. If you want to look at the main drainage basins of a region, you need to set the threshold higher. If you want to find all the small channels, you need to set the threshold lower. It’s worth trying a few options to find what works best for your dataset and the story you’re trying to tell.\nAs an output, we only want to load (and save to file) the two non-optional outputs:\n\nChannels\nDrainage basins (shapefile) (to differentiate the two “Drainage basins” options, you can check what format it saves the file as)\n\nThis is an example of creating vector data from raster data!\nWe can now play with the symbology for those elements. For example:\n\nTry using different colours for each basin, by classifying by ID, or remove the fill (Simple fill &gt; Fill Style &gt; No Brush) so you can see the colours of the elevation colours underneath. You can also make the borders more obvious by changing the width of the stroke.\nChange the colour of the channels.\n\nChange the symbol from “Single Symbol” to Graduated.\nSet the Value to “Order”\nChoose an appropriate colour ramp\nChange the Mode down the bottom of the window to “Equal Interval”\nClick Apply\n\nYou can also further differentiate minor channels from major ones by using a “Data defined override” for the Width value:\n\nClick on the bar next to Symbol \nClick on the “Data defined override” icon  next to the Width field\nUse the “Assistant”\n“Source” needs to be the column “ORDER” (which corresponds to the Strahler order)\nClick the double-arrow icon to “Fetch value range from layer”\nChange the “Size from” and “to” values to suitable values"
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#viewshed",
    "href": "qgis/Essentials/4 - Raster Analysis.html#viewshed",
    "title": "Raster Analysis",
    "section": "Viewshed",
    "text": "Viewshed\nIf you want to know what can be seen from a certain point in a landscape you can use a DEM to perform a Viewshed Analysis.\nOpen the Processing Toolbox (cog icon) and search for the GDAL tool called “Viewshed”.\n\nInput Layer: Choose your Reprojected DEM layer\nClick the three dots next to Observer location to select a point on the map\nObserver height, DEM units: 1.6 (the average human eye height is around 1.6m, choose a height you think might be appropriate)\nTarget height, DEM units: 1 (this means that the points around the observer will be obscured by any surface that is higher than 1m. If you want to know what ground your observer will see, choose something closer to 0)\nMaximum distance from observer to compute visibility: 5000 (5km is the distance you can see on flat ground due to the curvature of the earth, this would change if you were higher up, for which you can find calculators and a formula)\n\nThis will produce a black and white raster showing what can be seen, and what can’t. Go to the Layer Styling Menu, and change it to Singleband Pseudocolor, change the Mode to Equal Interval, and set the Classes to 2. Change one of the Colors to transparent to highlight either what can be see, or what cannot.\nAs an extra feature. You can do the reverse analysis with a Viewshed. That is, you could use this to know what landmarks are visible in a landscape. Set the Observer Height to that of a building or tree in the landscape, and the Target Height to be that of people in the landscape, and you’ll know where it can be seen from.\nIf you want to get more sophisticated with your Viewshed analyses, there is, of course, a plugin called Visibility Analysis which will allow you to use one or multiple points as observers, take in account of the Earth’s curvature, see what vector points can see other vector points, and more."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#d-maps",
    "href": "qgis/Essentials/4 - Raster Analysis.html#d-maps",
    "title": "Raster Analysis",
    "section": "3D maps",
    "text": "3D maps\nA 3D viewer is integrated in QGIS: View &gt; 3D Map Views &gt; New 3D Map View\nIn the 3D map window, make sure to first:\n\nClick the Options wrench icon, choose Configure &gt; Terrain, set the “Type” to “DEM (Raster layer)”, and set the “Elevation” to your clipped DEM.\nExaggerate the relief with the “Vertical scale” setting (try 3).\n\nTo see the 3D effect, you will have to use your Ctrl or Shift keys on your keyboard while panning with the mouse to change the angle of view.\nTo avoid seeing gaps in the rendering, you can go back to your Terrain options and set the “Tile resolution” and “Skirt height” to higher values.\n\nA useful plugin for 3D maps is qgis2threeJS, which might be handy to add a 3D map to a website."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#exporting",
    "href": "qgis/Essentials/4 - Raster Analysis.html#exporting",
    "title": "Raster Analysis",
    "section": "Exporting",
    "text": "Exporting\nUse the Layout Manager to create a new layout, and insert both a 2D map and a 3D map.\nWhen inserting the 3D map, it will tell you that the “scene is not set”. You will have to import the 3D scene settings from your view: Item Properties &gt; Scene Settings &gt; Copy Scene Settings from a 3D View... and then select your 3D map from the drop-down."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#saving-your-project",
    "href": "qgis/Essentials/4 - Raster Analysis.html#saving-your-project",
    "title": "Raster Analysis",
    "section": "Saving your project",
    "text": "Saving your project\nNotice the little icon next to some of your layers? We previously created “temporary scratch layers”. This is useful if you keep processing data and creating new layers that you want to discard afterwards. In our case, we do want to keep the “cities” and “rivers” layers, so we need to save them to a file. If we try to close QGIS with scratch layers loaded, it will give you a warning that they will be lost in the process.\nYou can click on the scratch layer icon to save the file. In the dialog, we can give the layers a File name (in our project’s home directory) and click OK.\nYou can save your project with the floppy disk icon, or using Ctrl + S, and the project should be visible in a list as soon as you open QGIS again."
  },
  {
    "objectID": "qgis/Essentials/4 - Raster Analysis.html#feedback",
    "href": "qgis/Essentials/4 - Raster Analysis.html#feedback",
    "title": "Raster Analysis",
    "section": "Feedback",
    "text": "Feedback\nPlease visit our website to provide feedback and find upcoming training courses we have on offer."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html",
    "href": "qgis/Essentials/1 - Fundamentals.html",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this workshop, we will learn about:\n\nThe QGIS interface\nLoading a basemap\nSetting up a project\nVector vs Raster Data\nIdentifying and selecting spatial features\nPersonalising the look of the map\nA basic map export\nFinding help and learning more"
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#what-are-we-going-to-learn",
    "href": "qgis/Essentials/1 - Fundamentals.html#what-are-we-going-to-learn",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this workshop, we will learn about:\n\nThe QGIS interface\nLoading a basemap\nSetting up a project\nVector vs Raster Data\nIdentifying and selecting spatial features\nPersonalising the look of the map\nA basic map export\nFinding help and learning more"
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#interface",
    "href": "qgis/Essentials/1 - Fundamentals.html#interface",
    "title": "The Fundamentals",
    "section": "Interface",
    "text": "Interface\nThe main elements of the interface are:\n\nthe Browser panel, to navigate our file system and data sources\nthe Layers panel, to organise the different layers that compose our map\nthe Canvas, where we see the map."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#load-a-basemap",
    "href": "qgis/Essentials/1 - Fundamentals.html#load-a-basemap",
    "title": "The Fundamentals",
    "section": "Load a Basemap",
    "text": "Load a Basemap\nWe can straight away load an OpenStreetMap basemap to have a background: in the Browser panel, XYZ Tiles &gt; OpenStreetMap."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#controls",
    "href": "qgis/Essentials/1 - Fundamentals.html#controls",
    "title": "The Fundamentals",
    "section": "Controls",
    "text": "Controls\nThe default mouse mode is Pan Map, which allows to drag the map around. We can use the mouse wheel to zoom in and out, and press the Ctrl key to use more precision."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#project-folder-structure",
    "href": "qgis/Essentials/1 - Fundamentals.html#project-folder-structure",
    "title": "The Fundamentals",
    "section": "Project Folder Structure",
    "text": "Project Folder Structure\nWe will start by creating a good folder structure to work within. This folder is where our project, our data, and creations will live. Folder structure is very important for keeping your data tidy, as well as for ease of sharing your project with others. You simply need to zip the project folder if you need to share the whole thing.\n\nOpen QGIS and create a new project with Project &gt; New.\nLet’s now save our project: Project &gt; Save.\nNavigate to where you want to save your project, and create a new folder, let’s call it “qgis_intro”.\n\n\n\n\nInside that folder, create these folders:\n“data” - for all the data we will use to make our maps, split into:\n“raw” - raw data from your research or the internet\n“processed” - any data you’ve modified\n\n“output” - for any maps or images we export\n“temp” - this folder isn’t necessary, but when you’re playing around and testing, it stops things getting messy.\n\nFinally, let’s save our .qgz project file inside the “qgis_intro” folder, named “qgis_intro_map.qgz”\n\n::: {.column width=“5%”}  :::::: {.column width=“30%”} \n\n::: {.column width=“5%”}  ::: ::::::\nYour .qgz file should always be in the highest level folder, so it’s only looking down into folders for data, not back out. This might feel unnecessary now, but things quickly get out of control and hard to find if you don’t have a good folder structure."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#what-is-spatial-data",
    "href": "qgis/Essentials/1 - Fundamentals.html#what-is-spatial-data",
    "title": "The Fundamentals",
    "section": "What is Spatial Data?",
    "text": "What is Spatial Data?\nWhat is spatial data? Most broadly-speaking, data is spatial when it has coordinates, and therefore a coordinate reference system (see more on this below). Coordinates define the longitude (x) and latitude (y) of where data is located across the globe.\nmapschool.io is a fantastic resource for a simple explanation of many spatial concepts.\n\nSpatial data types\nThere are three broad classes of spatial data that you may encounter.\n\nVector\n\n\nVector data can be points, lines, or polygons. Quite typically vector data is stored as shapefiles (.shp), although there are many file formats to store vector data. My go-to is geopackages (.gpkg) (more on this later).\nOften, vector data have multiple attributes, meaning that different variables have been measured for each vector geometry.\n\n\nRaster\n\n\nRaster data is gridded data, where each ‘grid cell’ (also referred to as a ‘pixel’) stores a data value. Data can be categorical (e.g. land use classes) or continuous (e.g. temperature).\nGrids can be regular, irregular, curvilinear, etc.\n\n\nSpatiotemporal data cubes\n\n\nSpatiotemporal data cubes are when vector or raster data have an additional dimension beyond x & y coordinates: time."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#data-download",
    "href": "qgis/Essentials/1 - Fundamentals.html#data-download",
    "title": "The Fundamentals",
    "section": "Data Download",
    "text": "Data Download\nThe data for this session can be directly downloaded from this link.\nOnce downloaded, extract the archive into your raw folder within your data folder."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#importing-data",
    "href": "qgis/Essentials/1 - Fundamentals.html#importing-data",
    "title": "The Fundamentals",
    "section": "Importing data",
    "text": "Importing data\nTo add our own data: Layer &gt; Add Layer &gt; Add Vector Layer..., choose the “ne_50m_admin_1_states_provinces” file, and click “Add”. It is now in your Layers panel.\nYou can also use the Project Home directory in the browser to add another layer: try loading the “populated places” and “rivers” shapefiles (format .shp), by drag-and-dropping or double-clicking.\nAll layers are visible in the “Layers” panel, with the most recently loaded by default at the top. Layers are rendered as they are listed, which means the top ones will cover the bottom ones. Make sure you optimise the order for your map!\nYou can also turn the layer visibility on and off from this panel with the tick box.\n\nLearn about the data\nYou can open the attribute table to see tabular data contained in each layer. (Right-click on a layer and use “Open Attribute Table”. Alternatively, use the top toolbar button or use F6.)\nYou can also use the Identify Features tool in the top toolbar. This allows you to learn about specific features included in the currently selected layer."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#subset-the-data",
    "href": "qgis/Essentials/1 - Fundamentals.html#subset-the-data",
    "title": "The Fundamentals",
    "section": "Subset the data",
    "text": "Subset the data\nWe currently have data from all around the World, which you can confirm by using the Zoom Full button. However, we want to focus on Australia exclusively.\nTo remove the useless regions, we can do the following:\n\nSelect the “admin” layer\nUse the Select Features button, and draw a rectangle around Australia, so all the region appear in yellow\nRight-click on the layer and use Export &gt; Save Selected Features As...\nName the new file “australia_admin” in your project directory, and click OK.\n\nThe new layer is loaded to the map by default.\nNow that we have we have a layer with only the administrative regions for Australia, we can use that as an overlay layer to clip the rivers. Follow these steps:\n\nSelect the layer you want to clip, in this case ne_10m_rivers_lake_centerlines\nUse the Vector &gt; Geoprocessing Tools &gt; Clip... tool\nUse the “australia_admin” layer as the overlay.\nClick “Run”\n\n\nIf you get an error about invalid geometries, you might have to use the Fix geometries tool on the Australian shapefile first (found in the Processing Toolbox).\n\nNotice how the clipped layers don’t have a descriptive name? Make sure you rename them. Let’s changed Clipped to australia_rivers_10m\nYou can now hide the original layers and confirm that you have only Australian data visible in the canvas by using the Zoom Full button.\n\nChallenge: can you do the same for the Cities? Do you notice anything strange? How can we fix that?"
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#saving-your-project",
    "href": "qgis/Essentials/1 - Fundamentals.html#saving-your-project",
    "title": "The Fundamentals",
    "section": "Saving your project",
    "text": "Saving your project\nIt’s always a good idea to regularly save your progress."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#temporary-scratch-layers",
    "href": "qgis/Essentials/1 - Fundamentals.html#temporary-scratch-layers",
    "title": "The Fundamentals",
    "section": "Temporary Scratch Layers",
    "text": "Temporary Scratch Layers\nNotice the little icon next to some of your layers? We previously created “temporary scratch layers”, they’re basically temp files that will disappear when we close QGIS. This is useful if you keep processing data and creating new layers that you want to discard afterwards. In our case, we do want to keep the “cities” and “rivers” layers, so we need to save them to a file. If we try to close QGIS with scratch layers loaded, it will give you a warning that they will be lost in the process.\nYou can click on the scratch layer icon to save the file. In the dialog, we can give the layers a File name (in our project’s home directory) and click OK.\nYou can save your project with the floppy disk icon, or using Ctrl + S, and the project should be visible in a list when you re-open QGIS again."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#personalise-your-map",
    "href": "qgis/Essentials/1 - Fundamentals.html#personalise-your-map",
    "title": "The Fundamentals",
    "section": "Personalise your map",
    "text": "Personalise your map\n\nChange the symbology\nOur vector layers are assigned a random colour when we load them. We now want to make them look better.\nDouble-click on the “admin” layer to open the Layer Properties click the  Symbology tab, and use Color to change to a better colour. Click Apply. We can also go into more details about the border (colour, width, type of line…) by clicking on Simple fill.\nWe can make more complex fills by adding an extra “symbol layer”, and layering different kinds of fill styles. Try this with both polygons and lines. For example, style the rivers so they look like water (the topo hydrology preset is a good start).\nNow try to change the point symbology of our “populated places” layer: we don’t have to stick to Simple marker. Try for example the different icons available with Symbol layer type &gt; SVG marker or Font marker selected.\n\nThe Properties dialog is quite large and makes it difficult to see the changes in symbology. You can use the “Layer Styling Panel” (button in the Layers panel, or F7 shortcut) to use a side panel instead, with the “Live update” option on by default.\n\n\n\nAdd labels\nHave a look at the attribute table for our “populated places” layer. What could we use to label our points?\nDouble-click on the “populated places” layer:  Labels and then click No Labels &gt; Single labels. You can also use the Layer Labelling Options button to open the sidebar, which allows you to “Live update” the map when you change a setting.\nChoose Value &gt; Name to label with the city names. In the “Text” tab, we can change the look of our labels: amend the size, the colour, the font… We can also add a text buffer with the “Buffer tab” to make them more readable.\nThe placement tab allows us to fine-tune the placement of the labels in reference to the points. The default mode is “Cartographic”, and we can increase the distance to the symbol used. If we want the label to cover the point, we can use Mode &gt; Offset from point and use the middle quadrant. We might also want to set the layer’s Symbology to “No Symbols”."
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#simple-map-export",
    "href": "qgis/Essentials/1 - Fundamentals.html#simple-map-export",
    "title": "The Fundamentals",
    "section": "Simple Map Export",
    "text": "Simple Map Export\nYou can export your map with a very customised layout, or you can do a simple export. This morning we will look at the simple map export.\nZoom to the level of detail you want your image to contain.\nTo export out your map Project &gt; Import/Export &gt; Export Map to Image..., choose Draw on Canvas, increase the Resolution to 300 dpi, click Save. Navigate to where you want to save your image, name it, and click Save"
  },
  {
    "objectID": "qgis/Essentials/1 - Fundamentals.html#resources",
    "href": "qgis/Essentials/1 - Fundamentals.html#resources",
    "title": "The Fundamentals",
    "section": "Resources",
    "text": "Resources\n\nYou can find help with QGIS in the QGIS Documentation."
  },
  {
    "objectID": "qgis/setup.html",
    "href": "qgis/setup.html",
    "title": "QGIS",
    "section": "",
    "text": "Warning🚧 Under construction 🚧\n\n\n\nThis content is still under construction and will be changing over the next few weeks.",
    "crumbs": [
      "QGIS"
    ]
  },
  {
    "objectID": "qgis/setup.html#overview",
    "href": "qgis/setup.html#overview",
    "title": "QGIS",
    "section": "Overview",
    "text": "Overview\nWelcome to our three-day QGIS training intensive! This runs twice a year and the next intensive will be in early February.\nBy the end of the three days, you’ll have learnt the QGIS skills to …\nAs we set up, there’s a few things to do, if you haven’t already\n\nInstall the software\nIntroduce yourself to your table\nJoin our Teams channel\nRegister your attendance",
    "crumbs": [
      "QGIS"
    ]
  },
  {
    "objectID": "qgis/setup.html#software",
    "href": "qgis/setup.html#software",
    "title": "QGIS",
    "section": "Software",
    "text": "Software\n…\n## Setting up\nThis tutorial is designed for QGIS 3.40. If you need to install it on your computer, go to the QGIS website.",
    "crumbs": [
      "QGIS"
    ]
  },
  {
    "objectID": "qgis/setup.html#workshops",
    "href": "qgis/setup.html#workshops",
    "title": "QGIS",
    "section": "Workshops",
    "text": "Workshops\n…\nThese content sessions are pretty packed, and we won’t have too much time to deviate. That’s why we’ll also have five project sessions - see The Project for details. You’re welcome to ask lengthier questions and play around there!",
    "crumbs": [
      "QGIS"
    ]
  },
  {
    "objectID": "r/Advanced topics/6 - Programming.html",
    "href": "r/Advanced topics/6 - Programming.html",
    "title": "Programming Essentials",
    "section": "",
    "text": "In this workshop we cover the building blocks for developing more complex code, looking at",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "r/Advanced topics/6 - Programming.html#directing-traffic-with-conditionals",
    "href": "r/Advanced topics/6 - Programming.html#directing-traffic-with-conditionals",
    "title": "Programming Essentials",
    "section": "Directing traffic with conditionals",
    "text": "Directing traffic with conditionals\nIn the first half of this session we’ll look at two types of control flows: conditionals and loops.\nConditionals allow you to put “gates” in your code, only running sections if a certain condition is true. They are common to most programming languages.\nIn R, they are called if statements, because you use the if command. For example,\n\nif (5 &gt; 0) {\n  print(\"We're inside the if statement\")\n}\n\n[1] \"We're inside the if statement\"\n\n\nThe line print(\"We're inside the if statement\") will only run if 5 &gt; 0 is true. If not, it’ll get skipped.\nCurly brackets are essential. Only code inside them will be governed by conditional\n\nif (5 &gt; 0) {\n  print(\"We're inside the if statement\")\n}\n\n[1] \"We're inside the if statement\"\n\nprint(\"This code always runs\")\n\n[1] \"This code always runs\"\n\n\nWatch what happens if we change the condition\n\nif (5 &gt; 10) {\n  print(\"We're inside the if statement\")\n}\n\nprint(\"This code always runs\")\n\n[1] \"This code always runs\"\n\n\nNow, the first line doesn’t run. That’s the essence of a conditional.\nThere’s not much point to using a condition that will always be true. Typically, you’d use a variable in the condition, for example.\n\npet_age &lt;- 10\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n}\n\n\nLogical operators\nHere is a table of the different operators you can make conditions with. When you run them, they always return either True or False.\n\n\n\n\n\n\n\n\nOperator\nTrue example\nDescription\n\n\n\n\n==\n10 == 10\nSame value and type\n\n\n!=\n\"10\" != 10\nDifferent value or type\n\n\n&gt;\n10 &gt; 5\nGreater than\n\n\n&gt;=\n10 &gt;= 10\nGreater than or equal to\n\n\n&lt;\n5 &lt; 10\nLess than\n\n\n&lt;=\n5 &lt;= 10\nLess than or equal to\n\n\n&&\n10 == 10 && \"apple\" == \"apple\"\nOnly true if both conditions are true.\n\n\n||\n10 == 10 || \"a\" == \"b\"\nAlways true if one condition is true.\n\n\n\n\n\nelif and else\nif statements only run if the condition is True. What happens if its False? That’s what the else command is for, it’s like a net that catches anything that slipped past if:\n\npet_age &lt;- 5\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n} else {\n  print(\"My pet is 10 or younger\")\n}\n\n[1] \"My pet is 10 or younger\"\n\n\n\nelse also needs curly brackets!\n\nCheck what happens when you change the age from 5 to 15.\nFinally, what if you wanted to check another condition only if the first one fails? That’s what else if is for. It’s another if statement but it only runs if the first fails.\n\npet_age = 5\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n} else if (pet_age &lt; 5) {\n  print(\"My pet is younger than 5\")\n} else {\n  print(\"My pet is 10 or younger\")\n}\n\n[1] \"My pet is 10 or younger\"\n\n\nYou can include as many as you’d like\n\npet_age = 5\n\nif (pet_age &gt; 10) {\n  print(\"My pet is older than 10\")\n} else if (pet_age &lt; 5) {\n  print(\"My pet is younger than 5\")\n} else if (pet_age &lt; 1) {\n  print(\"My pet is freshly born\")\n} else {\n  print(\"My pet is 10 or younger\")\n}\n\n[1] \"My pet is 10 or younger\"",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "r/Advanced topics/6 - Programming.html#repeat-after-me",
    "href": "r/Advanced topics/6 - Programming.html#repeat-after-me",
    "title": "Programming Essentials",
    "section": "Repeat after me",
    "text": "Repeat after me\nSometimes you need to repeat a task multiple times. Sometimes hundreds. Maybe you need to loop through 1 million pieces of data. Not fun.\nR’s loops offer us a way to run a section of code multiple times. There are two types: for loops, which run the code once for each element in a sequence (like a list or string), and while loops, which run until some condition is false.\n\nwhile loops\nThese are almost the same as if statements, except for the fact that they run the code multiple times. Let’s begin with a basic conditional\n\nnumber &lt;- 1\n\nif (number &lt; 5) {\n  paste(number, \"is less than 10.\")\n}\n\n[1] \"1 is less than 10.\"\n\n\n\nThe paste function lets you print multiple things together\n\nWhat if we wanted to check all the numbers between 5 and 10? We can use a while loop.\n\nnumber &lt;- 1\n\nwhile (number &lt; 5) {\n  print(paste(number, \"is less than 10.\"))\n  number &lt;- number + 1\n}\n\n[1] \"1 is less than 10.\"\n[1] \"2 is less than 10.\"\n[1] \"3 is less than 10.\"\n[1] \"4 is less than 10.\"\n\n\n\nWe need to include paste inside print because we’re doing it multiple times.\n\nWe’ve done two things\n\nReplace if with while\nIntroduce number = number + 1 to increase the number each time.\n\n\nWithout step 2, we’d have an infinite loop – one that never stops, because the condition would always be true!\n\nWhile loops are useful for repeating code an indeterminate number of times.\n\n\nfor loops\nRealistically, you’re most likely to use a for loop. They’re inherently safer (you can’t have an infinite loop) and often handier.\nIn R, for loops iterate through a sequence, like the objects in a list. This is more like other languages’ foreach, than most’s for.\nLet’s say you have a vector of different fruit\n\nlist_of_fruits &lt;- c(\"apple\", \"banana\", \"cherry\")\n\nand you want to run a section of code on \"apple\", then \"banana\", then \"cherry\". Maybe you want to know which ones have the letter “a”. We can start with a for loop\n\nlist_of_fruits &lt;- c(\"apple\", \"banana\", \"cherry\")\n\nfor (fruit in list_of_fruits) {\n  print(fruit)\n}\n\n[1] \"apple\"\n[1] \"banana\"\n[1] \"cherry\"\n\n\nThis loop’s job is to print out the variable fruit. But where is fruit defined? Well, the for loop runs print(fruit) for every element of list_of_fruits, storing the current element in the variable fruit. If we were to write it out explicitly, it would look like\n\nfruit &lt;- list_of_fruits[1]\nprint(fruit)\n\n[1] \"apple\"\n\nfruit &lt;- list_of_fruits[2]\nprint(fruit)\n\n[1] \"banana\"\n\nfruit &lt;- list_of_fruits[3]\nprint(fruit)\n\n[1] \"cherry\"\n\n\nLet’s return to our goal: working out which ones have an “a”. We need to put a conditional inside the loop:\n\nlist_of_fruits &lt;- c(\"apple\", \"banana\", \"cherry\")\n\nfor (fruit in list_of_fruits) {\n    if (grepl(\"a\", fruit)) { \n      print(paste(\"a is in\", fruit))\n    }\n    else {\n      print(paste(\"a is not in\", fruit))\n    }\n}\n\n[1] \"a is in apple\"\n[1] \"a is in banana\"\n[1] \"a is not in cherry\"\n\n\nFinally, it’s often convenient to loop through a list of numbers. R makes this easy with the x:y notation:\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\ncontains all the integers between \\(1\\) and \\(10\\). To loop through each,\n\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nThe advantage of this approach is that we can loop through many numbers:\n\nfor (i in 1:1000) {\n  print(i)\n}\n\nThis can be useful if you need to loop through multiple objects by indexing. We’ll spare you the output here.\n\n\nMapping with purrr\nConsider the follow situation. You have a dataset, and want to apply a function to every column. Or maybe some columns. What to do?\nYou could loop over them with a for loop. Alternatively, you could use the mapping functions in purrr, which simplifies the code.\nWhat is a map? Generally, a map takes something and makes it something else. So far, that’s the same a function. The difference is that a map takes lots of things and translates them all in the same way. For example, a geographical map takes life-sized locations and transforms them all in the same way to a hand-sized piece of paper.\nEssentially, maps are a way of transforming a selection of variables in the same way. We’ll start by brining in the purrr library\n\nlibrary(purrr)\n\nLet’s use the same data as in the statistics session:\n\nlibrary(dplyr)\nplayers &lt;- read.csv(\"../../data/Players2024.csv\")\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nWhat if you want the median value from all columns? We can use the map_dbl() function to map doubles (long decimal numbers):\n\nmap_dbl(players, median)\n\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\nWarning in mean.default(sort(x, partial = half + 0L:1L)[half + 0L:1L]):\nargument is not numeric or logical: returning NA\n\n\n       name  birth_date   height_cm   positions nationality         age \n         NA          NA         183          NA          NA          25 \n       club \n         NA \n\n\nDon’t worry about the warnings - they’re just there because you can’t take the median of a non-numeric variable. To check which ones are, we can map the logical operator is.numeric:\n\nmap_lgl(players, is.numeric)\n\n       name  birth_date   height_cm   positions nationality         age \n      FALSE       FALSE        TRUE       FALSE       FALSE        TRUE \n       club \n      FALSE \n\n\nWe can use the pipe here,\n\nplayers %&gt;% map_lgl(is.numeric)\n\n       name  birth_date   height_cm   positions nationality         age \n      FALSE       FALSE        TRUE       FALSE       FALSE        TRUE \n       club \n      FALSE \n\n\nLet’s select the numeric columns and look at the medians again\n\nplayers %&gt;% \n  select_if(is.numeric) %&gt;%\n  map_dbl(median)\n\nheight_cm       age \n      183        25 \n\n\nWe can also create custom functions. We use .x to refer to the variable:\n\nplayers %&gt;% \n  select_if(is.numeric) %&gt;%\n  map_dbl(~max(.x) - min(.x))\n\nheight_cm       age \n       46        27",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "r/Advanced topics/6 - Programming.html#building-your-own-machines",
    "href": "r/Advanced topics/6 - Programming.html#building-your-own-machines",
    "title": "Programming Essentials",
    "section": "Building your own machines",
    "text": "Building your own machines\nWe’ll wrap this session up by looking at custom functions. So far, we’ve only used built-in functions or those from other people’s modules. But we can make our own!\nWe’ve only ever called functions - this is what we do when we use them. All functions need a definition, this is the code that gets run when they’re called.\n\nThe function definition\nFunctions are machines. They take some inputs, run some code with those inputs, and spit out one output. We need to define how they work before we use them. We should specify\n\nA name\nSome inputs\nThe code to run (the machine itself)\n\nWe include these in three steps\n\nThe first line of the function definition (the function signature) specifies the name and inputs\nWe then indent all the code we want to run with our inputs\nWe end with a return statement, specifying the output\n\n\ninsert_function_name_here &lt;- function(input_1_name, input_2_name, ...) {\n  # Code code code\n}\n\nFor example, let’s create a function that converts centimetres to metres.\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_cm / 100\n}\n\nTaking it apart, we have\n\nName: cm_to_m\nInputs (just one): value_in_cm\nCode (just one line): value_in_cm / 100\n\nImportantly, nothing appears when you run this code. Why? Because you’ve only defined the function, you haven’t used it yet.\nTo use this function, we need to call it. Let’s convert \\(10\\text{ cm}\\) to \\(\\text{m}\\).\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_cm / 100\n}\n\ncm_to_m(10)\n\n[1] 0.1\n\n\nWhen we call the function, it runs with value_in_cm &lt;- 10.\nThat’s it! Every function that you use, built-in or imported, looks like this.\nBecause functions must be defined before called, and defining them produces no output, best practice is to place functions at the top of your script, below the import statements.\n\nReturn values and default values\nOne quirk of R functions is that, by default, they return the output of the line. Let’s add a new line that prints the message “\\(x\\text{ cm} = y\\text{ m}\\)”. We’ll need to also save our calculation in the process:\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_m &lt;- value_in_cm / 100\n    print(paste(value_in_cm, \"cm =\", value_in_m, \"m\"))\n}\n\ncm_to_m(10)\n\n[1] \"10 cm = 0.1 m\"\n\n\nIt works, but we have a problem. The output of the function is the whole message, not the value. The easiest way to fix this is to call the output on the last line:\n\ncm_to_m &lt;- function(value_in_cm) {\n    value_in_m &lt;- value_in_cm / 100\n    print(paste(value_in_cm, \"cm =\", value_in_m, \"m\"))\n    value_in_m\n}\n\ncm_to_m(10)\n\n[1] \"10 cm = 0.1 m\"\n\n\n[1] 0.1\n\n\nAlternatively, you can use the return() function to exit before the end and manually specify the output.",
    "crumbs": [
      "Advanced topics",
      "Programming Essentials"
    ]
  },
  {
    "objectID": "r/Essentials/4 - Sharing and Publishing.html",
    "href": "r/Essentials/4 - Sharing and Publishing.html",
    "title": "Sharing and Publishing",
    "section": "",
    "text": "In this workshop we cover using GitHub for sharing your source code, Git for version control, and Quarto for publishing outputs. Specifically, we look at:",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "r/Essentials/4 - Sharing and Publishing.html#quarto",
    "href": "r/Essentials/4 - Sharing and Publishing.html#quarto",
    "title": "Sharing and Publishing",
    "section": "Quarto",
    "text": "Quarto\nQuarto is a publishing system that allows creating documents, presentations, websites and dashboards that contain prose, code and code outputs. This means that such outputs can detail exactly what happened to the data, and outputs can be re-generated very quickly if, for example, the underlying dataset was updated, or if the analysis needs to change.\nLet’s create a document using some of the syntax we learned in previous sessions.\nUse “New File &gt; Quarto Document…” to create a .qmd file. The dialog that open allows us to change a few settings. Let’s give the title “Reproducible Output”, and untick “Use visual markdown editor” so we can learn about the syntax. Save the new file in your project directory.\nThis new .rmd script will be made of markdown text and code chunks. Code chunks can be inserted with the editor pane’s toolbar or the keyboard shortcut Ctrl+Alt+I.\nAt the top of our script, we need to include a header (also called “front matter”) that contains the document’s settings. We can start with:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\n---\nThe rest of the document will be a mix of markdown-formatted prose and executable code chunks. For example:\n## Import the data\n\nLet's **import** the data:\n\n```{r}\nplayers &lt;- read.csv(\"../../data/Players2024.csv\")\n```\n\n## Prepare the data\n\nRemove missing position and ensure **reasonable heights**:\n\n```{r}\nlibrary(dplyr)\nplayers &lt;- players %&gt;% filter(positions != \"Missing\", height_cm &gt; 100)\n```\n\n## Plot the data\n\nA boxplot of player **height by position**:\n\n```{r}\nlibrary(ggplot2)\nggplot(players, aes(x = positions, y = height_cm)) + \n  geom_boxplot() + \n  labs(x = \"Position\", y = \"Height (cm)\")\n```\nOutside the code chunks, we use the Markdown markup language to format the text. For example, using ## before some text defines a heading of level 2 (level 1 being the document’s title), and using ** around some text makes it bold. See more Markdown hints in the Quarto documentation.\n\nRendering\nTo render the document and see the result, use the “Render” button in the source pane toolbar.\nThis should create a HTML document in your project directory, which you can open in a web browser by clicking it and choosing “View in web browser” (if it is not opened automatically already). The file can be left open and will automatically update in your browser when the document is rendered again.\nAs the default Quarto output is a HTML file, we can include interactive visualisations too.\n\n\nCell options\nIf you want to show the code but don’t want to run it, you can add the cell option #| eval: false. And if you want to show the output but not show the underlying code, use #| echo: false.\n\n## Interactive plots\n\nWe need plotly. If you need to install it:\n\n```{r}\n#| eval: false\ninstall.packages(\"plotly\")\n```\n\nAn interactive scartterplot:\n\n```{r}\n#| title: Age vs Height\n#| echo: false\n\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\nlibrary(plotly)\nggplotly(p)\n```\nAnd for adding a caption and alternative text to a figure, we can modify our boxplot chunk as follows:\n```{r}\n#| fig-cap: \"Goalkeepers tend to be taller.\"\n#| fig-alt: \"A boxplot of the relationship between height and position.\"\nlibrary(ggplot2)\nggplot(players, aes(x = positions, y = height_cm)) + \n  geom_boxplot() + \n  labs(x = \"Position\", y = \"Height (cm)\")\n```\nMany more cell options exist, including captioning and formatting visualisations. Note that these options can be used at the cell level as well as globally (by modifying the front matter at the top of the document).\nFor example, to make sure error and warning messages are never shown:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nwarning: false\nerror: false\n---\n\n\nOutput formats\nThe default output format in Quarto is HTML, which is by far the most flexible. However, Quarto is a very versatile publishing system and can generate many different output formats, including PDF, DOCX and ODT, slide formats, Markdown suited for GitHub… and even whole blogs, books and dashboards.\nLet’s try rendering a PDF:\n---\ntitle: Reproducible Output\nauthor: Your Name\ndate: 2025-01-01\nformat: pdf\n---\nWhen rendering PDFs, the first issue we might run into is the lack of a LaTeX distribution. If Quarto didn’t detect one, it will suggest to install tinytex (a minimal LaTeX distribution) with this terminal command:\nquarto install tinytex\nOnce that is installed, Quarto should render a PDF.\nAnother issue with our example document is that an interactive HTML visualisation won’t be rendered in the PDF. You can suppress it by using the #| eval: false option:\n```{r}\n#| title: Age vs Height\n#| echo: false\n#| eval: false\np &lt;- ggplot(players, aes(x = age, y = height_cm, colour = positions, label = name, label2 = nationality)) + \n  geom_point() + \n  facet_wrap(vars(positions)) + \n  labs(x = \"Age\", colour = \"Position\", y = \"Height (cm)\")\nlibrary(plotly)\nggplotly(p)\n```",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "r/Essentials/4 - Sharing and Publishing.html#git-and-github",
    "href": "r/Essentials/4 - Sharing and Publishing.html#git-and-github",
    "title": "Sharing and Publishing",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nGit is a version control system that allows to record a clean history of your project, track precise authorship, and collaborate asynchronously with others. It can be used offline, from the command line or with integration into Integrated Desktop Environments\nGitHub is one of many websites that allow you to host projects that are tracked with Git. But even without using Git at all, it is possible to use GitHub to share and make your project public. Many researchers use it to make their code public alongside a published paper, to increase reproducibility and transparency. It can also be useful to build and share a portfolio of your work.\nFortunately, RStudio does have Git integration! If you have Git installed on your computer, you can use the “Git” section to commit those changes to a repository. You can then push and pull GitHub to keep your local copy in sync.\nLearning about the ins and out of Git takes time, so in this section we will mainly use GitHub as a place to upload and share your code and outputs, and as a starting point for learning more about Git in the future.\n\nGitHub\nGitHub is currently the most popular place for hosting, sharing and collaborating on code. You can create an account for free, and then create a repository for your project.\n\nCreate an account and log in\nClick on the “+” button (top right of the page)\nSelect “New repository”\nChoose a name and description for your repository\nTick “Add a README file” - this will be where you introduce your project\nClick “Create repository”\n\nFrom there, you can upload your files, and edit text-based files straight from your web browser if you need to.\nThe README file is a markdown file that can contain the most important information about your project. It’s important to populate it as it is the first document most people see. It could contain:\n\nName and description of the project\nHow to use it (installation process if any, examples…)\nWho is the author, who maintains it\nHow to contribute\n\nFor inspiration, see the pandas README file.\nTo practice managing a git repository on GitHub, try creating a personal portfolio repository where you can showcase what you have worked on and the outputs your are most proud of.",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "r/Essentials/4 - Sharing and Publishing.html#further-resources",
    "href": "r/Essentials/4 - Sharing and Publishing.html#further-resources",
    "title": "Sharing and Publishing",
    "section": "Further resources",
    "text": "Further resources\n\nSome alternatives to GitHub: Codeberg and Gitlab\nQuarto documentation\nCourse on Git from the command line\nCourse on Git with GitHub\nBook on Git for R and RStudio users, by Jenny Bryan",
    "crumbs": [
      "Essentials",
      "Sharing and Publishing"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html",
    "href": "r/Essentials/1 - Fundamentals.html",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this workshop, we will learn about:",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#maths-and-objects",
    "href": "r/Essentials/1 - Fundamentals.html#maths-and-objects",
    "title": "The Fundamentals",
    "section": "Maths and objects",
    "text": "Maths and objects\nThe console (by default at the bottom left in RStudio) is where most of the action happens. In the console, we can use R interactively. We write a command and then execute it by pressing Enter.\nIn its most basic use, R can be a calculator. Try executing the following commands:\n\n10 - 2\n\n[1] 8\n\n3 * 4\n\n[1] 12\n\n2 + 10 / 5\n\n[1] 4\n\n\nThose symbols are called “binary operators”: we can use them to multiply, divide, add and subtract. Once we execute the command (the “input”), we can see the result in the console (the “output”).\nWhat if we want to keep reusing the same value? We can store data by creating objects, and assigning values to them with the assignment operator &lt;-:\n\nnum1 &lt;- 42\nnum2 &lt;- num1 / 9\nnum2\n\n[1] 4.666667\n\n\n\nYou can use the shortcut Alt+- to type the assignement operator quicker.\n\nWe can also store text data:\n\nsentence &lt;- \"Hello World!\"\nsentence\n\n[1] \"Hello World!\"\n\n\nYou should now see your objects listed in you environment pane (top right).\nAs you can see, you can store different kinds of data as objects. If you want to store text data (a “string of characters”), you have to use quotes around them.\n\nYou can recall your recent commands with the up arrow, which is especially useful to correct typos or slightly modify a long command.\n\nUsing the console is great to test things and quickly run commands and get outputs. However, if we want to store our process and refine our code as we go over several sessions, it is best to work with a script. Let’s do a bit more setting up of our project.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#create-a-folder-structure",
    "href": "r/Essentials/1 - Fundamentals.html#create-a-folder-structure",
    "title": "The Fundamentals",
    "section": "Create a folder structure",
    "text": "Create a folder structure\nTo keep it tidy, we are creating 3 folders in our project directory:\n\nscripts\ndata\nplots\n\nYou can do that with the “New Folder” button in the “Files” pane (bottom right of the window).",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#scripts",
    "href": "r/Essentials/1 - Fundamentals.html#scripts",
    "title": "The Fundamentals",
    "section": "Scripts",
    "text": "Scripts\nScripts are simple text files that contain R code. They are useful for:\n\nsaving a set of commands for later use (and executing it in one click)\nmaking research reproducible\nmaking writing and reading code more comfortable\ndocumenting the code with comments, and\nsharing your work with peers\n\nLet’s create a new R script with the menu: File &gt; New File &gt; R Script. (This can also be done with the first icon in the toolbar, or with the shortcut Ctrl+Shift+N.)\nThis opens our fourth pane in the top left of RStudio: the source pane.\n\nComments\nWe should start with a couple of comments, to document our script. Comments start with #, and will be ignored by R:\n# Description: Introduction to R and RStudio\n# Author: &lt;your name&gt;\n# Date: &lt;today's date&gt;\n\n\nSyntax highlighting\nNow, add some commands to your script:\n\nnum1 &lt;- 42\nnum2 &lt;- num1 / 9\n\nNotice the colours? This is called syntax highlighting. This is one of the many ways RStudio makes it more comfortable to work with R. The code is more readable when working in a script.\n\nWhile editing your script, you can run the current command (or the selected block of code) by using Ctrl+Enter. Remember to save your script regularly with the shortcut Ctrl+S. You can find more shortcuts with Alt+Shift+K, or the menu “Tools &gt; Keyboard Shortcuts Help”.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#functions",
    "href": "r/Essentials/1 - Fundamentals.html#functions",
    "title": "The Fundamentals",
    "section": "Functions",
    "text": "Functions\nAn R function is a little program that does a particular job. It usually looks like this:\n&lt;functionname&gt;(&lt;argument(s)&gt;)\nArguments tell the function what to do. Some functions don’t need arguments, others need one or several, but they always need the parentheses after their name.\nFor example, try running the following command:\n\nround(num2)\n\n[1] 5\n\n\nThe round() function rounds a number to the closest integer. The only argument we give it is num2, the number we want to round.\n\nIf you scroll back to the top of your console, you will now be able to spot functions in the text.\n\n\nHelp\nWhat if we want to learn more about a function?\nThere are two main ways to find help about a specific function in RStudio:\n\nthe shortcut command: ?functionname\nthe keyboard shortcut: press F1 with your cursor in a function name (you can do this by simply clicking on the function name)\n\nLet’s look through the documentation for the round() function:\n?round\nAs you can see, different functions might share the same documentation page.\nThere is quite a lot of information in a function’s documentation, but the most important bits are:\n\nDescription: general description of the function(s)\nUsage: overview of what syntax can be used\nArguments: description of what each argument is\nExamples: some examples that demonstrate what is possible\n\nSee how the round() function has a second argument available? Try this now:\n\nround(num2, digits = 2)\n\n[1] 4.67\n\n\nWe can change the default behaviour of the function by telling it how many digits we want after the decimal point, using the argument digits. And if we use the arguments in order, we don’t need to name them:\n\nround(num2, 2)\n\n[1] 4.67\n\n\nTo group values together in a single object, use the c() function.\nc() combines the arguments into a vector. In other words, it takes any number of arguments (hence the ...), and stores all those values together, as one single object. For example, let’s store the ages of our pet dogs in a new object:\n\nages &lt;- c(4, 10, 2, NA, 3)\n\n\nYou can store missing data as NA.\n\nWe can now reuse this vector, and calculate their human age:\n\nages * 7\n\n[1] 28 70 14 NA 21\n\n\nR can create visualisations with functions too. Try a bar plot of your dogs’ ages with the barplot() function:\n\nbarplot(ages)\n\n\n\n\n\n\n\n\nWe can customise the plot with a title and some colours, for example:\n\nbarplot(ages, main = \"How old are my dogs?\", col = \"pink\")\n\n\n\n\n\n\n\n\n\nChallenge 1 – Finding help\nUse the help pages to find out what these functions do, and try executing commands with them:\n\nrep.int()\nmean()\nrm()\n\nrep.int() creates vectors like c(), but it is designed to easily replicate values. For example, if you find something very funny:\n\nrep.int(\"Ha!\", 30)\n\n [1] \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\"\n[13] \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\"\n[25] \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\" \"Ha!\"\n\n\nThe next function, mean(), returns the mean of a vector of numbers:\n\nmean(ages)\n\n[1] NA\n\n\nWhat happened there?\nWe have an NA value in the vector, which means the function can’t tell what the mean is. If we want to change this default behaviour, we can use an extra argument: na.rm, which stands for “remove NAs”.\n\nmean(ages, na.rm = TRUE)\n\n[1] 4.75\n\n\n\nIn our last command, if we hadn’t named the na.rm argument, R would have understood TRUE to be the value for the trim argument!\n\nrm() removes an object from your environment (remove() and rm() point to the same function). For example:\n\nrm(num1)\n\n\nR does not check if you are sure you want to remove something! As a programming language, it does what you ask it to do, which means you might have to be more careful. But you’ll see later on that, when working with scripts, this is less of a problem.\n\nLet’s do some more complex operations by combining two functions:\nls() returns a character vector: it contains the names of all the objects in the current environment (i.e. the objects we created in this R session). Notice that this function doesn’t require us to provide any argument, but we still need to write the parentheses to run the function.\nIs there a way we could combine ls() with rm()?\nYou can remove all the objects in the environment by using ls() as the value for the list argument:\n\nrm(list = ls())\n\nWe are nesting a function inside another one. More precisely, we are using the output of the ls() function as the value passed on to the list argument in the rm() function.\n\n\n\nIncomplete functions\nIf you don’t finish a function, by leaving off the last bracket ) for example, the line of code won’t necessarily give you an error, but it won’t work very well. If you forget to include that last bracket, R will run the code, and then wait for further instructions before giving you an output. This will appear as a + in the console like so:\n&gt; round(1.23\n+\nIf you try to give any further instructions to R, it will likely just continue giving you + symbols, and not return anything. To stop this, click on the console and press the Esc key on your keyboard.\n\n\nMore help\nWe’ve practised how to find help about functions we know the name of. What if we don’t know what the function is called? Or if we want general help about R?\n\nThe function help.start() is a good starting point: it opens a browser of official R help.\nIf you want to search for a word in all the documentation, you can use the ?? syntax. For example, try executing ??anova.\nFinally, you will often go to your web browser and search for a particular question, or a specific error message: most times, there already is an answer somewhere on the Internet. The challenge is to ask the right question!",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#import-data",
    "href": "r/Essentials/1 - Fundamentals.html#import-data",
    "title": "The Fundamentals",
    "section": "Import data",
    "text": "Import data\nLet’s bring in some data. Download our gapminder dataset and save it in the data/ folder you just created.\nOnce you’ve got the data, use the read.csv() command to bring it into R:\n\ngapminder &lt;- read.csv(\"../../data/gapminder.csv\")\n\nWhat do you think they do? Describe each one in detail, and try executing them.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#explore-data",
    "href": "r/Essentials/1 - Fundamentals.html#explore-data",
    "title": "The Fundamentals",
    "section": "Explore data",
    "text": "Explore data\nWe have downloaded a CSV file from the Internet, and read it into an object called gapminder.\nYou can type the name of your new object to print it to screen:\n\ngapminder\n\nThat’s a lot of lines printed to your console. To have a look at the first few lines only, we can use the head() function:\n\nhead(gapminder)\n\n      country year      pop continent lifeExp gdpPercap\n1 Afghanistan 1952  8425333      Asia  28.801  779.4453\n2 Afghanistan 1957  9240934      Asia  30.332  820.8530\n3 Afghanistan 1962 10267083      Asia  31.997  853.1007\n4 Afghanistan 1967 11537966      Asia  34.020  836.1971\n5 Afghanistan 1972 13079460      Asia  36.088  739.9811\n6 Afghanistan 1977 14880372      Asia  38.438  786.1134\n\n\nNow let’s use a few functions to learn more about our dataset:\n\nclass(gapminder) # what kind of object is it stored as?\n\n[1] \"data.frame\"\n\nnrow(gapminder) # how many rows?\n\n[1] 1704\n\nncol(gapminder) # how many columns?\n\n[1] 6\n\ndim(gapminder) # rows and columns\n\n[1] 1704    6\n\nnames(gapminder) # variable names\n\n[1] \"country\"   \"year\"      \"pop\"       \"continent\" \"lifeExp\"   \"gdpPercap\"\n\n\nAll the information we just saw (and more) is available with one single function:\n\nstr(gapminder) # general structure\n\n'data.frame':   1704 obs. of  6 variables:\n $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n $ gdpPercap: num  779 821 853 836 740 ...\n\n\n\nThe RStudio’s environment panel already shows us some of that information (click on the blue arrow next to the object name).\n\nAnd to explore the data in a viewer, click on the table icon next to the object in the Environment pane.\nThis viewer allows you to explore your data by scrolling through, searching terms, filtering rows and sorting the data. Remember that it is only a viewer: it will never modify your original object.\n\nNotice that RStudio actually runs the View() function. Feel free to use that instead of clicking on the button, but note that the case matters: using a lowercase “v” will yield an error.\n\nTo see summary statistics for each of our variables, you can use the summary() function:\n\nsummary(gapminder)\n\n   country               year           pop             continent        \n Length:1704        Min.   :1952   Min.   :6.001e+04   Length:1704       \n Class :character   1st Qu.:1966   1st Qu.:2.794e+06   Class :character  \n Mode  :character   Median :1980   Median :7.024e+06   Mode  :character  \n                    Mean   :1980   Mean   :2.960e+07                     \n                    3rd Qu.:1993   3rd Qu.:1.959e+07                     \n                    Max.   :2007   Max.   :1.319e+09                     \n    lifeExp        gdpPercap       \n Min.   :23.60   Min.   :   241.2  \n 1st Qu.:48.20   1st Qu.:  1202.1  \n Median :60.71   Median :  3531.8  \n Mean   :59.47   Mean   :  7215.3  \n 3rd Qu.:70.85   3rd Qu.:  9325.5  \n Max.   :82.60   Max.   :113523.1  \n\n\nNotice how categorical and numerical variables are handled differently?\nLet’s now plot the relationship between GDP per capita and life expectancy:\n\nplot(gapminder$gdpPercap, gapminder$lifeExp,\n     xlab = \"GDP per capita (USD)\",\n     ylab = \"Life expectancy (years)\")\n\n\n\n\n\n\n\n\n\nFor more on visualisations, we will later dive into the popular ggplot2 package.\n\nFinally, let’s fit a linear model to see how strongly correlated the two variables are:\n\nlinear_model &lt;- lm(gapminder$lifeExp ~ gapminder$gdpPercap)\nsummary(linear_model)\n\n\nCall:\nlm(formula = gapminder$lifeExp ~ gapminder$gdpPercap)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-82.754  -7.758   2.176   8.225  18.426 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.396e+01  3.150e-01  171.29   &lt;2e-16 ***\ngapminder$gdpPercap 7.649e-04  2.579e-05   29.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.49 on 1702 degrees of freedom\nMultiple R-squared:  0.3407,    Adjusted R-squared:  0.3403 \nF-statistic: 879.6 on 1 and 1702 DF,  p-value: &lt; 2.2e-16\n\n\nThe P-value suggests that there is a strong relationship between the two.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#packages",
    "href": "r/Essentials/1 - Fundamentals.html#packages",
    "title": "The Fundamentals",
    "section": "Packages",
    "text": "Packages\nPackages add functionalities to R and RStudio. There are more than 21000 available.\nYou can see the list of installed packages in your “Packages” tab, or by using the library() function without any argument.\nWe are going to install a package called “skimr”. We can do that in the Packages tab:\n\nOpen the “Packages” tab (bottom-right pane)\nClick the “Install” button\nSearch for “skimr”\nClick “Install”\n\n\nNotice how it runs an install.packages() command in the console? You can use that too.\n\nIf I now try running the command skim(), I get an error. That’s because, even though the package is installed, I need to load it every time I start a new R session. The library() function does that. Let’s load the package, and use the skim() function to get an augmented summary of our gapminder dataset:\n\nlibrary(skimr) # load the package into your library\nskim(gapminder) # use a function from the package\n\n\nData summary\n\n\nName\ngapminder\n\n\nNumber of rows\n1704\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncountry\n0\n1\n4\n24\n0\n142\n0\n\n\ncontinent\n0\n1\n4\n8\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1979.50\n17.27\n1952.00\n1965.75\n1979.50\n1993.25\n2007.0\n▇▅▅▅▇\n\n\npop\n0\n1\n29601212.33\n106157896.75\n60011.00\n2793664.00\n7023595.50\n19585221.75\n1318683096.0\n▇▁▁▁▁\n\n\nlifeExp\n0\n1\n59.47\n12.92\n23.60\n48.20\n60.71\n70.85\n82.6\n▁▆▇▇▇\n\n\ngdpPercap\n0\n1\n7215.33\n9857.45\n241.17\n1202.06\n3531.85\n9325.46\n113523.1\n▇▁▁▁▁\n\n\n\n\n\nThis function provides further summary statistics, and even displays a small histogram for each numeric variable.\n\nPackages are essential to use R to its full potential, by making the most out of what other users have created and shared with the community. To get an idea of some of the most important packages depending on your field of study, you can start with the CRAN Task Tiews.\n\n\nChallenge 3\nFor a bit of fun:\n\nTry installing the package “cowsay” and using its function say().\nHave a look at the documentation and the package’s website.\nCan you make Clippy say the current time?\nCan you make a chicken say “bok” a thousand times? (Hint: look at the paste() function and its arguments.)",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#closing-rstudio",
    "href": "r/Essentials/1 - Fundamentals.html#closing-rstudio",
    "title": "The Fundamentals",
    "section": "Closing RStudio",
    "text": "Closing RStudio\nYou can close RStudio after making sure that you saved your script.\nWhen you create a project in RStudio, you create an .Rproj file that gathers information about the state of your project. When you close RStudio, you have the option to save your workspace (i.e. the objects in your environment) as an .Rdata file. The .Rdata file is used to reload your workspace when you open your project again. Projects also bring back whatever source file (e.g. script) you had open, and your command history. You will find your command history in the “History” tab (upper right panel): all the commands that we used should be in there.\nIf you have a script that contains all your work, it is a good idea not to save your workspace: it makes it less likely to run into errors because of accumulating objects. The script will allow you to get back to where you left it, by executing all the clearly laid-out steps.\nThe console, on the other hand, only shows a brand new R session when you reopen RStudio. Sessions are not persistent, and a clean one is started when you open your project again, which is why you have to load any extra package your work requires again with the library() function.",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "r/Essentials/1 - Fundamentals.html#resources",
    "href": "r/Essentials/1 - Fundamentals.html#resources",
    "title": "The Fundamentals",
    "section": "Resources",
    "text": "Resources\n\nWe have a compilation of resources for the rest of your R learning\nAnd a cheatsheet of main terms and concepts for R",
    "crumbs": [
      "Essentials",
      "The Fundamentals"
    ]
  }
]